2025-06-07 11:20:39.117851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1749295239.138736     120 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1749295239.144898     120 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-06-07,11:20:45 | INFO | Running with a single process. Device cuda:0.
Downloading 'open_clip_pytorch_model.bin' to '/root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/52cc993c5c5ff962bd0c60931874bc001e7e9b41666a385530f4a036294576be.incomplete'
2025-06-07,11:20:46 | INFO | Downloading 'open_clip_pytorch_model.bin' to '/root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/52cc993c5c5ff962bd0c60931874bc001e7e9b41666a385530f4a036294576be.incomplete'
open_clip_pytorch_model.bin: 100%|████████████| 784M/784M [00:02<00:00, 270MB/s]
Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/52cc993c5c5ff962bd0c60931874bc001e7e9b41666a385530f4a036294576be
2025-06-07,11:20:49 | INFO | Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/52cc993c5c5ff962bd0c60931874bc001e7e9b41666a385530f4a036294576be
Downloading 'open_clip_config.json' to '/root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/127246c8e2bdbec4fff72874d2814f92ac77a403.incomplete'
2025-06-07,11:20:49 | INFO | Downloading 'open_clip_config.json' to '/root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/127246c8e2bdbec4fff72874d2814f92ac77a403.incomplete'
open_clip_config.json: 100%|███████████████████| 707/707 [00:00<00:00, 4.82MB/s]
Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/127246c8e2bdbec4fff72874d2814f92ac77a403
2025-06-07,11:20:49 | INFO | Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/blobs/127246c8e2bdbec4fff72874d2814f92ac77a403
2025-06-07,11:20:49 | INFO | Loaded hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 model config.
Downloading 'config.json' to '/root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/f8a8cd37533eee7ab2f72c09890b360824352953.incomplete'
2025-06-07,11:20:50 | INFO | Downloading 'config.json' to '/root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/f8a8cd37533eee7ab2f72c09890b360824352953.incomplete'
config.json: 100%|█████████████████████████████| 385/385 [00:00<00:00, 3.13MB/s]
Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/f8a8cd37533eee7ab2f72c09890b360824352953
2025-06-07,11:20:50 | INFO | Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/f8a8cd37533eee7ab2f72c09890b360824352953
loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d/config.json
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.51.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2025-06-07,11:20:53 | INFO | Loading pretrained hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 weights (/root/.cache/huggingface/hub/models--microsoft--BiomedCLIP-PubMedBERT_256-vit_base_patch16_224/snapshots/9f341de24bfb00180f1b847274256e9b65a3a32e/open_clip_pytorch_model.bin).
logit_scale: trainable=True
visual.trunk.cls_token: trainable=True
visual.trunk.pos_embed: trainable=True
visual.trunk.patch_embed.proj.weight: trainable=True
visual.trunk.patch_embed.proj.bias: trainable=True
visual.trunk.blocks.0.norm1.weight: trainable=True
visual.trunk.blocks.0.norm1.bias: trainable=True
visual.trunk.blocks.0.attn.qkv.weight: trainable=True
visual.trunk.blocks.0.attn.qkv.bias: trainable=True
visual.trunk.blocks.0.attn.proj.weight: trainable=True
visual.trunk.blocks.0.attn.proj.bias: trainable=True
visual.trunk.blocks.0.norm2.weight: trainable=True
visual.trunk.blocks.0.norm2.bias: trainable=True
visual.trunk.blocks.0.mlp.fc1.weight: trainable=True
visual.trunk.blocks.0.mlp.fc1.bias: trainable=True
visual.trunk.blocks.0.mlp.fc2.weight: trainable=True
visual.trunk.blocks.0.mlp.fc2.bias: trainable=True
visual.trunk.blocks.1.norm1.weight: trainable=True
visual.trunk.blocks.1.norm1.bias: trainable=True
visual.trunk.blocks.1.attn.qkv.weight: trainable=True
visual.trunk.blocks.1.attn.qkv.bias: trainable=True
visual.trunk.blocks.1.attn.proj.weight: trainable=True
visual.trunk.blocks.1.attn.proj.bias: trainable=True
visual.trunk.blocks.1.norm2.weight: trainable=True
visual.trunk.blocks.1.norm2.bias: trainable=True
visual.trunk.blocks.1.mlp.fc1.weight: trainable=True
visual.trunk.blocks.1.mlp.fc1.bias: trainable=True
visual.trunk.blocks.1.mlp.fc2.weight: trainable=True
visual.trunk.blocks.1.mlp.fc2.bias: trainable=True
visual.trunk.blocks.2.norm1.weight: trainable=True
visual.trunk.blocks.2.norm1.bias: trainable=True
visual.trunk.blocks.2.attn.qkv.weight: trainable=True
visual.trunk.blocks.2.attn.qkv.bias: trainable=True
visual.trunk.blocks.2.attn.proj.weight: trainable=True
visual.trunk.blocks.2.attn.proj.bias: trainable=True
visual.trunk.blocks.2.norm2.weight: trainable=True
visual.trunk.blocks.2.norm2.bias: trainable=True
visual.trunk.blocks.2.mlp.fc1.weight: trainable=True
visual.trunk.blocks.2.mlp.fc1.bias: trainable=True
visual.trunk.blocks.2.mlp.fc2.weight: trainable=True
visual.trunk.blocks.2.mlp.fc2.bias: trainable=True
visual.trunk.blocks.3.norm1.weight: trainable=True
visual.trunk.blocks.3.norm1.bias: trainable=True
visual.trunk.blocks.3.attn.qkv.weight: trainable=True
visual.trunk.blocks.3.attn.qkv.bias: trainable=True
visual.trunk.blocks.3.attn.proj.weight: trainable=True
visual.trunk.blocks.3.attn.proj.bias: trainable=True
visual.trunk.blocks.3.norm2.weight: trainable=True
visual.trunk.blocks.3.norm2.bias: trainable=True
visual.trunk.blocks.3.mlp.fc1.weight: trainable=True
visual.trunk.blocks.3.mlp.fc1.bias: trainable=True
visual.trunk.blocks.3.mlp.fc2.weight: trainable=True
visual.trunk.blocks.3.mlp.fc2.bias: trainable=True
visual.trunk.blocks.4.norm1.weight: trainable=True
visual.trunk.blocks.4.norm1.bias: trainable=True
visual.trunk.blocks.4.attn.qkv.weight: trainable=True
visual.trunk.blocks.4.attn.qkv.bias: trainable=True
visual.trunk.blocks.4.attn.proj.weight: trainable=True
visual.trunk.blocks.4.attn.proj.bias: trainable=True
visual.trunk.blocks.4.norm2.weight: trainable=True
visual.trunk.blocks.4.norm2.bias: trainable=True
visual.trunk.blocks.4.mlp.fc1.weight: trainable=True
visual.trunk.blocks.4.mlp.fc1.bias: trainable=True
visual.trunk.blocks.4.mlp.fc2.weight: trainable=True
visual.trunk.blocks.4.mlp.fc2.bias: trainable=True
visual.trunk.blocks.5.norm1.weight: trainable=True
visual.trunk.blocks.5.norm1.bias: trainable=True
visual.trunk.blocks.5.attn.qkv.weight: trainable=True
visual.trunk.blocks.5.attn.qkv.bias: trainable=True
visual.trunk.blocks.5.attn.proj.weight: trainable=True
visual.trunk.blocks.5.attn.proj.bias: trainable=True
visual.trunk.blocks.5.norm2.weight: trainable=True
visual.trunk.blocks.5.norm2.bias: trainable=True
visual.trunk.blocks.5.mlp.fc1.weight: trainable=True
visual.trunk.blocks.5.mlp.fc1.bias: trainable=True
visual.trunk.blocks.5.mlp.fc2.weight: trainable=True
visual.trunk.blocks.5.mlp.fc2.bias: trainable=True
visual.trunk.blocks.6.norm1.weight: trainable=True
visual.trunk.blocks.6.norm1.bias: trainable=True
visual.trunk.blocks.6.attn.qkv.weight: trainable=True
visual.trunk.blocks.6.attn.qkv.bias: trainable=True
visual.trunk.blocks.6.attn.proj.weight: trainable=True
visual.trunk.blocks.6.attn.proj.bias: trainable=True
visual.trunk.blocks.6.norm2.weight: trainable=True
visual.trunk.blocks.6.norm2.bias: trainable=True
visual.trunk.blocks.6.mlp.fc1.weight: trainable=True
visual.trunk.blocks.6.mlp.fc1.bias: trainable=True
visual.trunk.blocks.6.mlp.fc2.weight: trainable=True
visual.trunk.blocks.6.mlp.fc2.bias: trainable=True
visual.trunk.blocks.7.norm1.weight: trainable=True
visual.trunk.blocks.7.norm1.bias: trainable=True
visual.trunk.blocks.7.attn.qkv.weight: trainable=True
visual.trunk.blocks.7.attn.qkv.bias: trainable=True
visual.trunk.blocks.7.attn.proj.weight: trainable=True
visual.trunk.blocks.7.attn.proj.bias: trainable=True
visual.trunk.blocks.7.norm2.weight: trainable=True
visual.trunk.blocks.7.norm2.bias: trainable=True
visual.trunk.blocks.7.mlp.fc1.weight: trainable=True
visual.trunk.blocks.7.mlp.fc1.bias: trainable=True
visual.trunk.blocks.7.mlp.fc2.weight: trainable=True
visual.trunk.blocks.7.mlp.fc2.bias: trainable=True
visual.trunk.blocks.8.norm1.weight: trainable=True
visual.trunk.blocks.8.norm1.bias: trainable=True
visual.trunk.blocks.8.attn.qkv.weight: trainable=True
visual.trunk.blocks.8.attn.qkv.bias: trainable=True
visual.trunk.blocks.8.attn.proj.weight: trainable=True
visual.trunk.blocks.8.attn.proj.bias: trainable=True
visual.trunk.blocks.8.norm2.weight: trainable=True
visual.trunk.blocks.8.norm2.bias: trainable=True
visual.trunk.blocks.8.mlp.fc1.weight: trainable=True
visual.trunk.blocks.8.mlp.fc1.bias: trainable=True
visual.trunk.blocks.8.mlp.fc2.weight: trainable=True
visual.trunk.blocks.8.mlp.fc2.bias: trainable=True
visual.trunk.blocks.9.norm1.weight: trainable=True
visual.trunk.blocks.9.norm1.bias: trainable=True
visual.trunk.blocks.9.attn.qkv.weight: trainable=True
visual.trunk.blocks.9.attn.qkv.bias: trainable=True
visual.trunk.blocks.9.attn.proj.weight: trainable=True
visual.trunk.blocks.9.attn.proj.bias: trainable=True
visual.trunk.blocks.9.norm2.weight: trainable=True
visual.trunk.blocks.9.norm2.bias: trainable=True
visual.trunk.blocks.9.mlp.fc1.weight: trainable=True
visual.trunk.blocks.9.mlp.fc1.bias: trainable=True
visual.trunk.blocks.9.mlp.fc2.weight: trainable=True
visual.trunk.blocks.9.mlp.fc2.bias: trainable=True
visual.trunk.blocks.10.norm1.weight: trainable=True
visual.trunk.blocks.10.norm1.bias: trainable=True
visual.trunk.blocks.10.attn.qkv.weight: trainable=True
visual.trunk.blocks.10.attn.qkv.bias: trainable=True
visual.trunk.blocks.10.attn.proj.weight: trainable=True
visual.trunk.blocks.10.attn.proj.bias: trainable=True
visual.trunk.blocks.10.norm2.weight: trainable=True
visual.trunk.blocks.10.norm2.bias: trainable=True
visual.trunk.blocks.10.mlp.fc1.weight: trainable=True
visual.trunk.blocks.10.mlp.fc1.bias: trainable=True
visual.trunk.blocks.10.mlp.fc2.weight: trainable=True
visual.trunk.blocks.10.mlp.fc2.bias: trainable=True
visual.trunk.blocks.11.norm1.weight: trainable=True
visual.trunk.blocks.11.norm1.bias: trainable=True
visual.trunk.blocks.11.attn.qkv.weight: trainable=True
visual.trunk.blocks.11.attn.qkv.bias: trainable=True
visual.trunk.blocks.11.attn.proj.weight: trainable=True
visual.trunk.blocks.11.attn.proj.bias: trainable=True
visual.trunk.blocks.11.norm2.weight: trainable=True
visual.trunk.blocks.11.norm2.bias: trainable=True
visual.trunk.blocks.11.mlp.fc1.weight: trainable=True
visual.trunk.blocks.11.mlp.fc1.bias: trainable=True
visual.trunk.blocks.11.mlp.fc2.weight: trainable=True
visual.trunk.blocks.11.mlp.fc2.bias: trainable=True
visual.trunk.norm.weight: trainable=True
visual.trunk.norm.bias: trainable=True
visual.head.proj.weight: trainable=True
text.transformer.embeddings.word_embeddings.weight: trainable=True
text.transformer.embeddings.position_embeddings.weight: trainable=True
text.transformer.embeddings.token_type_embeddings.weight: trainable=True
text.transformer.embeddings.LayerNorm.weight: trainable=True
text.transformer.embeddings.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.0.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.0.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.0.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.0.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.0.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.0.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.0.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.0.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.0.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.0.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.0.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.0.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.0.output.dense.weight: trainable=True
text.transformer.encoder.layer.0.output.dense.bias: trainable=True
text.transformer.encoder.layer.0.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.0.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.1.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.1.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.1.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.1.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.1.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.1.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.1.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.1.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.1.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.1.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.1.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.1.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.1.output.dense.weight: trainable=True
text.transformer.encoder.layer.1.output.dense.bias: trainable=True
text.transformer.encoder.layer.1.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.1.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.2.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.2.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.2.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.2.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.2.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.2.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.2.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.2.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.2.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.2.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.2.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.2.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.2.output.dense.weight: trainable=True
text.transformer.encoder.layer.2.output.dense.bias: trainable=True
text.transformer.encoder.layer.2.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.2.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.3.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.3.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.3.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.3.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.3.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.3.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.3.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.3.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.3.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.3.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.3.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.3.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.3.output.dense.weight: trainable=True
text.transformer.encoder.layer.3.output.dense.bias: trainable=True
text.transformer.encoder.layer.3.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.3.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.4.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.4.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.4.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.4.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.4.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.4.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.4.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.4.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.4.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.4.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.4.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.4.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.4.output.dense.weight: trainable=True
text.transformer.encoder.layer.4.output.dense.bias: trainable=True
text.transformer.encoder.layer.4.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.4.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.5.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.5.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.5.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.5.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.5.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.5.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.5.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.5.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.5.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.5.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.5.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.5.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.5.output.dense.weight: trainable=True
text.transformer.encoder.layer.5.output.dense.bias: trainable=True
text.transformer.encoder.layer.5.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.5.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.6.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.6.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.6.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.6.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.6.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.6.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.6.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.6.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.6.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.6.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.6.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.6.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.6.output.dense.weight: trainable=True
text.transformer.encoder.layer.6.output.dense.bias: trainable=True
text.transformer.encoder.layer.6.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.6.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.7.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.7.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.7.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.7.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.7.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.7.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.7.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.7.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.7.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.7.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.7.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.7.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.7.output.dense.weight: trainable=True
text.transformer.encoder.layer.7.output.dense.bias: trainable=True
text.transformer.encoder.layer.7.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.7.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.8.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.8.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.8.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.8.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.8.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.8.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.8.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.8.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.8.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.8.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.8.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.8.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.8.output.dense.weight: trainable=True
text.transformer.encoder.layer.8.output.dense.bias: trainable=True
text.transformer.encoder.layer.8.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.8.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.9.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.9.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.9.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.9.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.9.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.9.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.9.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.9.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.9.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.9.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.9.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.9.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.9.output.dense.weight: trainable=True
text.transformer.encoder.layer.9.output.dense.bias: trainable=True
text.transformer.encoder.layer.9.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.9.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.10.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.10.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.10.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.10.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.10.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.10.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.10.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.10.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.10.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.10.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.10.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.10.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.10.output.dense.weight: trainable=True
text.transformer.encoder.layer.10.output.dense.bias: trainable=True
text.transformer.encoder.layer.10.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.10.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.11.attention.self.query.weight: trainable=True
text.transformer.encoder.layer.11.attention.self.query.bias: trainable=True
text.transformer.encoder.layer.11.attention.self.key.weight: trainable=True
text.transformer.encoder.layer.11.attention.self.key.bias: trainable=True
text.transformer.encoder.layer.11.attention.self.value.weight: trainable=True
text.transformer.encoder.layer.11.attention.self.value.bias: trainable=True
text.transformer.encoder.layer.11.attention.output.dense.weight: trainable=True
text.transformer.encoder.layer.11.attention.output.dense.bias: trainable=True
text.transformer.encoder.layer.11.attention.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.11.attention.output.LayerNorm.bias: trainable=True
text.transformer.encoder.layer.11.intermediate.dense.weight: trainable=True
text.transformer.encoder.layer.11.intermediate.dense.bias: trainable=True
text.transformer.encoder.layer.11.output.dense.weight: trainable=True
text.transformer.encoder.layer.11.output.dense.bias: trainable=True
text.transformer.encoder.layer.11.output.LayerNorm.weight: trainable=True
text.transformer.encoder.layer.11.output.LayerNorm.bias: trainable=True
text.proj.0.weight: trainable=True
text.proj.2.weight: trainable=True
2025-06-07,11:20:54 | INFO | Model:
2025-06-07,11:20:54 | INFO | CustomTextCLIP(
  (visual): TimmModel(
    (trunk): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (patch_drop): Identity()
      (norm_pre): Identity()
      (blocks): Sequential(
        (0): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (1): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (2): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (3): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (4): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (5): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (6): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (7): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (8): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (9): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (10): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (11): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
      )
      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (fc_norm): Identity()
      (head_drop): Dropout(p=0.0, inplace=False)
      (head): Identity()
    )
    (head): Sequential(
      (drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=768, out_features=512, bias=False)
    )
  )
  (text): HFTextEncoder(
    (transformer): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (pooler): ClsLastHiddenStatePooler()
    (proj): Sequential(
      (0): Linear(in_features=768, out_features=640, bias=False)
      (1): GELU(approximate='none')
      (2): Linear(in_features=640, out_features=512, bias=False)
    )
  )
)
2025-06-07,11:20:54 | INFO | Params:
2025-06-07,11:20:54 | INFO |   accum_freq: 1
2025-06-07,11:20:54 | INFO |   aug_cfg: {}
2025-06-07,11:20:54 | INFO |   batch_size: 64
2025-06-07,11:20:54 | INFO |   beta1: 0.9
2025-06-07,11:20:54 | INFO |   beta2: 0.98
2025-06-07,11:20:54 | INFO |   checkpoint_path: ./logs/2025_06_07-11_20_45-model_hf-hub:microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224-lr_0.0001-b_64-j_4-p_amp/checkpoints
2025-06-07,11:20:54 | INFO |   coca_caption_loss_weight: 2.0
2025-06-07,11:20:54 | INFO |   coca_contrastive_loss_weight: 1.0
2025-06-07,11:20:54 | INFO |   copy_codebase: False
2025-06-07,11:20:54 | INFO |   csv_caption_key: title
2025-06-07,11:20:54 | INFO |   csv_img_key: filepath
2025-06-07,11:20:54 | INFO |   csv_separator: 	
2025-06-07,11:20:54 | INFO |   dataset_resampled: False
2025-06-07,11:20:54 | INFO |   dataset_type: IUXray
2025-06-07,11:20:54 | INFO |   ddp_static_graph: False
2025-06-07,11:20:54 | INFO |   debug: False
2025-06-07,11:20:54 | INFO |   delete_previous_checkpoint: False
2025-06-07,11:20:54 | INFO |   device: cuda:0
2025-06-07,11:20:54 | INFO |   dist_backend: nccl
2025-06-07,11:20:54 | INFO |   dist_url: env://
2025-06-07,11:20:54 | INFO |   distill: False
2025-06-07,11:20:54 | INFO |   distill_model: None
2025-06-07,11:20:54 | INFO |   distill_pretrained: None
2025-06-07,11:20:54 | INFO |   distributed: False
2025-06-07,11:20:54 | INFO |   epochs: 360
2025-06-07,11:20:54 | INFO |   epochs_cooldown: None
2025-06-07,11:20:54 | INFO |   eps: 1e-06
2025-06-07,11:20:54 | INFO |   force_custom_text: False
2025-06-07,11:20:54 | INFO |   force_image_size: None
2025-06-07,11:20:54 | INFO |   force_patch_dropout: None
2025-06-07,11:20:54 | INFO |   force_quick_gelu: False
2025-06-07,11:20:54 | INFO |   gather_with_grad: False
2025-06-07,11:20:54 | INFO |   grad_checkpointing: False
2025-06-07,11:20:54 | INFO |   grad_clip_norm: None
2025-06-07,11:20:54 | INFO |   horovod: False
2025-06-07,11:20:54 | INFO |   image_interpolation: None
2025-06-07,11:20:54 | INFO |   image_mean: None
2025-06-07,11:20:54 | INFO |   image_resize_mode: None
2025-06-07,11:20:54 | INFO |   image_std: None
2025-06-07,11:20:54 | INFO |   imagenet_v2: None
2025-06-07,11:20:54 | INFO |   imagenet_val: None
2025-06-07,11:20:54 | INFO |   img_root: /kaggle/input/iu-xray/iu_xray/images
2025-06-07,11:20:54 | INFO |   local_loss: False
2025-06-07,11:20:54 | INFO |   local_rank: 0
2025-06-07,11:20:54 | INFO |   lock_image: False
2025-06-07,11:20:54 | INFO |   lock_image_freeze_bn_stats: False
2025-06-07,11:20:54 | INFO |   lock_image_unlocked_groups: 0
2025-06-07,11:20:54 | INFO |   lock_text: False
2025-06-07,11:20:54 | INFO |   lock_text_freeze_layer_norm: False
2025-06-07,11:20:54 | INFO |   lock_text_unlocked_layers: 0
2025-06-07,11:20:54 | INFO |   log_every_n_steps: 100
2025-06-07,11:20:54 | INFO |   log_level: 20
2025-06-07,11:20:54 | INFO |   log_local: False
2025-06-07,11:20:54 | INFO |   log_path: ./logs/2025_06_07-11_20_45-model_hf-hub:microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224-lr_0.0001-b_64-j_4-p_amp/out.log
2025-06-07,11:20:54 | INFO |   logs: ./logs/
2025-06-07,11:20:54 | INFO |   lr: 0.0001
2025-06-07,11:20:54 | INFO |   lr_cooldown_end: 0.0
2025-06-07,11:20:54 | INFO |   lr_cooldown_power: 1.0
2025-06-07,11:20:54 | INFO |   lr_scheduler: cosine
2025-06-07,11:20:54 | INFO |   model: hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224
2025-06-07,11:20:54 | INFO |   name: 2025_06_07-11_20_45-model_hf-hub:microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224-lr_0.0001-b_64-j_4-p_amp
2025-06-07,11:20:54 | INFO |   no_set_device_rank: False
2025-06-07,11:20:54 | INFO |   precision: amp
2025-06-07,11:20:54 | INFO |   pretrained: 
2025-06-07,11:20:54 | INFO |   pretrained_image: False
2025-06-07,11:20:54 | INFO |   rank: 0
2025-06-07,11:20:54 | INFO |   remote_sync: None
2025-06-07,11:20:54 | INFO |   remote_sync_frequency: 300
2025-06-07,11:20:54 | INFO |   remote_sync_protocol: s3
2025-06-07,11:20:54 | INFO |   report_to: tensorboard
2025-06-07,11:20:54 | INFO |   resume: None
2025-06-07,11:20:54 | INFO |   resume_id: None
2025-06-07,11:20:54 | INFO |   retrieve_output_path: test_retrieve
2025-06-07,11:20:54 | INFO |   retrieve_topk: 1
2025-06-07,11:20:54 | INFO |   save_frequency: 60
2025-06-07,11:20:54 | INFO |   save_most_recent: False
2025-06-07,11:20:54 | INFO |   seed: 0
2025-06-07,11:20:54 | INFO |   siglip: False
2025-06-07,11:20:54 | INFO |   skip_scheduler: False
2025-06-07,11:20:54 | INFO |   tensorboard: True
2025-06-07,11:20:54 | INFO |   tensorboard_path: ./logs/2025_06_07-11_20_45-model_hf-hub:microsoft-BiomedCLIP-PubMedBERT_256-vit_base_patch16_224-lr_0.0001-b_64-j_4-p_amp/tensorboard
2025-06-07,11:20:54 | INFO |   torchcompile: False
2025-06-07,11:20:54 | INFO |   torchscript: False
2025-06-07,11:20:54 | INFO |   trace: False
2025-06-07,11:20:54 | INFO |   train_data: /kaggle/input/iu-xray-json-rule/iu_xray_json_rule/iuxray_train.json
2025-06-07,11:20:54 | INFO |   train_data_upsampling_factors: None
2025-06-07,11:20:54 | INFO |   train_num_samples: None
2025-06-07,11:20:54 | INFO |   use_bn_sync: False
2025-06-07,11:20:54 | INFO |   use_bnb_linear: None
2025-06-07,11:20:54 | INFO |   val_data: /kaggle/input/iu-xray-json-rule/iu_xray_json_rule/iuxray_val.json
2025-06-07,11:20:54 | INFO |   val_frequency: 10
2025-06-07,11:20:54 | INFO |   val_num_samples: None
2025-06-07,11:20:54 | INFO |   wandb: False
2025-06-07,11:20:54 | INFO |   wandb_notes: 
2025-06-07,11:20:54 | INFO |   wandb_project_name: open-clip
2025-06-07,11:20:54 | INFO |   warmup: 10000
2025-06-07,11:20:54 | INFO |   wd: 0.2
2025-06-07,11:20:54 | INFO |   workers: 4
2025-06-07,11:20:54 | INFO |   world_size: 1
2025-06-07,11:20:54 | INFO |   zeroshot_frequency: 2
/kaggle/usr/lib/open_clip_training_rule/open_clip_training_rule.py:572: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler() if args.precision == "amp" else None
Downloading 'tokenizer_config.json' to '/root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/a661b1a138dac6dc5590367402d100765010ffd6.incomplete'
2025-06-07,11:20:54 | INFO | Downloading 'tokenizer_config.json' to '/root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/a661b1a138dac6dc5590367402d100765010ffd6.incomplete'
tokenizer_config.json: 100%|██████████████████| 28.0/28.0 [00:00<00:00, 237kB/s]
Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/a661b1a138dac6dc5590367402d100765010ffd6
2025-06-07,11:20:54 | INFO | Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/a661b1a138dac6dc5590367402d100765010ffd6
loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d/config.json
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.51.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

Downloading 'vocab.txt' to '/root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/9d65c8495e044c70ce1a30e2ae8e2f0b3738dbae.incomplete'
2025-06-07,11:20:54 | INFO | Downloading 'vocab.txt' to '/root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/9d65c8495e044c70ce1a30e2ae8e2f0b3738dbae.incomplete'
vocab.txt: 100%|█████████████████████████████| 225k/225k [00:00<00:00, 1.91MB/s]
Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/9d65c8495e044c70ce1a30e2ae8e2f0b3738dbae
2025-06-07,11:20:54 | INFO | Download complete. Moving file to /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/blobs/9d65c8495e044c70ce1a30e2ae8e2f0b3738dbae
loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d/vocab.txt
loading file tokenizer.json from cache at None
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at None
loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d/tokenizer_config.json
loading file chat_template.jinja from cache at None
loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d/config.json
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.51.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d/config.json
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.51.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2025-06-07,11:20:55 | INFO | Start epoch 0
/kaggle/usr/lib/open_clip_training_rule_utils/open_clip_training_rule_utils.py:3085: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
2025-06-07,11:21:00 | INFO | Train Epoch: 0 [  64/1034 (6%)] Data (t): 1.861 Batch (t): 5.283, 12.1145/s, 12.1145/s/gpu LR: 0.000000 Logit Scale: 85.232 Contrastive_loss: 5.9337 (5.9337) Loss: 5.9337 (5.9337)
2025-06-07,11:21:16 | INFO | Train Epoch: 0 [1024/1034 (100%)] Data (t): 0.001 Batch (t): 1.036, 60.8168/s, 60.8168/s/gpu LR: 0.000000 Logit Scale: 85.232 Contrastive_loss: 6.0430 (5.9884) Loss: 6.0430 (5.9884)
2025-06-07,11:21:16 | INFO | Start epoch 1
2025-06-07,11:21:19 | INFO | Train Epoch: 1 [  64/1034 (6%)] Data (t): 1.940 Batch (t): 3.018, 21.2041/s, 21.2041/s/gpu LR: 0.000000 Logit Scale: 85.232 Contrastive_loss: 5.6064 (5.6064) Loss: 5.6064 (5.6064)
2025-06-07,11:21:35 | INFO | Train Epoch: 1 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.066, 58.9131/s, 58.9131/s/gpu LR: 0.000000 Logit Scale: 85.232 Contrastive_loss: 5.6635 (5.6349) Loss: 5.6635 (5.6349)
2025-06-07,11:21:35 | INFO | Start epoch 2
2025-06-07,11:21:37 | INFO | Train Epoch: 2 [  64/1034 (6%)] Data (t): 1.179 Batch (t): 2.222, 28.8067/s, 28.8067/s/gpu LR: 0.000000 Logit Scale: 85.232 Contrastive_loss: 5.3656 (5.3656) Loss: 5.3656 (5.3656)
2025-06-07,11:21:54 | INFO | Train Epoch: 2 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.100, 57.4306/s, 57.4306/s/gpu LR: 0.000000 Logit Scale: 85.231 Contrastive_loss: 5.7626 (5.5641) Loss: 5.7626 (5.5641)
2025-06-07,11:21:54 | INFO | Start epoch 3
2025-06-07,11:21:56 | INFO | Train Epoch: 3 [  64/1034 (6%)] Data (t): 1.260 Batch (t): 2.328, 27.4919/s, 27.4919/s/gpu LR: 0.000000 Logit Scale: 85.231 Contrastive_loss: 6.1198 (6.1198) Loss: 6.1198 (6.1198)
2025-06-07,11:22:13 | INFO | Train Epoch: 3 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.132, 55.6995/s, 55.6995/s/gpu LR: 0.000001 Logit Scale: 85.231 Contrastive_loss: 5.4364 (5.7781) Loss: 5.4364 (5.7781)
2025-06-07,11:22:13 | INFO | Start epoch 4
2025-06-07,11:22:16 | INFO | Train Epoch: 4 [  64/1034 (6%)] Data (t): 1.269 Batch (t): 2.356, 27.1619/s, 27.1619/s/gpu LR: 0.000001 Logit Scale: 85.231 Contrastive_loss: 5.0719 (5.0719) Loss: 5.0719 (5.0719)
2025-06-07,11:22:33 | INFO | Train Epoch: 4 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.165, 54.4318/s, 54.4318/s/gpu LR: 0.000001 Logit Scale: 85.230 Contrastive_loss: 4.9008 (4.9864) Loss: 4.9008 (4.9864)
2025-06-07,11:22:33 | INFO | Start epoch 5
2025-06-07,11:22:36 | INFO | Train Epoch: 5 [  64/1034 (6%)] Data (t): 1.227 Batch (t): 2.358, 27.1459/s, 27.1459/s/gpu LR: 0.000001 Logit Scale: 85.230 Contrastive_loss: 4.7732 (4.7732) Loss: 4.7732 (4.7732)
2025-06-07,11:22:54 | INFO | Train Epoch: 5 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.198, 52.8497/s, 52.8497/s/gpu LR: 0.000001 Logit Scale: 85.229 Contrastive_loss: 4.5220 (4.6476) Loss: 4.5220 (4.6476)
2025-06-07,11:22:54 | INFO | Start epoch 6
2025-06-07,11:22:56 | INFO | Train Epoch: 6 [  64/1034 (6%)] Data (t): 1.222 Batch (t): 2.396, 26.7158/s, 26.7158/s/gpu LR: 0.000001 Logit Scale: 85.229 Contrastive_loss: 4.7865 (4.7865) Loss: 4.7865 (4.7865)
2025-06-07,11:23:15 | INFO | Train Epoch: 6 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.239, 51.0336/s, 51.0336/s/gpu LR: 0.000001 Logit Scale: 85.229 Contrastive_loss: 4.5035 (4.6450) Loss: 4.5035 (4.6450)
2025-06-07,11:23:15 | INFO | Start epoch 7
2025-06-07,11:23:17 | INFO | Train Epoch: 7 [  64/1034 (6%)] Data (t): 1.245 Batch (t): 2.457, 26.0528/s, 26.0528/s/gpu LR: 0.000001 Logit Scale: 85.229 Contrastive_loss: 4.3679 (4.3679) Loss: 4.3679 (4.3679)
2025-06-07,11:23:37 | INFO | Train Epoch: 7 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.290, 49.3379/s, 49.3379/s/gpu LR: 0.000001 Logit Scale: 85.228 Contrastive_loss: 4.0098 (4.1889) Loss: 4.0098 (4.1889)
2025-06-07,11:23:37 | INFO | Start epoch 8
2025-06-07,11:23:39 | INFO | Train Epoch: 8 [  64/1034 (6%)] Data (t): 1.181 Batch (t): 2.421, 26.4368/s, 26.4368/s/gpu LR: 0.000001 Logit Scale: 85.228 Contrastive_loss: 4.3756 (4.3756) Loss: 4.3756 (4.3756)
2025-06-07,11:23:58 | INFO | Train Epoch: 8 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 51.0824/s, 51.0824/s/gpu LR: 0.000001 Logit Scale: 85.227 Contrastive_loss: 3.9417 (4.1587) Loss: 3.9417 (4.1587)
2025-06-07,11:23:58 | INFO | Start epoch 9
2025-06-07,11:24:01 | INFO | Train Epoch: 9 [  64/1034 (6%)] Data (t): 1.178 Batch (t): 2.388, 26.8024/s, 26.8024/s/gpu LR: 0.000001 Logit Scale: 85.227 Contrastive_loss: 3.9754 (3.9754) Loss: 3.9754 (3.9754)
2025-06-07,11:24:20 | INFO | Train Epoch: 9 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9434/s, 50.9434/s/gpu LR: 0.000002 Logit Scale: 85.227 Contrastive_loss: 4.1321 (4.0538) Loss: 4.1321 (4.0538)
/kaggle/usr/lib/open_clip_training_rule_utils/open_clip_training_rule_utils.py:3265: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
2025-06-07,11:24:22 | INFO | Eval Epoch: 10 [64 / 1035]	Clip Loss: 4.150341	
2025-06-07,11:24:28 | INFO | Eval Epoch: 10 image_to_text_mean_rank: 392.2908	image_to_text_median_rank: 347.0000	image_to_text_R@1: 0.0048	image_to_text_R@5: 0.0184	image_to_text_R@10: 0.0444	text_to_image_mean_rank: 387.2058	text_to_image_median_rank: 342.0000	text_to_image_R@1: 0.0058	text_to_image_R@5: 0.0261	text_to_image_R@10: 0.0415	clip_val_loss: 4.1245	epoch: 10.0000	num_samples: 1035.0000
2025-06-07,11:24:28 | INFO | Start epoch 10
2025-06-07,11:24:31 | INFO | Train Epoch: 10 [  64/1034 (6%)] Data (t): 1.284 Batch (t): 2.472, 25.8913/s, 25.8913/s/gpu LR: 0.000002 Logit Scale: 85.227 Contrastive_loss: 3.7293 (3.7293) Loss: 3.7293 (3.7293)
2025-06-07,11:24:50 | INFO | Train Epoch: 10 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.265, 50.3348/s, 50.3348/s/gpu LR: 0.000002 Logit Scale: 85.226 Contrastive_loss: 3.9060 (3.8176) Loss: 3.9060 (3.8176)
2025-06-07,11:24:50 | INFO | Start epoch 11
2025-06-07,11:24:53 | INFO | Train Epoch: 11 [  64/1034 (6%)] Data (t): 1.216 Batch (t): 2.426, 26.3846/s, 26.3846/s/gpu LR: 0.000002 Logit Scale: 85.226 Contrastive_loss: 3.8837 (3.8837) Loss: 3.8837 (3.8837)
2025-06-07,11:25:12 | INFO | Train Epoch: 11 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.1864/s, 50.1864/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 4.0223 (3.9530) Loss: 4.0223 (3.9530)
2025-06-07,11:25:12 | INFO | Start epoch 12
2025-06-07,11:25:14 | INFO | Train Epoch: 12 [  64/1034 (6%)] Data (t): 1.392 Batch (t): 2.606, 24.5629/s, 24.5629/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.8714 (3.8714) Loss: 3.8714 (3.8714)
2025-06-07,11:25:33 | INFO | Train Epoch: 12 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 51.0502/s, 51.0502/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.9496 (3.9105) Loss: 3.9496 (3.9105)
2025-06-07,11:25:33 | INFO | Start epoch 13
2025-06-07,11:25:36 | INFO | Train Epoch: 13 [  64/1034 (6%)] Data (t): 1.145 Batch (t): 2.355, 27.1811/s, 27.1811/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.6360 (3.6360) Loss: 3.6360 (3.6360)
2025-06-07,11:25:55 | INFO | Train Epoch: 13 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0351/s, 51.0351/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.6300 (3.6330) Loss: 3.6300 (3.6330)
2025-06-07,11:25:55 | INFO | Start epoch 14
2025-06-07,11:25:57 | INFO | Train Epoch: 14 [  64/1034 (6%)] Data (t): 1.248 Batch (t): 2.438, 26.2468/s, 26.2468/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.6476 (3.6476) Loss: 3.6476 (3.6476)
2025-06-07,11:26:16 | INFO | Train Epoch: 14 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.265, 50.2076/s, 50.2076/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.4875 (3.5676) Loss: 3.4875 (3.5676)
2025-06-07,11:26:16 | INFO | Start epoch 15
2025-06-07,11:26:19 | INFO | Train Epoch: 15 [  64/1034 (6%)] Data (t): 1.291 Batch (t): 2.486, 25.7487/s, 25.7487/s/gpu LR: 0.000002 Logit Scale: 85.225 Contrastive_loss: 3.5196 (3.5196) Loss: 3.5196 (3.5196)
2025-06-07,11:26:38 | INFO | Train Epoch: 15 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.2237/s, 50.2237/s/gpu LR: 0.000003 Logit Scale: 85.225 Contrastive_loss: 3.4842 (3.5019) Loss: 3.4842 (3.5019)
2025-06-07,11:26:38 | INFO | Start epoch 16
2025-06-07,11:26:40 | INFO | Train Epoch: 16 [  64/1034 (6%)] Data (t): 1.207 Batch (t): 2.434, 26.2965/s, 26.2965/s/gpu LR: 0.000003 Logit Scale: 85.225 Contrastive_loss: 3.4200 (3.4200) Loss: 3.4200 (3.4200)
2025-06-07,11:26:59 | INFO | Train Epoch: 16 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.3308/s, 50.3308/s/gpu LR: 0.000003 Logit Scale: 85.226 Contrastive_loss: 3.5955 (3.5077) Loss: 3.5955 (3.5077)
2025-06-07,11:27:00 | INFO | Start epoch 17
2025-06-07,11:27:02 | INFO | Train Epoch: 17 [  64/1034 (6%)] Data (t): 1.260 Batch (t): 2.462, 25.9949/s, 25.9949/s/gpu LR: 0.000003 Logit Scale: 85.226 Contrastive_loss: 2.8699 (2.8699) Loss: 2.8699 (2.8699)
2025-06-07,11:27:21 | INFO | Train Epoch: 17 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.2485/s, 50.2485/s/gpu LR: 0.000003 Logit Scale: 85.227 Contrastive_loss: 3.1499 (3.0099) Loss: 3.1499 (3.0099)
2025-06-07,11:27:21 | INFO | Start epoch 18
2025-06-07,11:27:24 | INFO | Train Epoch: 18 [  64/1034 (6%)] Data (t): 1.351 Batch (t): 2.548, 25.1134/s, 25.1134/s/gpu LR: 0.000003 Logit Scale: 85.227 Contrastive_loss: 3.1495 (3.1495) Loss: 3.1495 (3.1495)
2025-06-07,11:27:43 | INFO | Train Epoch: 18 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.1646/s, 50.1646/s/gpu LR: 0.000003 Logit Scale: 85.228 Contrastive_loss: 3.2837 (3.2166) Loss: 3.2837 (3.2166)
2025-06-07,11:27:43 | INFO | Start epoch 19
2025-06-07,11:27:45 | INFO | Train Epoch: 19 [  64/1034 (6%)] Data (t): 1.199 Batch (t): 2.414, 26.5134/s, 26.5134/s/gpu LR: 0.000003 Logit Scale: 85.228 Contrastive_loss: 3.0656 (3.0656) Loss: 3.0656 (3.0656)
2025-06-07,11:28:04 | INFO | Train Epoch: 19 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.272, 50.2293/s, 50.2293/s/gpu LR: 0.000003 Logit Scale: 85.229 Contrastive_loss: 2.9596 (3.0126) Loss: 2.9596 (3.0126)
2025-06-07,11:28:06 | INFO | Eval Epoch: 20 [64 / 1035]	Clip Loss: 4.221076	
2025-06-07,11:28:13 | INFO | Eval Epoch: 20 image_to_text_mean_rank: 310.6744	image_to_text_median_rank: 237.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0357	image_to_text_R@10: 0.0676	text_to_image_mean_rank: 305.0377	text_to_image_median_rank: 233.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0444	text_to_image_R@10: 0.0744	clip_val_loss: 4.0498	epoch: 20.0000	num_samples: 1035.0000
2025-06-07,11:28:13 | INFO | Start epoch 20
2025-06-07,11:28:15 | INFO | Train Epoch: 20 [  64/1034 (6%)] Data (t): 1.319 Batch (t): 2.517, 25.4281/s, 25.4281/s/gpu LR: 0.000003 Logit Scale: 85.230 Contrastive_loss: 2.8382 (2.8382) Loss: 2.8382 (2.8382)
2025-06-07,11:28:35 | INFO | Train Epoch: 20 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.274, 50.1153/s, 50.1153/s/gpu LR: 0.000003 Logit Scale: 85.232 Contrastive_loss: 2.6256 (2.7319) Loss: 2.6256 (2.7319)
2025-06-07,11:28:35 | INFO | Start epoch 21
2025-06-07,11:28:37 | INFO | Train Epoch: 21 [  64/1034 (6%)] Data (t): 1.265 Batch (t): 2.462, 25.9966/s, 25.9966/s/gpu LR: 0.000003 Logit Scale: 85.232 Contrastive_loss: 2.4694 (2.4694) Loss: 2.4694 (2.4694)
2025-06-07,11:28:56 | INFO | Train Epoch: 21 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.2576/s, 50.2576/s/gpu LR: 0.000004 Logit Scale: 85.234 Contrastive_loss: 2.6574 (2.5634) Loss: 2.6574 (2.5634)
2025-06-07,11:28:56 | INFO | Start epoch 22
2025-06-07,11:28:59 | INFO | Train Epoch: 22 [  64/1034 (6%)] Data (t): 1.266 Batch (t): 2.471, 25.8979/s, 25.8979/s/gpu LR: 0.000004 Logit Scale: 85.235 Contrastive_loss: 2.5383 (2.5383) Loss: 2.5383 (2.5383)
2025-06-07,11:29:18 | INFO | Train Epoch: 22 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.2812/s, 50.2812/s/gpu LR: 0.000004 Logit Scale: 85.237 Contrastive_loss: 2.3212 (2.4297) Loss: 2.3212 (2.4297)
2025-06-07,11:29:18 | INFO | Start epoch 23
2025-06-07,11:29:21 | INFO | Train Epoch: 23 [  64/1034 (6%)] Data (t): 1.344 Batch (t): 2.550, 25.1011/s, 25.1011/s/gpu LR: 0.000004 Logit Scale: 85.237 Contrastive_loss: 2.2599 (2.2599) Loss: 2.2599 (2.2599)
2025-06-07,11:29:40 | INFO | Train Epoch: 23 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.1579/s, 50.1579/s/gpu LR: 0.000004 Logit Scale: 85.240 Contrastive_loss: 2.4246 (2.3422) Loss: 2.4246 (2.3422)
2025-06-07,11:29:40 | INFO | Start epoch 24
2025-06-07,11:29:42 | INFO | Train Epoch: 24 [  64/1034 (6%)] Data (t): 1.294 Batch (t): 2.519, 25.4069/s, 25.4069/s/gpu LR: 0.000004 Logit Scale: 85.240 Contrastive_loss: 2.1918 (2.1918) Loss: 2.1918 (2.1918)
2025-06-07,11:30:01 | INFO | Train Epoch: 24 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.3733/s, 50.3733/s/gpu LR: 0.000004 Logit Scale: 85.244 Contrastive_loss: 1.9181 (2.0550) Loss: 1.9181 (2.0550)
2025-06-07,11:30:01 | INFO | Start epoch 25
2025-06-07,11:30:04 | INFO | Train Epoch: 25 [  64/1034 (6%)] Data (t): 1.296 Batch (t): 2.508, 25.5210/s, 25.5210/s/gpu LR: 0.000004 Logit Scale: 85.244 Contrastive_loss: 1.9504 (1.9504) Loss: 1.9504 (1.9504)
2025-06-07,11:30:23 | INFO | Train Epoch: 25 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.1187/s, 50.1187/s/gpu LR: 0.000004 Logit Scale: 85.248 Contrastive_loss: 2.4292 (2.1898) Loss: 2.4292 (2.1898)
2025-06-07,11:30:23 | INFO | Start epoch 26
2025-06-07,11:30:26 | INFO | Train Epoch: 26 [  64/1034 (6%)] Data (t): 1.238 Batch (t): 2.440, 26.2261/s, 26.2261/s/gpu LR: 0.000004 Logit Scale: 85.249 Contrastive_loss: 1.6563 (1.6563) Loss: 1.6563 (1.6563)
2025-06-07,11:30:45 | INFO | Train Epoch: 26 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.2778/s, 50.2778/s/gpu LR: 0.000004 Logit Scale: 85.253 Contrastive_loss: 2.0765 (1.8664) Loss: 2.0765 (1.8664)
2025-06-07,11:30:45 | INFO | Start epoch 27
2025-06-07,11:30:48 | INFO | Train Epoch: 27 [  64/1034 (6%)] Data (t): 1.579 Batch (t): 2.798, 22.8707/s, 22.8707/s/gpu LR: 0.000004 Logit Scale: 85.253 Contrastive_loss: 1.5716 (1.5716) Loss: 1.5716 (1.5716)
2025-06-07,11:31:07 | INFO | Train Epoch: 27 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.3024/s, 50.3024/s/gpu LR: 0.000004 Logit Scale: 85.258 Contrastive_loss: 1.7468 (1.6592) Loss: 1.7468 (1.6592)
2025-06-07,11:31:07 | INFO | Start epoch 28
2025-06-07,11:31:09 | INFO | Train Epoch: 28 [  64/1034 (6%)] Data (t): 1.291 Batch (t): 2.499, 25.6080/s, 25.6080/s/gpu LR: 0.000004 Logit Scale: 85.258 Contrastive_loss: 1.8374 (1.8374) Loss: 1.8374 (1.8374)
2025-06-07,11:31:29 | INFO | Train Epoch: 28 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.274, 50.2410/s, 50.2410/s/gpu LR: 0.000005 Logit Scale: 85.262 Contrastive_loss: 1.5811 (1.7093) Loss: 1.5811 (1.7093)
2025-06-07,11:31:29 | INFO | Start epoch 29
2025-06-07,11:31:31 | INFO | Train Epoch: 29 [  64/1034 (6%)] Data (t): 1.226 Batch (t): 2.442, 26.2129/s, 26.2129/s/gpu LR: 0.000005 Logit Scale: 85.262 Contrastive_loss: 1.2376 (1.2376) Loss: 1.2376 (1.2376)
2025-06-07,11:31:50 | INFO | Train Epoch: 29 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.3013/s, 50.3013/s/gpu LR: 0.000005 Logit Scale: 85.267 Contrastive_loss: 1.3980 (1.3178) Loss: 1.3980 (1.3178)
2025-06-07,11:31:52 | INFO | Eval Epoch: 30 [64 / 1035]	Clip Loss: 5.984807	
2025-06-07,11:31:58 | INFO | Eval Epoch: 30 image_to_text_mean_rank: 307.7092	image_to_text_median_rank: 229.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0425	image_to_text_R@10: 0.0715	text_to_image_mean_rank: 298.3768	text_to_image_median_rank: 224.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0415	text_to_image_R@10: 0.0763	clip_val_loss: 5.5297	epoch: 30.0000	num_samples: 1035.0000
2025-06-07,11:31:58 | INFO | Start epoch 30
2025-06-07,11:32:01 | INFO | Train Epoch: 30 [  64/1034 (6%)] Data (t): 1.216 Batch (t): 2.426, 26.3764/s, 26.3764/s/gpu LR: 0.000005 Logit Scale: 85.267 Contrastive_loss: 1.3033 (1.3033) Loss: 1.3033 (1.3033)
2025-06-07,11:32:20 | INFO | Train Epoch: 30 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.267, 50.3146/s, 50.3146/s/gpu LR: 0.000005 Logit Scale: 85.271 Contrastive_loss: 1.4031 (1.3532) Loss: 1.4031 (1.3532)
2025-06-07,11:32:20 | INFO | Start epoch 31
2025-06-07,11:32:23 | INFO | Train Epoch: 31 [  64/1034 (6%)] Data (t): 1.468 Batch (t): 2.678, 23.8981/s, 23.8981/s/gpu LR: 0.000005 Logit Scale: 85.271 Contrastive_loss: 1.3292 (1.3292) Loss: 1.3292 (1.3292)
2025-06-07,11:32:42 | INFO | Train Epoch: 31 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.271, 50.2752/s, 50.2752/s/gpu LR: 0.000005 Logit Scale: 85.276 Contrastive_loss: 0.82597 (1.0776) Loss: 0.82597 (1.0776)
2025-06-07,11:32:42 | INFO | Start epoch 32
2025-06-07,11:32:44 | INFO | Train Epoch: 32 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.442, 26.2105/s, 26.2105/s/gpu LR: 0.000005 Logit Scale: 85.277 Contrastive_loss: 0.98616 (0.98616) Loss: 0.98616 (0.98616)
2025-06-07,11:33:04 | INFO | Train Epoch: 32 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.274, 50.1299/s, 50.1299/s/gpu LR: 0.000005 Logit Scale: 85.282 Contrastive_loss: 0.85538 (0.92077) Loss: 0.85538 (0.92077)
2025-06-07,11:33:04 | INFO | Start epoch 33
2025-06-07,11:33:06 | INFO | Train Epoch: 33 [  64/1034 (6%)] Data (t): 1.143 Batch (t): 2.354, 27.1856/s, 27.1856/s/gpu LR: 0.000005 Logit Scale: 85.283 Contrastive_loss: 0.78973 (0.78973) Loss: 0.78973 (0.78973)
2025-06-07,11:33:25 | INFO | Train Epoch: 33 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.272, 50.2753/s, 50.2753/s/gpu LR: 0.000005 Logit Scale: 85.287 Contrastive_loss: 0.99807 (0.89390) Loss: 0.99807 (0.89390)
2025-06-07,11:33:25 | INFO | Start epoch 34
2025-06-07,11:33:28 | INFO | Train Epoch: 34 [  64/1034 (6%)] Data (t): 1.190 Batch (t): 2.407, 26.5913/s, 26.5913/s/gpu LR: 0.000005 Logit Scale: 85.287 Contrastive_loss: 0.79312 (0.79312) Loss: 0.79312 (0.79312)
2025-06-07,11:33:47 | INFO | Train Epoch: 34 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.3180/s, 50.3180/s/gpu LR: 0.000006 Logit Scale: 85.292 Contrastive_loss: 0.73349 (0.76330) Loss: 0.73349 (0.76330)
2025-06-07,11:33:47 | INFO | Start epoch 35
2025-06-07,11:33:49 | INFO | Train Epoch: 35 [  64/1034 (6%)] Data (t): 1.174 Batch (t): 2.389, 26.7906/s, 26.7906/s/gpu LR: 0.000006 Logit Scale: 85.293 Contrastive_loss: 0.49165 (0.49165) Loss: 0.49165 (0.49165)
2025-06-07,11:34:08 | INFO | Train Epoch: 35 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.2510/s, 50.2510/s/gpu LR: 0.000006 Logit Scale: 85.299 Contrastive_loss: 0.57423 (0.53294) Loss: 0.57423 (0.53294)
2025-06-07,11:34:08 | INFO | Start epoch 36
2025-06-07,11:34:11 | INFO | Train Epoch: 36 [  64/1034 (6%)] Data (t): 1.250 Batch (t): 2.440, 26.2274/s, 26.2274/s/gpu LR: 0.000006 Logit Scale: 85.299 Contrastive_loss: 0.55038 (0.55038) Loss: 0.55038 (0.55038)
2025-06-07,11:34:30 | INFO | Train Epoch: 36 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.2551/s, 50.2551/s/gpu LR: 0.000006 Logit Scale: 85.302 Contrastive_loss: 0.75385 (0.65212) Loss: 0.75385 (0.65212)
2025-06-07,11:34:30 | INFO | Start epoch 37
2025-06-07,11:34:33 | INFO | Train Epoch: 37 [  64/1034 (6%)] Data (t): 1.282 Batch (t): 2.482, 25.7816/s, 25.7816/s/gpu LR: 0.000006 Logit Scale: 85.302 Contrastive_loss: 0.60704 (0.60704) Loss: 0.60704 (0.60704)
2025-06-07,11:34:52 | INFO | Train Epoch: 37 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.2497/s, 50.2497/s/gpu LR: 0.000006 Logit Scale: 85.306 Contrastive_loss: 0.75066 (0.67885) Loss: 0.75066 (0.67885)
2025-06-07,11:34:52 | INFO | Start epoch 38
2025-06-07,11:34:54 | INFO | Train Epoch: 38 [  64/1034 (6%)] Data (t): 1.177 Batch (t): 2.386, 26.8186/s, 26.8186/s/gpu LR: 0.000006 Logit Scale: 85.306 Contrastive_loss: 0.44882 (0.44882) Loss: 0.44882 (0.44882)
2025-06-07,11:35:13 | INFO | Train Epoch: 38 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.2881/s, 50.2881/s/gpu LR: 0.000006 Logit Scale: 85.311 Contrastive_loss: 0.69269 (0.57075) Loss: 0.69269 (0.57075)
2025-06-07,11:35:13 | INFO | Start epoch 39
2025-06-07,11:35:16 | INFO | Train Epoch: 39 [  64/1034 (6%)] Data (t): 1.178 Batch (t): 2.380, 26.8924/s, 26.8924/s/gpu LR: 0.000006 Logit Scale: 85.311 Contrastive_loss: 0.39618 (0.39618) Loss: 0.39618 (0.39618)
2025-06-07,11:35:35 | INFO | Train Epoch: 39 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.271, 50.1808/s, 50.1808/s/gpu LR: 0.000006 Logit Scale: 85.315 Contrastive_loss: 0.47529 (0.43573) Loss: 0.47529 (0.43573)
2025-06-07,11:35:37 | INFO | Eval Epoch: 40 [64 / 1035]	Clip Loss: 7.535244	
2025-06-07,11:35:43 | INFO | Eval Epoch: 40 image_to_text_mean_rank: 311.4039	image_to_text_median_rank: 238.0000	image_to_text_R@1: 0.0068	image_to_text_R@5: 0.0367	image_to_text_R@10: 0.0676	text_to_image_mean_rank: 302.5816	text_to_image_median_rank: 239.0000	text_to_image_R@1: 0.0106	text_to_image_R@5: 0.0483	text_to_image_R@10: 0.0763	clip_val_loss: 7.4020	epoch: 40.0000	num_samples: 1035.0000
2025-06-07,11:35:43 | INFO | Start epoch 40
2025-06-07,11:35:46 | INFO | Train Epoch: 40 [  64/1034 (6%)] Data (t): 1.271 Batch (t): 2.469, 25.9260/s, 25.9260/s/gpu LR: 0.000006 Logit Scale: 85.316 Contrastive_loss: 0.51878 (0.51878) Loss: 0.51878 (0.51878)
2025-06-07,11:36:05 | INFO | Train Epoch: 40 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.2742/s, 50.2742/s/gpu LR: 0.000007 Logit Scale: 85.318 Contrastive_loss: 0.54156 (0.53017) Loss: 0.54156 (0.53017)
2025-06-07,11:36:05 | INFO | Start epoch 41
2025-06-07,11:36:07 | INFO | Train Epoch: 41 [  64/1034 (6%)] Data (t): 1.203 Batch (t): 2.414, 26.5078/s, 26.5078/s/gpu LR: 0.000007 Logit Scale: 85.319 Contrastive_loss: 0.30726 (0.30726) Loss: 0.30726 (0.30726)
2025-06-07,11:36:26 | INFO | Train Epoch: 41 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.274, 50.1558/s, 50.1558/s/gpu LR: 0.000007 Logit Scale: 85.322 Contrastive_loss: 0.41122 (0.35924) Loss: 0.41122 (0.35924)
2025-06-07,11:36:27 | INFO | Start epoch 42
2025-06-07,11:36:29 | INFO | Train Epoch: 42 [  64/1034 (6%)] Data (t): 1.243 Batch (t): 2.442, 26.2027/s, 26.2027/s/gpu LR: 0.000007 Logit Scale: 85.322 Contrastive_loss: 0.56814 (0.56814) Loss: 0.56814 (0.56814)
2025-06-07,11:36:48 | INFO | Train Epoch: 42 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.274, 50.2715/s, 50.2715/s/gpu LR: 0.000007 Logit Scale: 85.326 Contrastive_loss: 0.39585 (0.48199) Loss: 0.39585 (0.48199)
2025-06-07,11:36:48 | INFO | Start epoch 43
2025-06-07,11:36:51 | INFO | Train Epoch: 43 [  64/1034 (6%)] Data (t): 1.259 Batch (t): 2.462, 25.9966/s, 25.9966/s/gpu LR: 0.000007 Logit Scale: 85.326 Contrastive_loss: 0.19166 (0.19166) Loss: 0.19166 (0.19166)
2025-06-07,11:37:10 | INFO | Train Epoch: 43 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.3213/s, 50.3213/s/gpu LR: 0.000007 Logit Scale: 85.331 Contrastive_loss: 0.40703 (0.29935) Loss: 0.40703 (0.29935)
2025-06-07,11:37:10 | INFO | Start epoch 44
2025-06-07,11:37:13 | INFO | Train Epoch: 44 [  64/1034 (6%)] Data (t): 1.919 Batch (t): 3.163, 20.2332/s, 20.2332/s/gpu LR: 0.000007 Logit Scale: 85.331 Contrastive_loss: 0.35087 (0.35087) Loss: 0.35087 (0.35087)
2025-06-07,11:37:32 | INFO | Train Epoch: 44 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.266, 50.1618/s, 50.1618/s/gpu LR: 0.000007 Logit Scale: 85.335 Contrastive_loss: 0.21312 (0.28200) Loss: 0.21312 (0.28200)
2025-06-07,11:37:32 | INFO | Start epoch 45
2025-06-07,11:37:35 | INFO | Train Epoch: 45 [  64/1034 (6%)] Data (t): 1.322 Batch (t): 2.518, 25.4198/s, 25.4198/s/gpu LR: 0.000007 Logit Scale: 85.335 Contrastive_loss: 0.25221 (0.25221) Loss: 0.25221 (0.25221)
2025-06-07,11:37:54 | INFO | Train Epoch: 45 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.2902/s, 50.2902/s/gpu LR: 0.000007 Logit Scale: 85.340 Contrastive_loss: 0.33264 (0.29243) Loss: 0.33264 (0.29243)
2025-06-07,11:37:54 | INFO | Start epoch 46
2025-06-07,11:37:56 | INFO | Train Epoch: 46 [  64/1034 (6%)] Data (t): 1.265 Batch (t): 2.460, 26.0156/s, 26.0156/s/gpu LR: 0.000007 Logit Scale: 85.340 Contrastive_loss: 0.28091 (0.28091) Loss: 0.28091 (0.28091)
2025-06-07,11:38:16 | INFO | Train Epoch: 46 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.2881/s, 50.2881/s/gpu LR: 0.000008 Logit Scale: 85.342 Contrastive_loss: 0.25093 (0.26592) Loss: 0.25093 (0.26592)
2025-06-07,11:38:16 | INFO | Start epoch 47
2025-06-07,11:38:18 | INFO | Train Epoch: 47 [  64/1034 (6%)] Data (t): 1.168 Batch (t): 2.386, 26.8235/s, 26.8235/s/gpu LR: 0.000008 Logit Scale: 85.342 Contrastive_loss: 0.63229 (0.63229) Loss: 0.63229 (0.63229)
2025-06-07,11:38:37 | INFO | Train Epoch: 47 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.2467/s, 50.2467/s/gpu LR: 0.000008 Logit Scale: 85.342 Contrastive_loss: 0.34946 (0.49088) Loss: 0.34946 (0.49088)
2025-06-07,11:38:37 | INFO | Start epoch 48
2025-06-07,11:38:40 | INFO | Train Epoch: 48 [  64/1034 (6%)] Data (t): 1.426 Batch (t): 2.627, 24.3666/s, 24.3666/s/gpu LR: 0.000008 Logit Scale: 85.342 Contrastive_loss: 0.22723 (0.22723) Loss: 0.22723 (0.22723)
2025-06-07,11:38:59 | INFO | Train Epoch: 48 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.269, 50.3400/s, 50.3400/s/gpu LR: 0.000008 Logit Scale: 85.346 Contrastive_loss: 0.45942 (0.34332) Loss: 0.45942 (0.34332)
2025-06-07,11:38:59 | INFO | Start epoch 49
2025-06-07,11:39:02 | INFO | Train Epoch: 49 [  64/1034 (6%)] Data (t): 1.299 Batch (t): 2.502, 25.5802/s, 25.5802/s/gpu LR: 0.000008 Logit Scale: 85.346 Contrastive_loss: 0.10647 (0.10647) Loss: 0.10647 (0.10647)
2025-06-07,11:39:21 | INFO | Train Epoch: 49 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.3941/s, 50.3941/s/gpu LR: 0.000008 Logit Scale: 85.350 Contrastive_loss: 0.24974 (0.17811) Loss: 0.24974 (0.17811)
2025-06-07,11:39:22 | INFO | Eval Epoch: 50 [64 / 1035]	Clip Loss: 8.251390	
2025-06-07,11:39:29 | INFO | Eval Epoch: 50 image_to_text_mean_rank: 308.3913	image_to_text_median_rank: 235.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0425	image_to_text_R@10: 0.0773	text_to_image_mean_rank: 303.1449	text_to_image_median_rank: 227.0000	text_to_image_R@1: 0.0106	text_to_image_R@5: 0.0444	text_to_image_R@10: 0.0783	clip_val_loss: 8.2077	epoch: 50.0000	num_samples: 1035.0000
2025-06-07,11:39:29 | INFO | Start epoch 50
2025-06-07,11:39:31 | INFO | Train Epoch: 50 [  64/1034 (6%)] Data (t): 1.218 Batch (t): 2.424, 26.3982/s, 26.3982/s/gpu LR: 0.000008 Logit Scale: 85.350 Contrastive_loss: 0.12456 (0.12456) Loss: 0.12456 (0.12456)
2025-06-07,11:39:50 | INFO | Train Epoch: 50 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.265, 50.2151/s, 50.2151/s/gpu LR: 0.000008 Logit Scale: 85.353 Contrastive_loss: 0.20166 (0.16311) Loss: 0.20166 (0.16311)
2025-06-07,11:39:50 | INFO | Start epoch 51
2025-06-07,11:39:53 | INFO | Train Epoch: 51 [  64/1034 (6%)] Data (t): 1.203 Batch (t): 2.410, 26.5556/s, 26.5556/s/gpu LR: 0.000008 Logit Scale: 85.353 Contrastive_loss: 0.39667 (0.39667) Loss: 0.39667 (0.39667)
2025-06-07,11:40:12 | INFO | Train Epoch: 51 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.1947/s, 50.1947/s/gpu LR: 0.000008 Logit Scale: 85.355 Contrastive_loss: 0.21728 (0.30697) Loss: 0.21728 (0.30697)
2025-06-07,11:40:12 | INFO | Start epoch 52
2025-06-07,11:40:15 | INFO | Train Epoch: 52 [  64/1034 (6%)] Data (t): 1.462 Batch (t): 2.685, 23.8357/s, 23.8357/s/gpu LR: 0.000008 Logit Scale: 85.355 Contrastive_loss: 0.28202 (0.28202) Loss: 0.28202 (0.28202)
2025-06-07,11:40:34 | INFO | Train Epoch: 52 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.2485/s, 50.2485/s/gpu LR: 0.000008 Logit Scale: 85.355 Contrastive_loss: 0.18699 (0.23450) Loss: 0.18699 (0.23450)
2025-06-07,11:40:34 | INFO | Start epoch 53
2025-06-07,11:40:37 | INFO | Train Epoch: 53 [  64/1034 (6%)] Data (t): 1.249 Batch (t): 2.441, 26.2178/s, 26.2178/s/gpu LR: 0.000008 Logit Scale: 85.355 Contrastive_loss: 0.27671 (0.27671) Loss: 0.27671 (0.27671)
2025-06-07,11:40:56 | INFO | Train Epoch: 53 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.271, 50.2526/s, 50.2526/s/gpu LR: 0.000009 Logit Scale: 85.357 Contrastive_loss: 0.19558 (0.23615) Loss: 0.19558 (0.23615)
2025-06-07,11:40:56 | INFO | Start epoch 54
2025-06-07,11:40:58 | INFO | Train Epoch: 54 [  64/1034 (6%)] Data (t): 1.229 Batch (t): 2.447, 26.1508/s, 26.1508/s/gpu LR: 0.000009 Logit Scale: 85.357 Contrastive_loss: 0.29200 (0.29200) Loss: 0.29200 (0.29200)
2025-06-07,11:41:17 | INFO | Train Epoch: 54 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.2476/s, 50.2476/s/gpu LR: 0.000009 Logit Scale: 85.359 Contrastive_loss: 0.20565 (0.24882) Loss: 0.20565 (0.24882)
2025-06-07,11:41:17 | INFO | Start epoch 55
2025-06-07,11:41:20 | INFO | Train Epoch: 55 [  64/1034 (6%)] Data (t): 1.306 Batch (t): 2.548, 25.1177/s, 25.1177/s/gpu LR: 0.000009 Logit Scale: 85.359 Contrastive_loss: 0.15645 (0.15645) Loss: 0.15645 (0.15645)
2025-06-07,11:41:39 | INFO | Train Epoch: 55 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.272, 50.3166/s, 50.3166/s/gpu LR: 0.000009 Logit Scale: 85.358 Contrastive_loss: 0.21683 (0.18664) Loss: 0.21683 (0.18664)
2025-06-07,11:41:39 | INFO | Start epoch 56
2025-06-07,11:41:41 | INFO | Train Epoch: 56 [  64/1034 (6%)] Data (t): 1.183 Batch (t): 2.388, 26.7951/s, 26.7951/s/gpu LR: 0.000009 Logit Scale: 85.358 Contrastive_loss: 0.23379 (0.23379) Loss: 0.23379 (0.23379)
2025-06-07,11:42:01 | INFO | Train Epoch: 56 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.274, 50.1864/s, 50.1864/s/gpu LR: 0.000009 Logit Scale: 85.356 Contrastive_loss: 0.11907 (0.17643) Loss: 0.11907 (0.17643)
2025-06-07,11:42:01 | INFO | Start epoch 57
2025-06-07,11:42:03 | INFO | Train Epoch: 57 [  64/1034 (6%)] Data (t): 1.231 Batch (t): 2.444, 26.1860/s, 26.1860/s/gpu LR: 0.000009 Logit Scale: 85.356 Contrastive_loss: 0.22113 (0.22113) Loss: 0.22113 (0.22113)
2025-06-07,11:42:22 | INFO | Train Epoch: 57 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.3733/s, 50.3733/s/gpu LR: 0.000009 Logit Scale: 85.356 Contrastive_loss: 0.044101 (0.13262) Loss: 0.044101 (0.13262)
2025-06-07,11:42:22 | INFO | Start epoch 58
2025-06-07,11:42:25 | INFO | Train Epoch: 58 [  64/1034 (6%)] Data (t): 1.275 Batch (t): 2.462, 25.9922/s, 25.9922/s/gpu LR: 0.000009 Logit Scale: 85.356 Contrastive_loss: 0.16960 (0.16960) Loss: 0.16960 (0.16960)
2025-06-07,11:42:44 | INFO | Train Epoch: 58 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.2519/s, 50.2519/s/gpu LR: 0.000009 Logit Scale: 85.356 Contrastive_loss: 0.21726 (0.19343) Loss: 0.21726 (0.19343)
2025-06-07,11:42:44 | INFO | Start epoch 59
2025-06-07,11:42:46 | INFO | Train Epoch: 59 [  64/1034 (6%)] Data (t): 1.205 Batch (t): 2.422, 26.4195/s, 26.4195/s/gpu LR: 0.000009 Logit Scale: 85.356 Contrastive_loss: 0.11407 (0.11407) Loss: 0.11407 (0.11407)
2025-06-07,11:43:05 | INFO | Train Epoch: 59 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.2094/s, 50.2094/s/gpu LR: 0.000010 Logit Scale: 85.356 Contrastive_loss: 0.12384 (0.11896) Loss: 0.12384 (0.11896)
2025-06-07,11:43:07 | INFO | Eval Epoch: 60 [64 / 1035]	Clip Loss: 8.493776	
2025-06-07,11:43:14 | INFO | Eval Epoch: 60 image_to_text_mean_rank: 314.0821	image_to_text_median_rank: 244.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0386	image_to_text_R@10: 0.0647	text_to_image_mean_rank: 304.3681	text_to_image_median_rank: 245.0000	text_to_image_R@1: 0.0087	text_to_image_R@5: 0.0435	text_to_image_R@10: 0.0734	clip_val_loss: 8.4276	epoch: 60.0000	num_samples: 1035.0000
2025-06-07,11:43:17 | INFO | Start epoch 60
2025-06-07,11:43:19 | INFO | Train Epoch: 60 [  64/1034 (6%)] Data (t): 1.237 Batch (t): 2.469, 25.9206/s, 25.9206/s/gpu LR: 0.000010 Logit Scale: 85.356 Contrastive_loss: 0.15891 (0.15891) Loss: 0.15891 (0.15891)
2025-06-07,11:43:38 | INFO | Train Epoch: 60 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.262, 50.1338/s, 50.1338/s/gpu LR: 0.000010 Logit Scale: 85.357 Contrastive_loss: 0.17475 (0.16683) Loss: 0.17475 (0.16683)
2025-06-07,11:43:38 | INFO | Start epoch 61
2025-06-07,11:43:41 | INFO | Train Epoch: 61 [  64/1034 (6%)] Data (t): 1.389 Batch (t): 2.599, 24.6215/s, 24.6215/s/gpu LR: 0.000010 Logit Scale: 85.357 Contrastive_loss: 0.11941 (0.11941) Loss: 0.11941 (0.11941)
2025-06-07,11:44:00 | INFO | Train Epoch: 61 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.273, 50.2801/s, 50.2801/s/gpu LR: 0.000010 Logit Scale: 85.358 Contrastive_loss: 0.12185 (0.12063) Loss: 0.12185 (0.12063)
2025-06-07,11:44:00 | INFO | Start epoch 62
2025-06-07,11:44:03 | INFO | Train Epoch: 62 [  64/1034 (6%)] Data (t): 1.247 Batch (t): 2.464, 25.9759/s, 25.9759/s/gpu LR: 0.000010 Logit Scale: 85.358 Contrastive_loss: 0.10819 (0.10819) Loss: 0.10819 (0.10819)
2025-06-07,11:44:22 | INFO | Train Epoch: 62 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.7449/s, 50.7449/s/gpu LR: 0.000010 Logit Scale: 85.360 Contrastive_loss: 0.21824 (0.16322) Loss: 0.21824 (0.16322)
2025-06-07,11:44:22 | INFO | Start epoch 63
2025-06-07,11:44:24 | INFO | Train Epoch: 63 [  64/1034 (6%)] Data (t): 1.245 Batch (t): 2.444, 26.1852/s, 26.1852/s/gpu LR: 0.000010 Logit Scale: 85.360 Contrastive_loss: 0.12102 (0.12102) Loss: 0.12102 (0.12102)
2025-06-07,11:44:43 | INFO | Train Epoch: 63 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1420/s, 51.1420/s/gpu LR: 0.000010 Logit Scale: 85.364 Contrastive_loss: 0.18189 (0.15145) Loss: 0.18189 (0.15145)
2025-06-07,11:44:43 | INFO | Start epoch 64
2025-06-07,11:44:46 | INFO | Train Epoch: 64 [  64/1034 (6%)] Data (t): 1.237 Batch (t): 2.424, 26.4062/s, 26.4062/s/gpu LR: 0.000010 Logit Scale: 85.365 Contrastive_loss: 0.25689 (0.25689) Loss: 0.25689 (0.25689)
2025-06-07,11:45:05 | INFO | Train Epoch: 64 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0700/s, 51.0700/s/gpu LR: 0.000010 Logit Scale: 85.367 Contrastive_loss: 0.21453 (0.23571) Loss: 0.21453 (0.23571)
2025-06-07,11:45:05 | INFO | Start epoch 65
2025-06-07,11:45:07 | INFO | Train Epoch: 65 [  64/1034 (6%)] Data (t): 1.269 Batch (t): 2.466, 25.9489/s, 25.9489/s/gpu LR: 0.000010 Logit Scale: 85.367 Contrastive_loss: 0.037494 (0.037494) Loss: 0.037494 (0.037494)
2025-06-07,11:45:26 | INFO | Train Epoch: 65 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 50.8009/s, 50.8009/s/gpu LR: 0.000011 Logit Scale: 85.364 Contrastive_loss: 0.14625 (0.091871) Loss: 0.14625 (0.091871)
2025-06-07,11:45:26 | INFO | Start epoch 66
2025-06-07,11:45:29 | INFO | Train Epoch: 66 [  64/1034 (6%)] Data (t): 1.312 Batch (t): 2.523, 25.3645/s, 25.3645/s/gpu LR: 0.000011 Logit Scale: 85.363 Contrastive_loss: 0.14779 (0.14779) Loss: 0.14779 (0.14779)
2025-06-07,11:45:48 | INFO | Train Epoch: 66 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.2081/s, 50.2081/s/gpu LR: 0.000011 Logit Scale: 85.361 Contrastive_loss: 0.11045 (0.12912) Loss: 0.11045 (0.12912)
2025-06-07,11:45:48 | INFO | Start epoch 67
2025-06-07,11:45:50 | INFO | Train Epoch: 67 [  64/1034 (6%)] Data (t): 1.276 Batch (t): 2.485, 25.7554/s, 25.7554/s/gpu LR: 0.000011 Logit Scale: 85.361 Contrastive_loss: 0.10710 (0.10710) Loss: 0.10710 (0.10710)
2025-06-07,11:46:09 | INFO | Train Epoch: 67 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.271, 50.1878/s, 50.1878/s/gpu LR: 0.000011 Logit Scale: 85.361 Contrastive_loss: 0.13295 (0.12003) Loss: 0.13295 (0.12003)
2025-06-07,11:46:09 | INFO | Start epoch 68
2025-06-07,11:46:12 | INFO | Train Epoch: 68 [  64/1034 (6%)] Data (t): 1.246 Batch (t): 2.434, 26.2932/s, 26.2932/s/gpu LR: 0.000011 Logit Scale: 85.361 Contrastive_loss: 0.12147 (0.12147) Loss: 0.12147 (0.12147)
2025-06-07,11:46:31 | INFO | Train Epoch: 68 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.266, 50.1721/s, 50.1721/s/gpu LR: 0.000011 Logit Scale: 85.360 Contrastive_loss: 0.17487 (0.14817) Loss: 0.17487 (0.14817)
2025-06-07,11:46:31 | INFO | Start epoch 69
2025-06-07,11:46:34 | INFO | Train Epoch: 69 [  64/1034 (6%)] Data (t): 1.531 Batch (t): 2.748, 23.2896/s, 23.2896/s/gpu LR: 0.000011 Logit Scale: 85.360 Contrastive_loss: 0.12567 (0.12567) Loss: 0.12567 (0.12567)
2025-06-07,11:46:53 | INFO | Train Epoch: 69 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.267, 50.1948/s, 50.1948/s/gpu LR: 0.000011 Logit Scale: 85.355 Contrastive_loss: 0.10662 (0.11615) Loss: 0.10662 (0.11615)
2025-06-07,11:46:55 | INFO | Eval Epoch: 70 [64 / 1035]	Clip Loss: 8.405233	
2025-06-07,11:47:01 | INFO | Eval Epoch: 70 image_to_text_mean_rank: 313.0386	image_to_text_median_rank: 234.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0493	image_to_text_R@10: 0.0725	text_to_image_mean_rank: 306.5208	text_to_image_median_rank: 241.0000	text_to_image_R@1: 0.0135	text_to_image_R@5: 0.0502	text_to_image_R@10: 0.0821	clip_val_loss: 8.3838	epoch: 70.0000	num_samples: 1035.0000
2025-06-07,11:47:01 | INFO | Start epoch 70
2025-06-07,11:47:04 | INFO | Train Epoch: 70 [  64/1034 (6%)] Data (t): 1.373 Batch (t): 2.584, 24.7689/s, 24.7689/s/gpu LR: 0.000011 Logit Scale: 85.355 Contrastive_loss: 0.12212 (0.12212) Loss: 0.12212 (0.12212)
2025-06-07,11:47:23 | INFO | Train Epoch: 70 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.3071/s, 50.3071/s/gpu LR: 0.000011 Logit Scale: 85.352 Contrastive_loss: 0.16322 (0.14267) Loss: 0.16322 (0.14267)
2025-06-07,11:47:23 | INFO | Start epoch 71
2025-06-07,11:47:25 | INFO | Train Epoch: 71 [  64/1034 (6%)] Data (t): 1.358 Batch (t): 2.563, 24.9728/s, 24.9728/s/gpu LR: 0.000011 Logit Scale: 85.352 Contrastive_loss: 0.11663 (0.11663) Loss: 0.11663 (0.11663)
2025-06-07,11:47:44 | INFO | Train Epoch: 71 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.262, 50.3076/s, 50.3076/s/gpu LR: 0.000012 Logit Scale: 85.352 Contrastive_loss: 0.093922 (0.10528) Loss: 0.093922 (0.10528)
2025-06-07,11:47:44 | INFO | Start epoch 72
2025-06-07,11:47:47 | INFO | Train Epoch: 72 [  64/1034 (6%)] Data (t): 1.230 Batch (t): 2.429, 26.3432/s, 26.3432/s/gpu LR: 0.000012 Logit Scale: 85.352 Contrastive_loss: 0.12550 (0.12550) Loss: 0.12550 (0.12550)
2025-06-07,11:48:06 | INFO | Train Epoch: 72 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.264, 50.2026/s, 50.2026/s/gpu LR: 0.000012 Logit Scale: 85.351 Contrastive_loss: 0.091124 (0.10831) Loss: 0.091124 (0.10831)
2025-06-07,11:48:06 | INFO | Start epoch 73
2025-06-07,11:48:08 | INFO | Train Epoch: 73 [  64/1034 (6%)] Data (t): 1.170 Batch (t): 2.383, 26.8521/s, 26.8521/s/gpu LR: 0.000012 Logit Scale: 85.351 Contrastive_loss: 0.11457 (0.11457) Loss: 0.11457 (0.11457)
2025-06-07,11:48:27 | INFO | Train Epoch: 73 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 51.0562/s, 51.0562/s/gpu LR: 0.000012 Logit Scale: 85.348 Contrastive_loss: 0.21761 (0.16609) Loss: 0.21761 (0.16609)
2025-06-07,11:48:27 | INFO | Start epoch 74
2025-06-07,11:48:30 | INFO | Train Epoch: 74 [  64/1034 (6%)] Data (t): 1.261 Batch (t): 2.451, 26.1126/s, 26.1126/s/gpu LR: 0.000012 Logit Scale: 85.347 Contrastive_loss: 0.18994 (0.18994) Loss: 0.18994 (0.18994)
2025-06-07,11:48:49 | INFO | Train Epoch: 74 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.3154/s, 51.3154/s/gpu LR: 0.000012 Logit Scale: 85.345 Contrastive_loss: 0.14896 (0.16945) Loss: 0.14896 (0.16945)
2025-06-07,11:48:49 | INFO | Start epoch 75
2025-06-07,11:48:51 | INFO | Train Epoch: 75 [  64/1034 (6%)] Data (t): 1.319 Batch (t): 2.530, 25.2960/s, 25.2960/s/gpu LR: 0.000012 Logit Scale: 85.345 Contrastive_loss: 0.13224 (0.13224) Loss: 0.13224 (0.13224)
2025-06-07,11:49:10 | INFO | Train Epoch: 75 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.2909/s, 50.2909/s/gpu LR: 0.000012 Logit Scale: 85.342 Contrastive_loss: 0.19103 (0.16164) Loss: 0.19103 (0.16164)
2025-06-07,11:49:10 | INFO | Start epoch 76
2025-06-07,11:49:13 | INFO | Train Epoch: 76 [  64/1034 (6%)] Data (t): 1.720 Batch (t): 2.944, 21.7428/s, 21.7428/s/gpu LR: 0.000012 Logit Scale: 85.341 Contrastive_loss: 0.23291 (0.23291) Loss: 0.23291 (0.23291)
2025-06-07,11:49:32 | INFO | Train Epoch: 76 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.2077/s, 50.2077/s/gpu LR: 0.000012 Logit Scale: 85.336 Contrastive_loss: 0.090738 (0.16183) Loss: 0.090738 (0.16183)
2025-06-07,11:49:32 | INFO | Start epoch 77
2025-06-07,11:49:35 | INFO | Train Epoch: 77 [  64/1034 (6%)] Data (t): 1.305 Batch (t): 2.522, 25.3729/s, 25.3729/s/gpu LR: 0.000012 Logit Scale: 85.336 Contrastive_loss: 0.15099 (0.15099) Loss: 0.15099 (0.15099)
2025-06-07,11:49:54 | INFO | Train Epoch: 77 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.263, 50.9711/s, 50.9711/s/gpu LR: 0.000012 Logit Scale: 85.336 Contrastive_loss: 0.049894 (0.10044) Loss: 0.049894 (0.10044)
2025-06-07,11:49:54 | INFO | Start epoch 78
2025-06-07,11:49:57 | INFO | Train Epoch: 78 [  64/1034 (6%)] Data (t): 1.502 Batch (t): 2.709, 23.6217/s, 23.6217/s/gpu LR: 0.000012 Logit Scale: 85.336 Contrastive_loss: 0.13212 (0.13212) Loss: 0.13212 (0.13212)
2025-06-07,11:50:16 | INFO | Train Epoch: 78 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.267, 50.2273/s, 50.2273/s/gpu LR: 0.000013 Logit Scale: 85.333 Contrastive_loss: 0.27133 (0.20172) Loss: 0.27133 (0.20172)
2025-06-07,11:50:16 | INFO | Start epoch 79
2025-06-07,11:50:19 | INFO | Train Epoch: 79 [  64/1034 (6%)] Data (t): 1.508 Batch (t): 2.719, 23.5366/s, 23.5366/s/gpu LR: 0.000013 Logit Scale: 85.333 Contrastive_loss: 0.066157 (0.066157) Loss: 0.066157 (0.066157)
2025-06-07,11:50:38 | INFO | Train Epoch: 79 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.266, 50.8769/s, 50.8769/s/gpu LR: 0.000013 Logit Scale: 85.333 Contrastive_loss: 0.071439 (0.068798) Loss: 0.071439 (0.068798)
2025-06-07,11:50:40 | INFO | Eval Epoch: 80 [64 / 1035]	Clip Loss: 8.551193	
2025-06-07,11:50:46 | INFO | Eval Epoch: 80 image_to_text_mean_rank: 322.2841	image_to_text_median_rank: 246.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0329	image_to_text_R@10: 0.0570	text_to_image_mean_rank: 310.3604	text_to_image_median_rank: 240.0000	text_to_image_R@1: 0.0097	text_to_image_R@5: 0.0329	text_to_image_R@10: 0.0599	clip_val_loss: 9.0616	epoch: 80.0000	num_samples: 1035.0000
2025-06-07,11:50:46 | INFO | Start epoch 80
2025-06-07,11:50:49 | INFO | Train Epoch: 80 [  64/1034 (6%)] Data (t): 1.616 Batch (t): 2.832, 22.6003/s, 22.6003/s/gpu LR: 0.000013 Logit Scale: 85.333 Contrastive_loss: 0.18510 (0.18510) Loss: 0.18510 (0.18510)
2025-06-07,11:51:08 | INFO | Train Epoch: 80 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 50.8053/s, 50.8053/s/gpu LR: 0.000013 Logit Scale: 85.331 Contrastive_loss: 0.17214 (0.17862) Loss: 0.17214 (0.17862)
2025-06-07,11:51:08 | INFO | Start epoch 81
2025-06-07,11:51:11 | INFO | Train Epoch: 81 [  64/1034 (6%)] Data (t): 1.369 Batch (t): 2.571, 24.8974/s, 24.8974/s/gpu LR: 0.000013 Logit Scale: 85.331 Contrastive_loss: 0.061066 (0.061066) Loss: 0.061066 (0.061066)
2025-06-07,11:51:30 | INFO | Train Epoch: 81 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.3483/s, 50.3483/s/gpu LR: 0.000013 Logit Scale: 85.329 Contrastive_loss: 0.042276 (0.051671) Loss: 0.042276 (0.051671)
2025-06-07,11:51:30 | INFO | Start epoch 82
2025-06-07,11:51:32 | INFO | Train Epoch: 82 [  64/1034 (6%)] Data (t): 1.275 Batch (t): 2.474, 25.8707/s, 25.8707/s/gpu LR: 0.000013 Logit Scale: 85.328 Contrastive_loss: 0.20743 (0.20743) Loss: 0.20743 (0.20743)
2025-06-07,11:51:51 | INFO | Train Epoch: 82 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.262, 50.3914/s, 50.3914/s/gpu LR: 0.000013 Logit Scale: 85.322 Contrastive_loss: 0.10397 (0.15570) Loss: 0.10397 (0.15570)
2025-06-07,11:51:51 | INFO | Start epoch 83
2025-06-07,11:51:54 | INFO | Train Epoch: 83 [  64/1034 (6%)] Data (t): 1.424 Batch (t): 2.633, 24.3069/s, 24.3069/s/gpu LR: 0.000013 Logit Scale: 85.322 Contrastive_loss: 0.069383 (0.069383) Loss: 0.069383 (0.069383)
2025-06-07,11:52:13 | INFO | Train Epoch: 83 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 50.2848/s, 50.2848/s/gpu LR: 0.000013 Logit Scale: 85.318 Contrastive_loss: 0.13040 (0.099889) Loss: 0.13040 (0.099889)
2025-06-07,11:52:13 | INFO | Start epoch 84
2025-06-07,11:52:16 | INFO | Train Epoch: 84 [  64/1034 (6%)] Data (t): 1.403 Batch (t): 2.607, 24.5479/s, 24.5479/s/gpu LR: 0.000013 Logit Scale: 85.318 Contrastive_loss: 0.012416 (0.012416) Loss: 0.012416 (0.012416)
2025-06-07,11:52:35 | INFO | Train Epoch: 84 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 50.2625/s, 50.2625/s/gpu LR: 0.000014 Logit Scale: 85.315 Contrastive_loss: 0.092972 (0.052694) Loss: 0.092972 (0.052694)
2025-06-07,11:52:35 | INFO | Start epoch 85
2025-06-07,11:52:37 | INFO | Train Epoch: 85 [  64/1034 (6%)] Data (t): 1.416 Batch (t): 2.616, 24.4648/s, 24.4648/s/gpu LR: 0.000014 Logit Scale: 85.315 Contrastive_loss: 0.12229 (0.12229) Loss: 0.12229 (0.12229)
2025-06-07,11:52:56 | INFO | Train Epoch: 85 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.268, 50.2837/s, 50.2837/s/gpu LR: 0.000014 Logit Scale: 85.310 Contrastive_loss: 0.078550 (0.10042) Loss: 0.078550 (0.10042)
2025-06-07,11:52:56 | INFO | Start epoch 86
2025-06-07,11:52:59 | INFO | Train Epoch: 86 [  64/1034 (6%)] Data (t): 1.351 Batch (t): 2.551, 25.0851/s, 25.0851/s/gpu LR: 0.000014 Logit Scale: 85.310 Contrastive_loss: 0.11214 (0.11214) Loss: 0.11214 (0.11214)
2025-06-07,11:53:18 | INFO | Train Epoch: 86 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.263, 50.7826/s, 50.7826/s/gpu LR: 0.000014 Logit Scale: 85.309 Contrastive_loss: 0.072474 (0.092307) Loss: 0.072474 (0.092307)
2025-06-07,11:53:18 | INFO | Start epoch 87
2025-06-07,11:53:21 | INFO | Train Epoch: 87 [  64/1034 (6%)] Data (t): 1.512 Batch (t): 2.716, 23.5681/s, 23.5681/s/gpu LR: 0.000014 Logit Scale: 85.309 Contrastive_loss: 0.028252 (0.028252) Loss: 0.028252 (0.028252)
2025-06-07,11:53:40 | INFO | Train Epoch: 87 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.262, 50.2594/s, 50.2594/s/gpu LR: 0.000014 Logit Scale: 85.307 Contrastive_loss: 0.14565 (0.086953) Loss: 0.14565 (0.086953)
2025-06-07,11:53:40 | INFO | Start epoch 88
2025-06-07,11:53:42 | INFO | Train Epoch: 88 [  64/1034 (6%)] Data (t): 1.209 Batch (t): 2.426, 26.3786/s, 26.3786/s/gpu LR: 0.000014 Logit Scale: 85.307 Contrastive_loss: 0.14355 (0.14355) Loss: 0.14355 (0.14355)
2025-06-07,11:54:01 | INFO | Train Epoch: 88 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.3352/s, 50.3352/s/gpu LR: 0.000014 Logit Scale: 85.301 Contrastive_loss: 0.023120 (0.083333) Loss: 0.023120 (0.083333)
2025-06-07,11:54:01 | INFO | Start epoch 89
2025-06-07,11:54:04 | INFO | Train Epoch: 89 [  64/1034 (6%)] Data (t): 1.293 Batch (t): 2.500, 25.6049/s, 25.6049/s/gpu LR: 0.000014 Logit Scale: 85.301 Contrastive_loss: 0.11856 (0.11856) Loss: 0.11856 (0.11856)
2025-06-07,11:54:23 | INFO | Train Epoch: 89 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.265, 50.3621/s, 50.3621/s/gpu LR: 0.000014 Logit Scale: 85.300 Contrastive_loss: 0.13831 (0.12844) Loss: 0.13831 (0.12844)
2025-06-07,11:54:25 | INFO | Eval Epoch: 90 [64 / 1035]	Clip Loss: 8.574661	
2025-06-07,11:54:31 | INFO | Eval Epoch: 90 image_to_text_mean_rank: 314.1024	image_to_text_median_rank: 245.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0329	image_to_text_R@10: 0.0599	text_to_image_mean_rank: 302.2232	text_to_image_median_rank: 238.0000	text_to_image_R@1: 0.0087	text_to_image_R@5: 0.0377	text_to_image_R@10: 0.0628	clip_val_loss: 8.5487	epoch: 90.0000	num_samples: 1035.0000
2025-06-07,11:54:31 | INFO | Start epoch 90
2025-06-07,11:54:34 | INFO | Train Epoch: 90 [  64/1034 (6%)] Data (t): 1.303 Batch (t): 2.510, 25.4954/s, 25.4954/s/gpu LR: 0.000014 Logit Scale: 85.300 Contrastive_loss: 0.13672 (0.13672) Loss: 0.13672 (0.13672)
2025-06-07,11:54:53 | INFO | Train Epoch: 90 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.264, 50.2983/s, 50.2983/s/gpu LR: 0.000015 Logit Scale: 85.293 Contrastive_loss: 0.068613 (0.10267) Loss: 0.068613 (0.10267)
2025-06-07,11:54:53 | INFO | Start epoch 91
2025-06-07,11:54:55 | INFO | Train Epoch: 91 [  64/1034 (6%)] Data (t): 1.192 Batch (t): 2.404, 26.6272/s, 26.6272/s/gpu LR: 0.000015 Logit Scale: 85.293 Contrastive_loss: 0.13796 (0.13796) Loss: 0.13796 (0.13796)
2025-06-07,11:55:14 | INFO | Train Epoch: 91 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.2670/s, 50.2670/s/gpu LR: 0.000015 Logit Scale: 85.286 Contrastive_loss: 0.13841 (0.13818) Loss: 0.13841 (0.13818)
2025-06-07,11:55:15 | INFO | Start epoch 92
2025-06-07,11:55:17 | INFO | Train Epoch: 92 [  64/1034 (6%)] Data (t): 1.503 Batch (t): 2.704, 23.6677/s, 23.6677/s/gpu LR: 0.000015 Logit Scale: 85.286 Contrastive_loss: 0.039737 (0.039737) Loss: 0.039737 (0.039737)
2025-06-07,11:55:36 | INFO | Train Epoch: 92 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.263, 50.6712/s, 50.6712/s/gpu LR: 0.000015 Logit Scale: 85.283 Contrastive_loss: 0.10957 (0.074652) Loss: 0.10957 (0.074652)
2025-06-07,11:55:36 | INFO | Start epoch 93
2025-06-07,11:55:39 | INFO | Train Epoch: 93 [  64/1034 (6%)] Data (t): 1.173 Batch (t): 2.397, 26.7000/s, 26.7000/s/gpu LR: 0.000015 Logit Scale: 85.283 Contrastive_loss: 0.10898 (0.10898) Loss: 0.10898 (0.10898)
2025-06-07,11:55:58 | INFO | Train Epoch: 93 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.264, 50.2611/s, 50.2611/s/gpu LR: 0.000015 Logit Scale: 85.281 Contrastive_loss: 0.22859 (0.16879) Loss: 0.22859 (0.16879)
2025-06-07,11:55:58 | INFO | Start epoch 94
2025-06-07,11:56:00 | INFO | Train Epoch: 94 [  64/1034 (6%)] Data (t): 1.237 Batch (t): 2.447, 26.1500/s, 26.1500/s/gpu LR: 0.000015 Logit Scale: 85.280 Contrastive_loss: 0.095025 (0.095025) Loss: 0.095025 (0.095025)
2025-06-07,11:56:19 | INFO | Train Epoch: 94 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.267, 50.4218/s, 50.4218/s/gpu LR: 0.000015 Logit Scale: 85.275 Contrastive_loss: 0.12734 (0.11118) Loss: 0.12734 (0.11118)
2025-06-07,11:56:19 | INFO | Start epoch 95
2025-06-07,11:56:22 | INFO | Train Epoch: 95 [  64/1034 (6%)] Data (t): 1.251 Batch (t): 2.445, 26.1754/s, 26.1754/s/gpu LR: 0.000015 Logit Scale: 85.275 Contrastive_loss: 0.18037 (0.18037) Loss: 0.18037 (0.18037)
2025-06-07,11:56:41 | INFO | Train Epoch: 95 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 51.0685/s, 51.0685/s/gpu LR: 0.000015 Logit Scale: 85.270 Contrastive_loss: 0.083809 (0.13209) Loss: 0.083809 (0.13209)
2025-06-07,11:56:41 | INFO | Start epoch 96
2025-06-07,11:56:44 | INFO | Train Epoch: 96 [  64/1034 (6%)] Data (t): 1.545 Batch (t): 2.740, 23.3557/s, 23.3557/s/gpu LR: 0.000015 Logit Scale: 85.271 Contrastive_loss: 0.097059 (0.097059) Loss: 0.097059 (0.097059)
2025-06-07,11:57:02 | INFO | Train Epoch: 96 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0546/s, 51.0546/s/gpu LR: 0.000016 Logit Scale: 85.271 Contrastive_loss: 0.033923 (0.065491) Loss: 0.033923 (0.065491)
2025-06-07,11:57:03 | INFO | Start epoch 97
2025-06-07,11:57:05 | INFO | Train Epoch: 97 [  64/1034 (6%)] Data (t): 1.203 Batch (t): 2.416, 26.4922/s, 26.4922/s/gpu LR: 0.000016 Logit Scale: 85.271 Contrastive_loss: 0.15494 (0.15494) Loss: 0.15494 (0.15494)
2025-06-07,11:57:24 | INFO | Train Epoch: 97 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1242/s, 51.1242/s/gpu LR: 0.000016 Logit Scale: 85.269 Contrastive_loss: 0.047991 (0.10146) Loss: 0.047991 (0.10146)
2025-06-07,11:57:24 | INFO | Start epoch 98
2025-06-07,11:57:26 | INFO | Train Epoch: 98 [  64/1034 (6%)] Data (t): 1.239 Batch (t): 2.419, 26.4592/s, 26.4592/s/gpu LR: 0.000016 Logit Scale: 85.268 Contrastive_loss: 0.036231 (0.036231) Loss: 0.036231 (0.036231)
2025-06-07,11:57:45 | INFO | Train Epoch: 98 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8299/s, 50.8299/s/gpu LR: 0.000016 Logit Scale: 85.259 Contrastive_loss: 0.14962 (0.092925) Loss: 0.14962 (0.092925)
2025-06-07,11:57:45 | INFO | Start epoch 99
2025-06-07,11:57:48 | INFO | Train Epoch: 99 [  64/1034 (6%)] Data (t): 1.216 Batch (t): 2.427, 26.3728/s, 26.3728/s/gpu LR: 0.000016 Logit Scale: 85.259 Contrastive_loss: 0.073082 (0.073082) Loss: 0.073082 (0.073082)
2025-06-07,11:58:07 | INFO | Train Epoch: 99 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.2771/s, 50.2771/s/gpu LR: 0.000016 Logit Scale: 85.251 Contrastive_loss: 0.084279 (0.078681) Loss: 0.084279 (0.078681)
2025-06-07,11:58:08 | INFO | Eval Epoch: 100 [64 / 1035]	Clip Loss: 7.675239	
2025-06-07,11:58:15 | INFO | Eval Epoch: 100 image_to_text_mean_rank: 314.6232	image_to_text_median_rank: 242.0000	image_to_text_R@1: 0.0145	image_to_text_R@5: 0.0454	image_to_text_R@10: 0.0696	text_to_image_mean_rank: 310.2155	text_to_image_median_rank: 236.0000	text_to_image_R@1: 0.0155	text_to_image_R@5: 0.0444	text_to_image_R@10: 0.0686	clip_val_loss: 8.2707	epoch: 100.0000	num_samples: 1035.0000
2025-06-07,11:58:15 | INFO | Start epoch 100
2025-06-07,11:58:17 | INFO | Train Epoch: 100 [  64/1034 (6%)] Data (t): 1.192 Batch (t): 2.388, 26.7967/s, 26.7967/s/gpu LR: 0.000016 Logit Scale: 85.251 Contrastive_loss: 0.16154 (0.16154) Loss: 0.16154 (0.16154)
2025-06-07,11:58:36 | INFO | Train Epoch: 100 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.264, 50.3346/s, 50.3346/s/gpu LR: 0.000016 Logit Scale: 85.247 Contrastive_loss: 0.055533 (0.10853) Loss: 0.055533 (0.10853)
2025-06-07,11:58:36 | INFO | Start epoch 101
2025-06-07,11:58:39 | INFO | Train Epoch: 101 [  64/1034 (6%)] Data (t): 1.254 Batch (t): 2.464, 25.9742/s, 25.9742/s/gpu LR: 0.000016 Logit Scale: 85.247 Contrastive_loss: 0.079899 (0.079899) Loss: 0.079899 (0.079899)
2025-06-07,11:58:58 | INFO | Train Epoch: 101 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.266, 50.2407/s, 50.2407/s/gpu LR: 0.000016 Logit Scale: 85.250 Contrastive_loss: 0.025604 (0.052751) Loss: 0.025604 (0.052751)
2025-06-07,11:58:58 | INFO | Start epoch 102
2025-06-07,11:59:01 | INFO | Train Epoch: 102 [  64/1034 (6%)] Data (t): 1.391 Batch (t): 2.605, 24.5639/s, 24.5639/s/gpu LR: 0.000016 Logit Scale: 85.251 Contrastive_loss: 0.15298 (0.15298) Loss: 0.15298 (0.15298)
2025-06-07,11:59:20 | INFO | Train Epoch: 102 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1122/s, 51.1122/s/gpu LR: 0.000016 Logit Scale: 85.251 Contrastive_loss: 0.11949 (0.13623) Loss: 0.11949 (0.13623)
2025-06-07,11:59:20 | INFO | Start epoch 103
2025-06-07,11:59:22 | INFO | Train Epoch: 103 [  64/1034 (6%)] Data (t): 1.227 Batch (t): 2.416, 26.4934/s, 26.4934/s/gpu LR: 0.000016 Logit Scale: 85.251 Contrastive_loss: 0.041813 (0.041813) Loss: 0.041813 (0.041813)
2025-06-07,11:59:41 | INFO | Train Epoch: 103 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.4058/s, 50.4058/s/gpu LR: 0.000017 Logit Scale: 85.247 Contrastive_loss: 0.091936 (0.066874) Loss: 0.091936 (0.066874)
2025-06-07,11:59:41 | INFO | Start epoch 104
2025-06-07,11:59:43 | INFO | Train Epoch: 104 [  64/1034 (6%)] Data (t): 1.253 Batch (t): 2.459, 26.0294/s, 26.0294/s/gpu LR: 0.000017 Logit Scale: 85.246 Contrastive_loss: 0.18144 (0.18144) Loss: 0.18144 (0.18144)
2025-06-07,12:00:02 | INFO | Train Epoch: 104 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.8759/s, 50.8759/s/gpu LR: 0.000017 Logit Scale: 85.236 Contrastive_loss: 0.072099 (0.12677) Loss: 0.072099 (0.12677)
2025-06-07,12:00:02 | INFO | Start epoch 105
2025-06-07,12:00:05 | INFO | Train Epoch: 105 [  64/1034 (6%)] Data (t): 1.260 Batch (t): 2.476, 25.8531/s, 25.8531/s/gpu LR: 0.000017 Logit Scale: 85.236 Contrastive_loss: 0.095025 (0.095025) Loss: 0.095025 (0.095025)
2025-06-07,12:00:24 | INFO | Train Epoch: 105 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 51.0197/s, 51.0197/s/gpu LR: 0.000017 Logit Scale: 85.234 Contrastive_loss: 0.080568 (0.087797) Loss: 0.080568 (0.087797)
2025-06-07,12:00:24 | INFO | Start epoch 106
2025-06-07,12:00:26 | INFO | Train Epoch: 106 [  64/1034 (6%)] Data (t): 1.238 Batch (t): 2.444, 26.1897/s, 26.1897/s/gpu LR: 0.000017 Logit Scale: 85.234 Contrastive_loss: 0.025572 (0.025572) Loss: 0.025572 (0.025572)
2025-06-07,12:00:45 | INFO | Train Epoch: 106 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.2540/s, 50.2540/s/gpu LR: 0.000017 Logit Scale: 85.228 Contrastive_loss: 0.032442 (0.029007) Loss: 0.032442 (0.029007)
2025-06-07,12:00:45 | INFO | Start epoch 107
2025-06-07,12:00:48 | INFO | Train Epoch: 107 [  64/1034 (6%)] Data (t): 1.260 Batch (t): 2.484, 25.7623/s, 25.7623/s/gpu LR: 0.000017 Logit Scale: 85.228 Contrastive_loss: 0.099099 (0.099099) Loss: 0.099099 (0.099099)
2025-06-07,12:01:07 | INFO | Train Epoch: 107 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 50.2711/s, 50.2711/s/gpu LR: 0.000017 Logit Scale: 85.226 Contrastive_loss: 0.25710 (0.17810) Loss: 0.25710 (0.17810)
2025-06-07,12:01:07 | INFO | Start epoch 108
2025-06-07,12:01:09 | INFO | Train Epoch: 108 [  64/1034 (6%)] Data (t): 1.197 Batch (t): 2.412, 26.5335/s, 26.5335/s/gpu LR: 0.000017 Logit Scale: 85.225 Contrastive_loss: 0.14581 (0.14581) Loss: 0.14581 (0.14581)
2025-06-07,12:01:28 | INFO | Train Epoch: 108 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.9852/s, 50.9852/s/gpu LR: 0.000017 Logit Scale: 85.216 Contrastive_loss: 0.14762 (0.14671) Loss: 0.14762 (0.14671)
2025-06-07,12:01:28 | INFO | Start epoch 109
2025-06-07,12:01:31 | INFO | Train Epoch: 109 [  64/1034 (6%)] Data (t): 1.250 Batch (t): 2.436, 26.2674/s, 26.2674/s/gpu LR: 0.000017 Logit Scale: 85.215 Contrastive_loss: 0.067988 (0.067988) Loss: 0.067988 (0.067988)
2025-06-07,12:01:50 | INFO | Train Epoch: 109 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 51.0265/s, 51.0265/s/gpu LR: 0.000018 Logit Scale: 85.212 Contrastive_loss: 0.12280 (0.095395) Loss: 0.12280 (0.095395)
2025-06-07,12:01:52 | INFO | Eval Epoch: 110 [64 / 1035]	Clip Loss: 8.436489	
2025-06-07,12:01:58 | INFO | Eval Epoch: 110 image_to_text_mean_rank: 320.6184	image_to_text_median_rank: 259.0000	image_to_text_R@1: 0.0097	image_to_text_R@5: 0.0348	image_to_text_R@10: 0.0589	text_to_image_mean_rank: 303.7845	text_to_image_median_rank: 245.0000	text_to_image_R@1: 0.0126	text_to_image_R@5: 0.0357	text_to_image_R@10: 0.0667	clip_val_loss: 8.4852	epoch: 110.0000	num_samples: 1035.0000
2025-06-07,12:01:58 | INFO | Start epoch 110
2025-06-07,12:02:01 | INFO | Train Epoch: 110 [  64/1034 (6%)] Data (t): 1.263 Batch (t): 2.461, 26.0023/s, 26.0023/s/gpu LR: 0.000018 Logit Scale: 85.212 Contrastive_loss: 0.13060 (0.13060) Loss: 0.13060 (0.13060)
2025-06-07,12:02:20 | INFO | Train Epoch: 110 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.9338/s, 50.9338/s/gpu LR: 0.000018 Logit Scale: 85.208 Contrastive_loss: 0.11498 (0.12279) Loss: 0.11498 (0.12279)
2025-06-07,12:02:20 | INFO | Start epoch 111
2025-06-07,12:02:22 | INFO | Train Epoch: 111 [  64/1034 (6%)] Data (t): 1.206 Batch (t): 2.466, 25.9508/s, 25.9508/s/gpu LR: 0.000018 Logit Scale: 85.208 Contrastive_loss: 0.11726 (0.11726) Loss: 0.11726 (0.11726)
2025-06-07,12:02:41 | INFO | Train Epoch: 111 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.259, 51.0788/s, 51.0788/s/gpu LR: 0.000018 Logit Scale: 85.205 Contrastive_loss: 0.044995 (0.081126) Loss: 0.044995 (0.081126)
2025-06-07,12:02:41 | INFO | Start epoch 112
2025-06-07,12:02:44 | INFO | Train Epoch: 112 [  64/1034 (6%)] Data (t): 1.261 Batch (t): 2.465, 25.9607/s, 25.9607/s/gpu LR: 0.000018 Logit Scale: 85.205 Contrastive_loss: 0.14390 (0.14390) Loss: 0.14390 (0.14390)
2025-06-07,12:03:03 | INFO | Train Epoch: 112 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.3948/s, 50.3948/s/gpu LR: 0.000018 Logit Scale: 85.201 Contrastive_loss: 0.12662 (0.13526) Loss: 0.12662 (0.13526)
2025-06-07,12:03:03 | INFO | Start epoch 113
2025-06-07,12:03:05 | INFO | Train Epoch: 113 [  64/1034 (6%)] Data (t): 1.252 Batch (t): 2.442, 26.2036/s, 26.2036/s/gpu LR: 0.000018 Logit Scale: 85.201 Contrastive_loss: 0.024940 (0.024940) Loss: 0.024940 (0.024940)
2025-06-07,12:03:24 | INFO | Train Epoch: 113 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.9585/s, 50.9585/s/gpu LR: 0.000018 Logit Scale: 85.198 Contrastive_loss: 0.056101 (0.040520) Loss: 0.056101 (0.040520)
2025-06-07,12:03:24 | INFO | Start epoch 114
2025-06-07,12:03:27 | INFO | Train Epoch: 114 [  64/1034 (6%)] Data (t): 1.253 Batch (t): 2.465, 25.9634/s, 25.9634/s/gpu LR: 0.000018 Logit Scale: 85.198 Contrastive_loss: 0.059970 (0.059970) Loss: 0.059970 (0.059970)
2025-06-07,12:03:45 | INFO | Train Epoch: 114 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 51.0104/s, 51.0104/s/gpu LR: 0.000018 Logit Scale: 85.195 Contrastive_loss: 0.070335 (0.065153) Loss: 0.070335 (0.065153)
2025-06-07,12:03:46 | INFO | Start epoch 115
2025-06-07,12:03:48 | INFO | Train Epoch: 115 [  64/1034 (6%)] Data (t): 1.287 Batch (t): 2.484, 25.7599/s, 25.7599/s/gpu LR: 0.000018 Logit Scale: 85.195 Contrastive_loss: 0.040420 (0.040420) Loss: 0.040420 (0.040420)
2025-06-07,12:04:07 | INFO | Train Epoch: 115 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 51.0695/s, 51.0695/s/gpu LR: 0.000019 Logit Scale: 85.190 Contrastive_loss: 0.077628 (0.059024) Loss: 0.077628 (0.059024)
2025-06-07,12:04:07 | INFO | Start epoch 116
2025-06-07,12:04:10 | INFO | Train Epoch: 116 [  64/1034 (6%)] Data (t): 1.269 Batch (t): 2.469, 25.9210/s, 25.9210/s/gpu LR: 0.000019 Logit Scale: 85.189 Contrastive_loss: 0.071639 (0.071639) Loss: 0.071639 (0.071639)
2025-06-07,12:04:28 | INFO | Train Epoch: 116 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.9771/s, 50.9771/s/gpu LR: 0.000019 Logit Scale: 85.187 Contrastive_loss: 0.048784 (0.060211) Loss: 0.048784 (0.060211)
2025-06-07,12:04:29 | INFO | Start epoch 117
2025-06-07,12:04:31 | INFO | Train Epoch: 117 [  64/1034 (6%)] Data (t): 1.456 Batch (t): 2.661, 24.0522/s, 24.0522/s/gpu LR: 0.000019 Logit Scale: 85.187 Contrastive_loss: 0.076564 (0.076564) Loss: 0.076564 (0.076564)
2025-06-07,12:04:50 | INFO | Train Epoch: 117 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.2493/s, 50.2493/s/gpu LR: 0.000019 Logit Scale: 85.182 Contrastive_loss: 0.12743 (0.10200) Loss: 0.12743 (0.10200)
2025-06-07,12:04:50 | INFO | Start epoch 118
2025-06-07,12:04:53 | INFO | Train Epoch: 118 [  64/1034 (6%)] Data (t): 1.205 Batch (t): 2.409, 26.5631/s, 26.5631/s/gpu LR: 0.000019 Logit Scale: 85.181 Contrastive_loss: 0.10053 (0.10053) Loss: 0.10053 (0.10053)
2025-06-07,12:05:12 | INFO | Train Epoch: 118 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.263, 50.3536/s, 50.3536/s/gpu LR: 0.000019 Logit Scale: 85.169 Contrastive_loss: 0.13629 (0.11841) Loss: 0.13629 (0.11841)
2025-06-07,12:05:12 | INFO | Start epoch 119
2025-06-07,12:05:14 | INFO | Train Epoch: 119 [  64/1034 (6%)] Data (t): 1.328 Batch (t): 2.535, 25.2423/s, 25.2423/s/gpu LR: 0.000019 Logit Scale: 85.169 Contrastive_loss: 0.059972 (0.059972) Loss: 0.059972 (0.059972)
2025-06-07,12:05:33 | INFO | Train Epoch: 119 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 51.0168/s, 51.0168/s/gpu LR: 0.000019 Logit Scale: 85.165 Contrastive_loss: 0.078550 (0.069261) Loss: 0.078550 (0.069261)
2025-06-07,12:05:35 | INFO | Eval Epoch: 120 [64 / 1035]	Clip Loss: 8.467321	
2025-06-07,12:05:42 | INFO | Eval Epoch: 120 image_to_text_mean_rank: 323.7807	image_to_text_median_rank: 260.0000	image_to_text_R@1: 0.0068	image_to_text_R@5: 0.0348	image_to_text_R@10: 0.0522	text_to_image_mean_rank: 309.3739	text_to_image_median_rank: 240.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0377	text_to_image_R@10: 0.0628	clip_val_loss: 8.3303	epoch: 120.0000	num_samples: 1035.0000
2025-06-07,12:05:45 | INFO | Start epoch 120
2025-06-07,12:05:47 | INFO | Train Epoch: 120 [  64/1034 (6%)] Data (t): 1.299 Batch (t): 2.507, 25.5288/s, 25.5288/s/gpu LR: 0.000019 Logit Scale: 85.164 Contrastive_loss: 0.15554 (0.15554) Loss: 0.15554 (0.15554)
2025-06-07,12:06:06 | INFO | Train Epoch: 120 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.4206/s, 50.4206/s/gpu LR: 0.000019 Logit Scale: 85.160 Contrastive_loss: 0.27813 (0.21684) Loss: 0.27813 (0.21684)
2025-06-07,12:06:06 | INFO | Start epoch 121
2025-06-07,12:06:09 | INFO | Train Epoch: 121 [  64/1034 (6%)] Data (t): 1.255 Batch (t): 2.451, 26.1160/s, 26.1160/s/gpu LR: 0.000019 Logit Scale: 85.159 Contrastive_loss: 0.023444 (0.023444) Loss: 0.023444 (0.023444)
2025-06-07,12:06:28 | INFO | Train Epoch: 121 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.9693/s, 50.9693/s/gpu LR: 0.000020 Logit Scale: 85.150 Contrastive_loss: 0.028800 (0.026122) Loss: 0.028800 (0.026122)
2025-06-07,12:06:28 | INFO | Start epoch 122
2025-06-07,12:06:30 | INFO | Train Epoch: 122 [  64/1034 (6%)] Data (t): 1.221 Batch (t): 2.421, 26.4337/s, 26.4337/s/gpu LR: 0.000020 Logit Scale: 85.149 Contrastive_loss: 0.097237 (0.097237) Loss: 0.097237 (0.097237)
2025-06-07,12:06:49 | INFO | Train Epoch: 122 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.7864/s, 50.7864/s/gpu LR: 0.000020 Logit Scale: 85.139 Contrastive_loss: 0.14863 (0.12293) Loss: 0.14863 (0.12293)
2025-06-07,12:06:49 | INFO | Start epoch 123
2025-06-07,12:06:52 | INFO | Train Epoch: 123 [  64/1034 (6%)] Data (t): 1.273 Batch (t): 2.456, 26.0547/s, 26.0547/s/gpu LR: 0.000020 Logit Scale: 85.139 Contrastive_loss: 0.082419 (0.082419) Loss: 0.082419 (0.082419)
2025-06-07,12:07:11 | INFO | Train Epoch: 123 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8608/s, 50.8608/s/gpu LR: 0.000020 Logit Scale: 85.129 Contrastive_loss: 0.20947 (0.14594) Loss: 0.20947 (0.14594)
2025-06-07,12:07:11 | INFO | Start epoch 124
2025-06-07,12:07:13 | INFO | Train Epoch: 124 [  64/1034 (6%)] Data (t): 1.226 Batch (t): 2.418, 26.4629/s, 26.4629/s/gpu LR: 0.000020 Logit Scale: 85.128 Contrastive_loss: 0.093681 (0.093681) Loss: 0.093681 (0.093681)
2025-06-07,12:07:32 | INFO | Train Epoch: 124 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.3194/s, 51.3194/s/gpu LR: 0.000020 Logit Scale: 85.125 Contrastive_loss: 0.048924 (0.071302) Loss: 0.048924 (0.071302)
2025-06-07,12:07:32 | INFO | Start epoch 125
2025-06-07,12:07:35 | INFO | Train Epoch: 125 [  64/1034 (6%)] Data (t): 1.302 Batch (t): 2.503, 25.5693/s, 25.5693/s/gpu LR: 0.000020 Logit Scale: 85.126 Contrastive_loss: 0.12041 (0.12041) Loss: 0.12041 (0.12041)
2025-06-07,12:07:53 | INFO | Train Epoch: 125 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0404/s, 51.0404/s/gpu LR: 0.000020 Logit Scale: 85.127 Contrastive_loss: 0.15941 (0.13991) Loss: 0.15941 (0.13991)
2025-06-07,12:07:54 | INFO | Start epoch 126
2025-06-07,12:07:56 | INFO | Train Epoch: 126 [  64/1034 (6%)] Data (t): 1.230 Batch (t): 2.427, 26.3678/s, 26.3678/s/gpu LR: 0.000020 Logit Scale: 85.127 Contrastive_loss: 0.10971 (0.10971) Loss: 0.10971 (0.10971)
2025-06-07,12:08:15 | INFO | Train Epoch: 126 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 50.9869/s, 50.9869/s/gpu LR: 0.000020 Logit Scale: 85.120 Contrastive_loss: 0.034661 (0.072184) Loss: 0.034661 (0.072184)
2025-06-07,12:08:15 | INFO | Start epoch 127
2025-06-07,12:08:17 | INFO | Train Epoch: 127 [  64/1034 (6%)] Data (t): 1.181 Batch (t): 2.388, 26.8029/s, 26.8029/s/gpu LR: 0.000020 Logit Scale: 85.119 Contrastive_loss: 0.097158 (0.097158) Loss: 0.097158 (0.097158)
2025-06-07,12:08:36 | INFO | Train Epoch: 127 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.270, 50.1778/s, 50.1778/s/gpu LR: 0.000020 Logit Scale: 85.112 Contrastive_loss: 0.15566 (0.12641) Loss: 0.15566 (0.12641)
2025-06-07,12:08:37 | INFO | Start epoch 128
2025-06-07,12:08:39 | INFO | Train Epoch: 128 [  64/1034 (6%)] Data (t): 1.242 Batch (t): 2.461, 26.0029/s, 26.0029/s/gpu LR: 0.000020 Logit Scale: 85.111 Contrastive_loss: 0.052435 (0.052435) Loss: 0.052435 (0.052435)
2025-06-07,12:08:58 | INFO | Train Epoch: 128 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.9463/s, 50.9463/s/gpu LR: 0.000021 Logit Scale: 85.106 Contrastive_loss: 0.11179 (0.082112) Loss: 0.11179 (0.082112)
2025-06-07,12:08:58 | INFO | Start epoch 129
2025-06-07,12:09:00 | INFO | Train Epoch: 129 [  64/1034 (6%)] Data (t): 1.199 Batch (t): 2.406, 26.6006/s, 26.6006/s/gpu LR: 0.000021 Logit Scale: 85.106 Contrastive_loss: 0.056167 (0.056167) Loss: 0.056167 (0.056167)
2025-06-07,12:09:19 | INFO | Train Epoch: 129 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 50.3321/s, 50.3321/s/gpu LR: 0.000021 Logit Scale: 85.100 Contrastive_loss: 0.052340 (0.054254) Loss: 0.052340 (0.054254)
2025-06-07,12:09:21 | INFO | Eval Epoch: 130 [64 / 1035]	Clip Loss: 8.588926	
2025-06-07,12:09:28 | INFO | Eval Epoch: 130 image_to_text_mean_rank: 323.9594	image_to_text_median_rank: 249.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0280	image_to_text_R@10: 0.0425	text_to_image_mean_rank: 306.3527	text_to_image_median_rank: 231.0000	text_to_image_R@1: 0.0087	text_to_image_R@5: 0.0377	text_to_image_R@10: 0.0541	clip_val_loss: 8.9582	epoch: 130.0000	num_samples: 1035.0000
2025-06-07,12:09:28 | INFO | Start epoch 130
2025-06-07,12:09:30 | INFO | Train Epoch: 130 [  64/1034 (6%)] Data (t): 1.259 Batch (t): 2.451, 26.1133/s, 26.1133/s/gpu LR: 0.000021 Logit Scale: 85.099 Contrastive_loss: 0.23120 (0.23120) Loss: 0.23120 (0.23120)
2025-06-07,12:09:49 | INFO | Train Epoch: 130 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.262, 50.2357/s, 50.2357/s/gpu LR: 0.000021 Logit Scale: 85.082 Contrastive_loss: 0.058890 (0.14504) Loss: 0.058890 (0.14504)
2025-06-07,12:09:49 | INFO | Start epoch 131
2025-06-07,12:09:52 | INFO | Train Epoch: 131 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.444, 26.1887/s, 26.1887/s/gpu LR: 0.000021 Logit Scale: 85.081 Contrastive_loss: 0.11978 (0.11978) Loss: 0.11978 (0.11978)
2025-06-07,12:10:11 | INFO | Train Epoch: 131 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.264, 50.1930/s, 50.1930/s/gpu LR: 0.000021 Logit Scale: 85.071 Contrastive_loss: 0.10579 (0.11278) Loss: 0.10579 (0.11278)
2025-06-07,12:10:11 | INFO | Start epoch 132
2025-06-07,12:10:13 | INFO | Train Epoch: 132 [  64/1034 (6%)] Data (t): 1.203 Batch (t): 2.415, 26.4981/s, 26.4981/s/gpu LR: 0.000021 Logit Scale: 85.071 Contrastive_loss: 0.17050 (0.17050) Loss: 0.17050 (0.17050)
2025-06-07,12:10:32 | INFO | Train Epoch: 132 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1099/s, 51.1099/s/gpu LR: 0.000021 Logit Scale: 85.069 Contrastive_loss: 0.053574 (0.11204) Loss: 0.053574 (0.11204)
2025-06-07,12:10:32 | INFO | Start epoch 133
2025-06-07,12:10:35 | INFO | Train Epoch: 133 [  64/1034 (6%)] Data (t): 1.279 Batch (t): 2.473, 25.8762/s, 25.8762/s/gpu LR: 0.000021 Logit Scale: 85.069 Contrastive_loss: 0.27210 (0.27210) Loss: 0.27210 (0.27210)
2025-06-07,12:10:53 | INFO | Train Epoch: 133 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.3464/s, 50.3464/s/gpu LR: 0.000021 Logit Scale: 85.061 Contrastive_loss: 0.10756 (0.18983) Loss: 0.10756 (0.18983)
2025-06-07,12:10:54 | INFO | Start epoch 134
2025-06-07,12:10:56 | INFO | Train Epoch: 134 [  64/1034 (6%)] Data (t): 1.153 Batch (t): 2.346, 27.2797/s, 27.2797/s/gpu LR: 0.000021 Logit Scale: 85.060 Contrastive_loss: 0.089454 (0.089454) Loss: 0.089454 (0.089454)
2025-06-07,12:11:15 | INFO | Train Epoch: 134 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.9384/s, 50.9384/s/gpu LR: 0.000022 Logit Scale: 85.051 Contrastive_loss: 0.058871 (0.074162) Loss: 0.058871 (0.074162)
2025-06-07,12:11:15 | INFO | Start epoch 135
2025-06-07,12:11:17 | INFO | Train Epoch: 135 [  64/1034 (6%)] Data (t): 1.217 Batch (t): 2.433, 26.3088/s, 26.3088/s/gpu LR: 0.000022 Logit Scale: 85.050 Contrastive_loss: 0.10049 (0.10049) Loss: 0.10049 (0.10049)
2025-06-07,12:11:36 | INFO | Train Epoch: 135 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.3350/s, 50.3350/s/gpu LR: 0.000022 Logit Scale: 85.046 Contrastive_loss: 0.12154 (0.11101) Loss: 0.12154 (0.11101)
2025-06-07,12:11:36 | INFO | Start epoch 136
2025-06-07,12:11:39 | INFO | Train Epoch: 136 [  64/1034 (6%)] Data (t): 1.256 Batch (t): 2.438, 26.2485/s, 26.2485/s/gpu LR: 0.000022 Logit Scale: 85.046 Contrastive_loss: 0.042089 (0.042089) Loss: 0.042089 (0.042089)
2025-06-07,12:11:58 | INFO | Train Epoch: 136 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 51.0789/s, 51.0789/s/gpu LR: 0.000022 Logit Scale: 85.043 Contrastive_loss: 0.10905 (0.075572) Loss: 0.10905 (0.075572)
2025-06-07,12:11:58 | INFO | Start epoch 137
2025-06-07,12:12:00 | INFO | Train Epoch: 137 [  64/1034 (6%)] Data (t): 1.211 Batch (t): 2.421, 26.4341/s, 26.4341/s/gpu LR: 0.000022 Logit Scale: 85.043 Contrastive_loss: 0.062463 (0.062463) Loss: 0.062463 (0.062463)
2025-06-07,12:12:19 | INFO | Train Epoch: 137 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 51.0398/s, 51.0398/s/gpu LR: 0.000022 Logit Scale: 85.034 Contrastive_loss: 0.087367 (0.074915) Loss: 0.087367 (0.074915)
2025-06-07,12:12:19 | INFO | Start epoch 138
2025-06-07,12:12:22 | INFO | Train Epoch: 138 [  64/1034 (6%)] Data (t): 1.237 Batch (t): 2.436, 26.2775/s, 26.2775/s/gpu LR: 0.000022 Logit Scale: 85.034 Contrastive_loss: 0.092527 (0.092527) Loss: 0.092527 (0.092527)
2025-06-07,12:12:41 | INFO | Train Epoch: 138 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 51.1109/s, 51.1109/s/gpu LR: 0.000022 Logit Scale: 85.031 Contrastive_loss: 0.039771 (0.066149) Loss: 0.039771 (0.066149)
2025-06-07,12:12:41 | INFO | Start epoch 139
2025-06-07,12:12:43 | INFO | Train Epoch: 139 [  64/1034 (6%)] Data (t): 1.189 Batch (t): 2.390, 26.7796/s, 26.7796/s/gpu LR: 0.000022 Logit Scale: 85.031 Contrastive_loss: 0.20471 (0.20471) Loss: 0.20471 (0.20471)
2025-06-07,12:13:02 | INFO | Train Epoch: 139 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.4840/s, 50.4840/s/gpu LR: 0.000022 Logit Scale: 85.022 Contrastive_loss: 0.051196 (0.12795) Loss: 0.051196 (0.12795)
2025-06-07,12:13:04 | INFO | Eval Epoch: 140 [64 / 1035]	Clip Loss: 7.818280	
2025-06-07,12:13:10 | INFO | Eval Epoch: 140 image_to_text_mean_rank: 322.0377	image_to_text_median_rank: 258.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0444	image_to_text_R@10: 0.0715	text_to_image_mean_rank: 305.0058	text_to_image_median_rank: 240.0000	text_to_image_R@1: 0.0087	text_to_image_R@5: 0.0386	text_to_image_R@10: 0.0657	clip_val_loss: 7.9846	epoch: 140.0000	num_samples: 1035.0000
2025-06-07,12:13:10 | INFO | Start epoch 140
2025-06-07,12:13:13 | INFO | Train Epoch: 140 [  64/1034 (6%)] Data (t): 1.212 Batch (t): 2.422, 26.4250/s, 26.4250/s/gpu LR: 0.000022 Logit Scale: 85.022 Contrastive_loss: 0.040031 (0.040031) Loss: 0.040031 (0.040031)
2025-06-07,12:13:32 | INFO | Train Epoch: 140 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.256, 50.6104/s, 50.6104/s/gpu LR: 0.000023 Logit Scale: 85.018 Contrastive_loss: 0.11330 (0.076664) Loss: 0.11330 (0.076664)
2025-06-07,12:13:32 | INFO | Start epoch 141
2025-06-07,12:13:34 | INFO | Train Epoch: 141 [  64/1034 (6%)] Data (t): 1.308 Batch (t): 2.491, 25.6953/s, 25.6953/s/gpu LR: 0.000023 Logit Scale: 85.018 Contrastive_loss: 0.11989 (0.11989) Loss: 0.11989 (0.11989)
2025-06-07,12:13:53 | INFO | Train Epoch: 141 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 51.0296/s, 51.0296/s/gpu LR: 0.000023 Logit Scale: 85.016 Contrastive_loss: 0.22521 (0.17255) Loss: 0.22521 (0.17255)
2025-06-07,12:13:53 | INFO | Start epoch 142
2025-06-07,12:13:56 | INFO | Train Epoch: 142 [  64/1034 (6%)] Data (t): 1.234 Batch (t): 2.417, 26.4746/s, 26.4746/s/gpu LR: 0.000023 Logit Scale: 85.016 Contrastive_loss: 0.039366 (0.039366) Loss: 0.039366 (0.039366)
2025-06-07,12:14:15 | INFO | Train Epoch: 142 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9758/s, 50.9758/s/gpu LR: 0.000023 Logit Scale: 85.011 Contrastive_loss: 0.069526 (0.054446) Loss: 0.069526 (0.054446)
2025-06-07,12:14:15 | INFO | Start epoch 143
2025-06-07,12:14:17 | INFO | Train Epoch: 143 [  64/1034 (6%)] Data (t): 1.200 Batch (t): 2.414, 26.5096/s, 26.5096/s/gpu LR: 0.000023 Logit Scale: 85.010 Contrastive_loss: 0.038281 (0.038281) Loss: 0.038281 (0.038281)
2025-06-07,12:14:36 | INFO | Train Epoch: 143 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.3551/s, 50.3551/s/gpu LR: 0.000023 Logit Scale: 85.001 Contrastive_loss: 0.11867 (0.078476) Loss: 0.11867 (0.078476)
2025-06-07,12:14:36 | INFO | Start epoch 144
2025-06-07,12:14:39 | INFO | Train Epoch: 144 [  64/1034 (6%)] Data (t): 1.207 Batch (t): 2.414, 26.5162/s, 26.5162/s/gpu LR: 0.000023 Logit Scale: 85.000 Contrastive_loss: 0.058770 (0.058770) Loss: 0.058770 (0.058770)
2025-06-07,12:14:57 | INFO | Train Epoch: 144 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.9943/s, 50.9943/s/gpu LR: 0.000023 Logit Scale: 84.995 Contrastive_loss: 0.17183 (0.11530) Loss: 0.17183 (0.11530)
2025-06-07,12:14:57 | INFO | Start epoch 145
2025-06-07,12:15:00 | INFO | Train Epoch: 145 [  64/1034 (6%)] Data (t): 1.172 Batch (t): 2.395, 26.7181/s, 26.7181/s/gpu LR: 0.000023 Logit Scale: 84.995 Contrastive_loss: 0.21854 (0.21854) Loss: 0.21854 (0.21854)
2025-06-07,12:15:19 | INFO | Train Epoch: 145 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.5198/s, 50.5198/s/gpu LR: 0.000023 Logit Scale: 84.990 Contrastive_loss: 0.083303 (0.15092) Loss: 0.083303 (0.15092)
2025-06-07,12:15:19 | INFO | Start epoch 146
2025-06-07,12:15:21 | INFO | Train Epoch: 146 [  64/1034 (6%)] Data (t): 1.275 Batch (t): 2.486, 25.7396/s, 25.7396/s/gpu LR: 0.000023 Logit Scale: 84.990 Contrastive_loss: 0.12580 (0.12580) Loss: 0.12580 (0.12580)
2025-06-07,12:15:40 | INFO | Train Epoch: 146 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 51.0903/s, 51.0903/s/gpu LR: 0.000024 Logit Scale: 84.983 Contrastive_loss: 0.14165 (0.13372) Loss: 0.14165 (0.13372)
2025-06-07,12:15:40 | INFO | Start epoch 147
2025-06-07,12:15:43 | INFO | Train Epoch: 147 [  64/1034 (6%)] Data (t): 1.281 Batch (t): 2.477, 25.8337/s, 25.8337/s/gpu LR: 0.000024 Logit Scale: 84.982 Contrastive_loss: 0.10831 (0.10831) Loss: 0.10831 (0.10831)
2025-06-07,12:16:02 | INFO | Train Epoch: 147 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 51.0297/s, 51.0297/s/gpu LR: 0.000024 Logit Scale: 84.976 Contrastive_loss: 0.13576 (0.12204) Loss: 0.13576 (0.12204)
2025-06-07,12:16:02 | INFO | Start epoch 148
2025-06-07,12:16:04 | INFO | Train Epoch: 148 [  64/1034 (6%)] Data (t): 1.270 Batch (t): 2.497, 25.6317/s, 25.6317/s/gpu LR: 0.000024 Logit Scale: 84.975 Contrastive_loss: 0.11708 (0.11708) Loss: 0.11708 (0.11708)
2025-06-07,12:16:23 | INFO | Train Epoch: 148 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0637/s, 51.0637/s/gpu LR: 0.000024 Logit Scale: 84.960 Contrastive_loss: 0.063579 (0.090329) Loss: 0.063579 (0.090329)
2025-06-07,12:16:23 | INFO | Start epoch 149
2025-06-07,12:16:26 | INFO | Train Epoch: 149 [  64/1034 (6%)] Data (t): 1.189 Batch (t): 2.386, 26.8266/s, 26.8266/s/gpu LR: 0.000024 Logit Scale: 84.959 Contrastive_loss: 0.14164 (0.14164) Loss: 0.14164 (0.14164)
2025-06-07,12:16:45 | INFO | Train Epoch: 149 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 51.0419/s, 51.0419/s/gpu LR: 0.000024 Logit Scale: 84.947 Contrastive_loss: 0.082639 (0.11214) Loss: 0.082639 (0.11214)
2025-06-07,12:16:46 | INFO | Eval Epoch: 150 [64 / 1035]	Clip Loss: 8.097038	
2025-06-07,12:16:53 | INFO | Eval Epoch: 150 image_to_text_mean_rank: 325.0589	image_to_text_median_rank: 265.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0367	image_to_text_R@10: 0.0599	text_to_image_mean_rank: 307.6493	text_to_image_median_rank: 235.0000	text_to_image_R@1: 0.0097	text_to_image_R@5: 0.0396	text_to_image_R@10: 0.0647	clip_val_loss: 8.4442	epoch: 150.0000	num_samples: 1035.0000
2025-06-07,12:16:53 | INFO | Start epoch 150
2025-06-07,12:16:56 | INFO | Train Epoch: 150 [  64/1034 (6%)] Data (t): 1.261 Batch (t): 2.447, 26.1538/s, 26.1538/s/gpu LR: 0.000024 Logit Scale: 84.947 Contrastive_loss: 0.047084 (0.047084) Loss: 0.047084 (0.047084)
2025-06-07,12:17:14 | INFO | Train Epoch: 150 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 50.8210/s, 50.8210/s/gpu LR: 0.000024 Logit Scale: 84.945 Contrastive_loss: 0.25007 (0.14858) Loss: 0.25007 (0.14858)
2025-06-07,12:17:14 | INFO | Start epoch 151
2025-06-07,12:17:17 | INFO | Train Epoch: 151 [  64/1034 (6%)] Data (t): 1.212 Batch (t): 2.402, 26.6436/s, 26.6436/s/gpu LR: 0.000024 Logit Scale: 84.944 Contrastive_loss: 0.074189 (0.074189) Loss: 0.074189 (0.074189)
2025-06-07,12:17:36 | INFO | Train Epoch: 151 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 51.1593/s, 51.1593/s/gpu LR: 0.000024 Logit Scale: 84.935 Contrastive_loss: 0.079938 (0.077063) Loss: 0.079938 (0.077063)
2025-06-07,12:17:36 | INFO | Start epoch 152
2025-06-07,12:17:38 | INFO | Train Epoch: 152 [  64/1034 (6%)] Data (t): 1.237 Batch (t): 2.426, 26.3801/s, 26.3801/s/gpu LR: 0.000024 Logit Scale: 84.934 Contrastive_loss: 0.058790 (0.058790) Loss: 0.058790 (0.058790)
2025-06-07,12:17:57 | INFO | Train Epoch: 152 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.5489/s, 50.5489/s/gpu LR: 0.000024 Logit Scale: 84.935 Contrastive_loss: 0.035831 (0.047311) Loss: 0.035831 (0.047311)
2025-06-07,12:17:57 | INFO | Start epoch 153
2025-06-07,12:18:00 | INFO | Train Epoch: 153 [  64/1034 (6%)] Data (t): 1.237 Batch (t): 2.438, 26.2473/s, 26.2473/s/gpu LR: 0.000024 Logit Scale: 84.936 Contrastive_loss: 0.073068 (0.073068) Loss: 0.073068 (0.073068)
2025-06-07,12:18:19 | INFO | Train Epoch: 153 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0981/s, 51.0981/s/gpu LR: 0.000025 Logit Scale: 84.934 Contrastive_loss: 0.013147 (0.043107) Loss: 0.013147 (0.043107)
2025-06-07,12:18:19 | INFO | Start epoch 154
2025-06-07,12:18:21 | INFO | Train Epoch: 154 [  64/1034 (6%)] Data (t): 1.189 Batch (t): 2.399, 26.6743/s, 26.6743/s/gpu LR: 0.000025 Logit Scale: 84.933 Contrastive_loss: 0.15115 (0.15115) Loss: 0.15115 (0.15115)
2025-06-07,12:18:40 | INFO | Train Epoch: 154 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.259, 50.3064/s, 50.3064/s/gpu LR: 0.000025 Logit Scale: 84.926 Contrastive_loss: 0.13828 (0.14471) Loss: 0.13828 (0.14471)
2025-06-07,12:18:40 | INFO | Start epoch 155
2025-06-07,12:18:43 | INFO | Train Epoch: 155 [  64/1034 (6%)] Data (t): 1.212 Batch (t): 2.423, 26.4131/s, 26.4131/s/gpu LR: 0.000025 Logit Scale: 84.925 Contrastive_loss: 0.12806 (0.12806) Loss: 0.12806 (0.12806)
2025-06-07,12:19:01 | INFO | Train Epoch: 155 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 51.0858/s, 51.0858/s/gpu LR: 0.000025 Logit Scale: 84.909 Contrastive_loss: 0.010030 (0.069045) Loss: 0.010030 (0.069045)
2025-06-07,12:19:01 | INFO | Start epoch 156
2025-06-07,12:19:04 | INFO | Train Epoch: 156 [  64/1034 (6%)] Data (t): 1.246 Batch (t): 2.440, 26.2252/s, 26.2252/s/gpu LR: 0.000025 Logit Scale: 84.908 Contrastive_loss: 0.075383 (0.075383) Loss: 0.075383 (0.075383)
2025-06-07,12:19:23 | INFO | Train Epoch: 156 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1013/s, 51.1013/s/gpu LR: 0.000025 Logit Scale: 84.903 Contrastive_loss: 0.10546 (0.090422) Loss: 0.10546 (0.090422)
2025-06-07,12:19:23 | INFO | Start epoch 157
2025-06-07,12:19:25 | INFO | Train Epoch: 157 [  64/1034 (6%)] Data (t): 1.171 Batch (t): 2.383, 26.8623/s, 26.8623/s/gpu LR: 0.000025 Logit Scale: 84.903 Contrastive_loss: 0.083234 (0.083234) Loss: 0.083234 (0.083234)
2025-06-07,12:19:44 | INFO | Train Epoch: 157 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 51.1971/s, 51.1971/s/gpu LR: 0.000025 Logit Scale: 84.902 Contrastive_loss: 0.094032 (0.088633) Loss: 0.094032 (0.088633)
2025-06-07,12:19:44 | INFO | Start epoch 158
2025-06-07,12:19:47 | INFO | Train Epoch: 158 [  64/1034 (6%)] Data (t): 1.163 Batch (t): 2.374, 26.9618/s, 26.9618/s/gpu LR: 0.000025 Logit Scale: 84.901 Contrastive_loss: 0.095843 (0.095843) Loss: 0.095843 (0.095843)
2025-06-07,12:20:05 | INFO | Train Epoch: 158 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0151/s, 51.0151/s/gpu LR: 0.000025 Logit Scale: 84.905 Contrastive_loss: 0.14507 (0.12046) Loss: 0.14507 (0.12046)
2025-06-07,12:20:06 | INFO | Start epoch 159
2025-06-07,12:20:08 | INFO | Train Epoch: 159 [  64/1034 (6%)] Data (t): 1.244 Batch (t): 2.419, 26.4610/s, 26.4610/s/gpu LR: 0.000025 Logit Scale: 84.905 Contrastive_loss: 0.087471 (0.087471) Loss: 0.087471 (0.087471)
2025-06-07,12:20:27 | INFO | Train Epoch: 159 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.0283/s, 51.0283/s/gpu LR: 0.000026 Logit Scale: 84.900 Contrastive_loss: 0.047124 (0.067298) Loss: 0.047124 (0.067298)
2025-06-07,12:20:29 | INFO | Eval Epoch: 160 [64 / 1035]	Clip Loss: 9.078123	
2025-06-07,12:20:35 | INFO | Eval Epoch: 160 image_to_text_mean_rank: 335.9961	image_to_text_median_rank: 279.0000	image_to_text_R@1: 0.0087	image_to_text_R@5: 0.0338	image_to_text_R@10: 0.0618	text_to_image_mean_rank: 307.6995	text_to_image_median_rank: 242.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0348	text_to_image_R@10: 0.0628	clip_val_loss: 9.1813	epoch: 160.0000	num_samples: 1035.0000
2025-06-07,12:20:35 | INFO | Start epoch 160
2025-06-07,12:20:38 | INFO | Train Epoch: 160 [  64/1034 (6%)] Data (t): 1.167 Batch (t): 2.374, 26.9630/s, 26.9630/s/gpu LR: 0.000026 Logit Scale: 84.899 Contrastive_loss: 0.11426 (0.11426) Loss: 0.11426 (0.11426)
2025-06-07,12:20:57 | INFO | Train Epoch: 160 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.3345/s, 50.3345/s/gpu LR: 0.000026 Logit Scale: 84.886 Contrastive_loss: 0.089942 (0.10210) Loss: 0.089942 (0.10210)
2025-06-07,12:20:57 | INFO | Start epoch 161
2025-06-07,12:20:59 | INFO | Train Epoch: 161 [  64/1034 (6%)] Data (t): 1.235 Batch (t): 2.439, 26.2421/s, 26.2421/s/gpu LR: 0.000026 Logit Scale: 84.885 Contrastive_loss: 0.033481 (0.033481) Loss: 0.033481 (0.033481)
2025-06-07,12:21:18 | INFO | Train Epoch: 161 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.3044/s, 51.3044/s/gpu LR: 0.000026 Logit Scale: 84.888 Contrastive_loss: 0.010483 (0.021982) Loss: 0.010483 (0.021982)
2025-06-07,12:21:18 | INFO | Start epoch 162
2025-06-07,12:21:20 | INFO | Train Epoch: 162 [  64/1034 (6%)] Data (t): 1.234 Batch (t): 2.426, 26.3755/s, 26.3755/s/gpu LR: 0.000026 Logit Scale: 84.887 Contrastive_loss: 0.010204 (0.010204) Loss: 0.010204 (0.010204)
2025-06-07,12:21:39 | INFO | Train Epoch: 162 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.3142/s, 50.3142/s/gpu LR: 0.000026 Logit Scale: 84.879 Contrastive_loss: 0.055899 (0.033051) Loss: 0.055899 (0.033051)
2025-06-07,12:21:39 | INFO | Start epoch 163
2025-06-07,12:21:42 | INFO | Train Epoch: 163 [  64/1034 (6%)] Data (t): 1.228 Batch (t): 2.422, 26.4274/s, 26.4274/s/gpu LR: 0.000026 Logit Scale: 84.877 Contrastive_loss: 0.41505 (0.41505) Loss: 0.41505 (0.41505)
2025-06-07,12:22:01 | INFO | Train Epoch: 163 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 51.0263/s, 51.0263/s/gpu LR: 0.000026 Logit Scale: 84.867 Contrastive_loss: 0.014893 (0.21497) Loss: 0.014893 (0.21497)
2025-06-07,12:22:01 | INFO | Start epoch 164
2025-06-07,12:22:03 | INFO | Train Epoch: 164 [  64/1034 (6%)] Data (t): 1.243 Batch (t): 2.449, 26.1367/s, 26.1367/s/gpu LR: 0.000026 Logit Scale: 84.867 Contrastive_loss: 0.12747 (0.12747) Loss: 0.12747 (0.12747)
2025-06-07,12:22:22 | INFO | Train Epoch: 164 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.3832/s, 50.3832/s/gpu LR: 0.000026 Logit Scale: 84.860 Contrastive_loss: 0.014008 (0.070737) Loss: 0.014008 (0.070737)
2025-06-07,12:22:22 | INFO | Start epoch 165
2025-06-07,12:22:25 | INFO | Train Epoch: 165 [  64/1034 (6%)] Data (t): 1.224 Batch (t): 2.412, 26.5327/s, 26.5327/s/gpu LR: 0.000026 Logit Scale: 84.860 Contrastive_loss: 0.045186 (0.045186) Loss: 0.045186 (0.045186)
2025-06-07,12:22:44 | INFO | Train Epoch: 165 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.4793/s, 50.4793/s/gpu LR: 0.000027 Logit Scale: 84.858 Contrastive_loss: 0.059634 (0.052410) Loss: 0.059634 (0.052410)
2025-06-07,12:22:44 | INFO | Start epoch 166
2025-06-07,12:22:46 | INFO | Train Epoch: 166 [  64/1034 (6%)] Data (t): 1.193 Batch (t): 2.382, 26.8709/s, 26.8709/s/gpu LR: 0.000027 Logit Scale: 84.858 Contrastive_loss: 0.16362 (0.16362) Loss: 0.16362 (0.16362)
2025-06-07,12:23:05 | INFO | Train Epoch: 166 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.0298/s, 51.0298/s/gpu LR: 0.000027 Logit Scale: 84.844 Contrastive_loss: 0.19995 (0.18178) Loss: 0.19995 (0.18178)
2025-06-07,12:23:05 | INFO | Start epoch 167
2025-06-07,12:23:08 | INFO | Train Epoch: 167 [  64/1034 (6%)] Data (t): 1.228 Batch (t): 2.417, 26.4833/s, 26.4833/s/gpu LR: 0.000027 Logit Scale: 84.843 Contrastive_loss: 0.090765 (0.090765) Loss: 0.090765 (0.090765)
2025-06-07,12:23:26 | INFO | Train Epoch: 167 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.9670/s, 50.9670/s/gpu LR: 0.000027 Logit Scale: 84.843 Contrastive_loss: 0.0076482 (0.049206) Loss: 0.0076482 (0.049206)
2025-06-07,12:23:26 | INFO | Start epoch 168
2025-06-07,12:23:29 | INFO | Train Epoch: 168 [  64/1034 (6%)] Data (t): 1.424 Batch (t): 2.617, 24.4535/s, 24.4535/s/gpu LR: 0.000027 Logit Scale: 84.843 Contrastive_loss: 0.15080 (0.15080) Loss: 0.15080 (0.15080)
2025-06-07,12:23:48 | INFO | Train Epoch: 168 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.9081/s, 50.9081/s/gpu LR: 0.000027 Logit Scale: 84.830 Contrastive_loss: 0.10533 (0.12806) Loss: 0.10533 (0.12806)
2025-06-07,12:23:48 | INFO | Start epoch 169
2025-06-07,12:23:50 | INFO | Train Epoch: 169 [  64/1034 (6%)] Data (t): 1.223 Batch (t): 2.424, 26.4036/s, 26.4036/s/gpu LR: 0.000027 Logit Scale: 84.828 Contrastive_loss: 0.15237 (0.15237) Loss: 0.15237 (0.15237)
2025-06-07,12:24:09 | INFO | Train Epoch: 169 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.9131/s, 50.9131/s/gpu LR: 0.000027 Logit Scale: 84.814 Contrastive_loss: 0.095332 (0.12385) Loss: 0.095332 (0.12385)
2025-06-07,12:24:11 | INFO | Eval Epoch: 170 [64 / 1035]	Clip Loss: 7.840320	
2025-06-07,12:24:18 | INFO | Eval Epoch: 170 image_to_text_mean_rank: 316.8126	image_to_text_median_rank: 251.0000	image_to_text_R@1: 0.0087	image_to_text_R@5: 0.0290	image_to_text_R@10: 0.0531	text_to_image_mean_rank: 302.1633	text_to_image_median_rank: 234.0000	text_to_image_R@1: 0.0029	text_to_image_R@5: 0.0444	text_to_image_R@10: 0.0715	clip_val_loss: 8.5129	epoch: 170.0000	num_samples: 1035.0000
2025-06-07,12:24:18 | INFO | Start epoch 170
2025-06-07,12:24:20 | INFO | Train Epoch: 170 [  64/1034 (6%)] Data (t): 1.197 Batch (t): 2.416, 26.4860/s, 26.4860/s/gpu LR: 0.000027 Logit Scale: 84.814 Contrastive_loss: 0.049728 (0.049728) Loss: 0.049728 (0.049728)
2025-06-07,12:24:39 | INFO | Train Epoch: 170 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.9701/s, 50.9701/s/gpu LR: 0.000027 Logit Scale: 84.810 Contrastive_loss: 0.12356 (0.086642) Loss: 0.12356 (0.086642)
2025-06-07,12:24:39 | INFO | Start epoch 171
2025-06-07,12:24:41 | INFO | Train Epoch: 171 [  64/1034 (6%)] Data (t): 1.161 Batch (t): 2.362, 27.0982/s, 27.0982/s/gpu LR: 0.000027 Logit Scale: 84.810 Contrastive_loss: 0.0085270 (0.0085270) Loss: 0.0085270 (0.0085270)
2025-06-07,12:25:00 | INFO | Train Epoch: 171 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.7706/s, 50.7706/s/gpu LR: 0.000028 Logit Scale: 84.806 Contrastive_loss: 0.086343 (0.047435) Loss: 0.086343 (0.047435)
2025-06-07,12:25:00 | INFO | Start epoch 172
2025-06-07,12:25:03 | INFO | Train Epoch: 172 [  64/1034 (6%)] Data (t): 1.227 Batch (t): 2.417, 26.4802/s, 26.4802/s/gpu LR: 0.000028 Logit Scale: 84.805 Contrastive_loss: 0.057766 (0.057766) Loss: 0.057766 (0.057766)
2025-06-07,12:25:22 | INFO | Train Epoch: 172 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.2636/s, 51.2636/s/gpu LR: 0.000028 Logit Scale: 84.793 Contrastive_loss: 0.10866 (0.083213) Loss: 0.10866 (0.083213)
2025-06-07,12:25:22 | INFO | Start epoch 173
2025-06-07,12:25:24 | INFO | Train Epoch: 173 [  64/1034 (6%)] Data (t): 1.273 Batch (t): 2.460, 26.0160/s, 26.0160/s/gpu LR: 0.000028 Logit Scale: 84.793 Contrastive_loss: 0.15084 (0.15084) Loss: 0.15084 (0.15084)
2025-06-07,12:25:43 | INFO | Train Epoch: 173 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1445/s, 51.1445/s/gpu LR: 0.000028 Logit Scale: 84.777 Contrastive_loss: 0.036162 (0.093503) Loss: 0.036162 (0.093503)
2025-06-07,12:25:43 | INFO | Start epoch 174
2025-06-07,12:25:46 | INFO | Train Epoch: 174 [  64/1034 (6%)] Data (t): 1.214 Batch (t): 2.417, 26.4756/s, 26.4756/s/gpu LR: 0.000028 Logit Scale: 84.776 Contrastive_loss: 0.054690 (0.054690) Loss: 0.054690 (0.054690)
2025-06-07,12:26:04 | INFO | Train Epoch: 174 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.8689/s, 50.8689/s/gpu LR: 0.000028 Logit Scale: 84.768 Contrastive_loss: 0.041375 (0.048033) Loss: 0.041375 (0.048033)
2025-06-07,12:26:04 | INFO | Start epoch 175
2025-06-07,12:26:07 | INFO | Train Epoch: 175 [  64/1034 (6%)] Data (t): 1.231 Batch (t): 2.449, 26.1326/s, 26.1326/s/gpu LR: 0.000028 Logit Scale: 84.767 Contrastive_loss: 0.087461 (0.087461) Loss: 0.087461 (0.087461)
2025-06-07,12:26:26 | INFO | Train Epoch: 175 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 51.1678/s, 51.1678/s/gpu LR: 0.000028 Logit Scale: 84.756 Contrastive_loss: 0.020436 (0.053949) Loss: 0.020436 (0.053949)
2025-06-07,12:26:26 | INFO | Start epoch 176
2025-06-07,12:26:28 | INFO | Train Epoch: 176 [  64/1034 (6%)] Data (t): 1.200 Batch (t): 2.403, 26.6328/s, 26.6328/s/gpu LR: 0.000028 Logit Scale: 84.755 Contrastive_loss: 0.027888 (0.027888) Loss: 0.027888 (0.027888)
2025-06-07,12:26:47 | INFO | Train Epoch: 176 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.260, 50.3856/s, 50.3856/s/gpu LR: 0.000028 Logit Scale: 84.739 Contrastive_loss: 0.019971 (0.023930) Loss: 0.019971 (0.023930)
2025-06-07,12:26:47 | INFO | Start epoch 177
2025-06-07,12:26:50 | INFO | Train Epoch: 177 [  64/1034 (6%)] Data (t): 1.180 Batch (t): 2.383, 26.8567/s, 26.8567/s/gpu LR: 0.000028 Logit Scale: 84.738 Contrastive_loss: 0.071120 (0.071120) Loss: 0.071120 (0.071120)
2025-06-07,12:27:09 | INFO | Train Epoch: 177 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.9933/s, 50.9933/s/gpu LR: 0.000028 Logit Scale: 84.729 Contrastive_loss: 0.099220 (0.085170) Loss: 0.099220 (0.085170)
2025-06-07,12:27:09 | INFO | Start epoch 178
2025-06-07,12:27:11 | INFO | Train Epoch: 178 [  64/1034 (6%)] Data (t): 1.470 Batch (t): 2.661, 24.0553/s, 24.0553/s/gpu LR: 0.000028 Logit Scale: 84.729 Contrastive_loss: 0.054851 (0.054851) Loss: 0.054851 (0.054851)
2025-06-07,12:27:30 | INFO | Train Epoch: 178 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0929/s, 51.0929/s/gpu LR: 0.000029 Logit Scale: 84.724 Contrastive_loss: 0.15743 (0.10614) Loss: 0.15743 (0.10614)
2025-06-07,12:27:30 | INFO | Start epoch 179
2025-06-07,12:27:33 | INFO | Train Epoch: 179 [  64/1034 (6%)] Data (t): 1.242 Batch (t): 2.447, 26.1506/s, 26.1506/s/gpu LR: 0.000029 Logit Scale: 84.724 Contrastive_loss: 0.084010 (0.084010) Loss: 0.084010 (0.084010)
2025-06-07,12:27:52 | INFO | Train Epoch: 179 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1256/s, 51.1256/s/gpu LR: 0.000029 Logit Scale: 84.718 Contrastive_loss: 0.0064517 (0.045231) Loss: 0.0064517 (0.045231)
2025-06-07,12:27:53 | INFO | Eval Epoch: 180 [64 / 1035]	Clip Loss: 8.280998	
2025-06-07,12:28:00 | INFO | Eval Epoch: 180 image_to_text_mean_rank: 325.3836	image_to_text_median_rank: 267.0000	image_to_text_R@1: 0.0126	image_to_text_R@5: 0.0386	image_to_text_R@10: 0.0628	text_to_image_mean_rank: 308.8754	text_to_image_median_rank: 233.0000	text_to_image_R@1: 0.0116	text_to_image_R@5: 0.0319	text_to_image_R@10: 0.0560	clip_val_loss: 8.7261	epoch: 180.0000	num_samples: 1035.0000
2025-06-07,12:28:03 | INFO | Start epoch 180
2025-06-07,12:28:06 | INFO | Train Epoch: 180 [  64/1034 (6%)] Data (t): 1.325 Batch (t): 2.527, 25.3312/s, 25.3312/s/gpu LR: 0.000029 Logit Scale: 84.717 Contrastive_loss: 0.13083 (0.13083) Loss: 0.13083 (0.13083)
2025-06-07,12:28:24 | INFO | Train Epoch: 180 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.4235/s, 50.4235/s/gpu LR: 0.000029 Logit Scale: 84.710 Contrastive_loss: 0.074746 (0.10279) Loss: 0.074746 (0.10279)
2025-06-07,12:28:24 | INFO | Start epoch 181
2025-06-07,12:28:27 | INFO | Train Epoch: 181 [  64/1034 (6%)] Data (t): 1.236 Batch (t): 2.445, 26.1760/s, 26.1760/s/gpu LR: 0.000029 Logit Scale: 84.710 Contrastive_loss: 0.094792 (0.094792) Loss: 0.094792 (0.094792)
2025-06-07,12:28:46 | INFO | Train Epoch: 181 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.272, 50.0504/s, 50.0504/s/gpu LR: 0.000029 Logit Scale: 84.702 Contrastive_loss: 0.025559 (0.060176) Loss: 0.025559 (0.060176)
2025-06-07,12:28:46 | INFO | Start epoch 182
2025-06-07,12:28:49 | INFO | Train Epoch: 182 [  64/1034 (6%)] Data (t): 1.147 Batch (t): 2.359, 27.1271/s, 27.1271/s/gpu LR: 0.000029 Logit Scale: 84.702 Contrastive_loss: 0.090283 (0.090283) Loss: 0.090283 (0.090283)
2025-06-07,12:29:07 | INFO | Train Epoch: 182 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1704/s, 51.1704/s/gpu LR: 0.000029 Logit Scale: 84.692 Contrastive_loss: 0.12580 (0.10804) Loss: 0.12580 (0.10804)
2025-06-07,12:29:07 | INFO | Start epoch 183
2025-06-07,12:29:10 | INFO | Train Epoch: 183 [  64/1034 (6%)] Data (t): 1.211 Batch (t): 2.401, 26.6581/s, 26.6581/s/gpu LR: 0.000029 Logit Scale: 84.691 Contrastive_loss: 0.18139 (0.18139) Loss: 0.18139 (0.18139)
2025-06-07,12:29:29 | INFO | Train Epoch: 183 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9989/s, 50.9989/s/gpu LR: 0.000029 Logit Scale: 84.683 Contrastive_loss: 0.0080866 (0.094737) Loss: 0.0080866 (0.094737)
2025-06-07,12:29:29 | INFO | Start epoch 184
2025-06-07,12:29:31 | INFO | Train Epoch: 184 [  64/1034 (6%)] Data (t): 1.233 Batch (t): 2.430, 26.3418/s, 26.3418/s/gpu LR: 0.000029 Logit Scale: 84.682 Contrastive_loss: 0.024119 (0.024119) Loss: 0.024119 (0.024119)
2025-06-07,12:29:50 | INFO | Train Epoch: 184 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8511/s, 50.8511/s/gpu LR: 0.000030 Logit Scale: 84.666 Contrastive_loss: 0.13096 (0.077539) Loss: 0.13096 (0.077539)
2025-06-07,12:29:50 | INFO | Start epoch 185
2025-06-07,12:29:53 | INFO | Train Epoch: 185 [  64/1034 (6%)] Data (t): 1.238 Batch (t): 2.423, 26.4082/s, 26.4082/s/gpu LR: 0.000030 Logit Scale: 84.665 Contrastive_loss: 0.18553 (0.18553) Loss: 0.18553 (0.18553)
2025-06-07,12:30:11 | INFO | Train Epoch: 185 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.8232/s, 50.8232/s/gpu LR: 0.000030 Logit Scale: 84.663 Contrastive_loss: 0.10074 (0.14313) Loss: 0.10074 (0.14313)
2025-06-07,12:30:12 | INFO | Start epoch 186
2025-06-07,12:30:14 | INFO | Train Epoch: 186 [  64/1034 (6%)] Data (t): 1.250 Batch (t): 2.458, 26.0375/s, 26.0375/s/gpu LR: 0.000030 Logit Scale: 84.664 Contrastive_loss: 0.013852 (0.013852) Loss: 0.013852 (0.013852)
2025-06-07,12:30:33 | INFO | Train Epoch: 186 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1784/s, 51.1784/s/gpu LR: 0.000030 Logit Scale: 84.659 Contrastive_loss: 0.049772 (0.031812) Loss: 0.049772 (0.031812)
2025-06-07,12:30:33 | INFO | Start epoch 187
2025-06-07,12:30:35 | INFO | Train Epoch: 187 [  64/1034 (6%)] Data (t): 1.183 Batch (t): 2.387, 26.8151/s, 26.8151/s/gpu LR: 0.000030 Logit Scale: 84.658 Contrastive_loss: 0.059449 (0.059449) Loss: 0.059449 (0.059449)
2025-06-07,12:30:54 | INFO | Train Epoch: 187 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0561/s, 51.0561/s/gpu LR: 0.000030 Logit Scale: 84.647 Contrastive_loss: 0.022206 (0.040827) Loss: 0.022206 (0.040827)
2025-06-07,12:30:54 | INFO | Start epoch 188
2025-06-07,12:30:57 | INFO | Train Epoch: 188 [  64/1034 (6%)] Data (t): 1.243 Batch (t): 2.449, 26.1285/s, 26.1285/s/gpu LR: 0.000030 Logit Scale: 84.646 Contrastive_loss: 0.027807 (0.027807) Loss: 0.027807 (0.027807)
2025-06-07,12:31:16 | INFO | Train Epoch: 188 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.9395/s, 50.9395/s/gpu LR: 0.000030 Logit Scale: 84.640 Contrastive_loss: 0.066154 (0.046981) Loss: 0.066154 (0.046981)
2025-06-07,12:31:16 | INFO | Start epoch 189
2025-06-07,12:31:18 | INFO | Train Epoch: 189 [  64/1034 (6%)] Data (t): 1.303 Batch (t): 2.500, 25.6023/s, 25.6023/s/gpu LR: 0.000030 Logit Scale: 84.640 Contrastive_loss: 0.024640 (0.024640) Loss: 0.024640 (0.024640)
2025-06-07,12:31:37 | INFO | Train Epoch: 189 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.7085/s, 50.7085/s/gpu LR: 0.000030 Logit Scale: 84.636 Contrastive_loss: 0.024081 (0.024360) Loss: 0.024081 (0.024360)
2025-06-07,12:31:39 | INFO | Eval Epoch: 190 [64 / 1035]	Clip Loss: 8.647639	
2025-06-07,12:31:46 | INFO | Eval Epoch: 190 image_to_text_mean_rank: 331.6957	image_to_text_median_rank: 269.0000	image_to_text_R@1: 0.0068	image_to_text_R@5: 0.0348	image_to_text_R@10: 0.0580	text_to_image_mean_rank: 304.2222	text_to_image_median_rank: 230.0000	text_to_image_R@1: 0.0097	text_to_image_R@5: 0.0319	text_to_image_R@10: 0.0522	clip_val_loss: 8.7018	epoch: 190.0000	num_samples: 1035.0000
2025-06-07,12:31:46 | INFO | Start epoch 190
2025-06-07,12:31:48 | INFO | Train Epoch: 190 [  64/1034 (6%)] Data (t): 1.416 Batch (t): 2.606, 24.5583/s, 24.5583/s/gpu LR: 0.000030 Logit Scale: 84.636 Contrastive_loss: 0.097641 (0.097641) Loss: 0.097641 (0.097641)
2025-06-07,12:32:07 | INFO | Train Epoch: 190 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1963/s, 51.1963/s/gpu LR: 0.000031 Logit Scale: 84.623 Contrastive_loss: 0.061114 (0.079378) Loss: 0.061114 (0.079378)
2025-06-07,12:32:07 | INFO | Start epoch 191
2025-06-07,12:32:10 | INFO | Train Epoch: 191 [  64/1034 (6%)] Data (t): 1.338 Batch (t): 2.553, 25.0702/s, 25.0702/s/gpu LR: 0.000031 Logit Scale: 84.622 Contrastive_loss: 0.080027 (0.080027) Loss: 0.080027 (0.080027)
2025-06-07,12:32:29 | INFO | Train Epoch: 191 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 50.8671/s, 50.8671/s/gpu LR: 0.000031 Logit Scale: 84.613 Contrastive_loss: 0.10990 (0.094962) Loss: 0.10990 (0.094962)
2025-06-07,12:32:29 | INFO | Start epoch 192
2025-06-07,12:32:31 | INFO | Train Epoch: 192 [  64/1034 (6%)] Data (t): 1.203 Batch (t): 2.403, 26.6294/s, 26.6294/s/gpu LR: 0.000031 Logit Scale: 84.613 Contrastive_loss: 0.0075456 (0.0075456) Loss: 0.0075456 (0.0075456)
2025-06-07,12:32:50 | INFO | Train Epoch: 192 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.254, 51.0084/s, 51.0084/s/gpu LR: 0.000031 Logit Scale: 84.609 Contrastive_loss: 0.094158 (0.050852) Loss: 0.094158 (0.050852)
2025-06-07,12:32:50 | INFO | Start epoch 193
2025-06-07,12:32:53 | INFO | Train Epoch: 193 [  64/1034 (6%)] Data (t): 1.321 Batch (t): 2.501, 25.5892/s, 25.5892/s/gpu LR: 0.000031 Logit Scale: 84.609 Contrastive_loss: 0.022716 (0.022716) Loss: 0.022716 (0.022716)
2025-06-07,12:33:11 | INFO | Train Epoch: 193 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0737/s, 51.0737/s/gpu LR: 0.000031 Logit Scale: 84.597 Contrastive_loss: 0.22875 (0.12574) Loss: 0.22875 (0.12574)
2025-06-07,12:33:11 | INFO | Start epoch 194
2025-06-07,12:33:14 | INFO | Train Epoch: 194 [  64/1034 (6%)] Data (t): 1.258 Batch (t): 2.456, 26.0578/s, 26.0578/s/gpu LR: 0.000031 Logit Scale: 84.596 Contrastive_loss: 0.096888 (0.096888) Loss: 0.096888 (0.096888)
2025-06-07,12:33:33 | INFO | Train Epoch: 194 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.253, 51.0762/s, 51.0762/s/gpu LR: 0.000031 Logit Scale: 84.580 Contrastive_loss: 0.057186 (0.077037) Loss: 0.057186 (0.077037)
2025-06-07,12:33:33 | INFO | Start epoch 195
2025-06-07,12:33:35 | INFO | Train Epoch: 195 [  64/1034 (6%)] Data (t): 1.177 Batch (t): 2.394, 26.7286/s, 26.7286/s/gpu LR: 0.000031 Logit Scale: 84.579 Contrastive_loss: 0.072970 (0.072970) Loss: 0.072970 (0.072970)
2025-06-07,12:33:54 | INFO | Train Epoch: 195 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1250/s, 51.1250/s/gpu LR: 0.000031 Logit Scale: 84.565 Contrastive_loss: 0.040750 (0.056860) Loss: 0.040750 (0.056860)
2025-06-07,12:33:54 | INFO | Start epoch 196
2025-06-07,12:33:57 | INFO | Train Epoch: 196 [  64/1034 (6%)] Data (t): 1.265 Batch (t): 2.463, 25.9816/s, 25.9816/s/gpu LR: 0.000031 Logit Scale: 84.564 Contrastive_loss: 0.030581 (0.030581) Loss: 0.030581 (0.030581)
2025-06-07,12:34:16 | INFO | Train Epoch: 196 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0208/s, 51.0208/s/gpu LR: 0.000032 Logit Scale: 84.555 Contrastive_loss: 0.092457 (0.061519) Loss: 0.092457 (0.061519)
2025-06-07,12:34:16 | INFO | Start epoch 197
2025-06-07,12:34:18 | INFO | Train Epoch: 197 [  64/1034 (6%)] Data (t): 1.196 Batch (t): 2.411, 26.5453/s, 26.5453/s/gpu LR: 0.000032 Logit Scale: 84.554 Contrastive_loss: 0.10095 (0.10095) Loss: 0.10095 (0.10095)
2025-06-07,12:34:37 | INFO | Train Epoch: 197 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.3867/s, 50.3867/s/gpu LR: 0.000032 Logit Scale: 84.541 Contrastive_loss: 0.023115 (0.062034) Loss: 0.023115 (0.062034)
2025-06-07,12:34:37 | INFO | Start epoch 198
2025-06-07,12:34:40 | INFO | Train Epoch: 198 [  64/1034 (6%)] Data (t): 1.269 Batch (t): 2.458, 26.0330/s, 26.0330/s/gpu LR: 0.000032 Logit Scale: 84.540 Contrastive_loss: 0.036647 (0.036647) Loss: 0.036647 (0.036647)
2025-06-07,12:34:58 | INFO | Train Epoch: 198 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0887/s, 51.0887/s/gpu LR: 0.000032 Logit Scale: 84.537 Contrastive_loss: 0.13956 (0.088105) Loss: 0.13956 (0.088105)
2025-06-07,12:34:58 | INFO | Start epoch 199
2025-06-07,12:35:01 | INFO | Train Epoch: 199 [  64/1034 (6%)] Data (t): 1.409 Batch (t): 2.605, 24.5672/s, 24.5672/s/gpu LR: 0.000032 Logit Scale: 84.536 Contrastive_loss: 0.11695 (0.11695) Loss: 0.11695 (0.11695)
2025-06-07,12:35:20 | INFO | Train Epoch: 199 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.3260/s, 51.3260/s/gpu LR: 0.000032 Logit Scale: 84.525 Contrastive_loss: 0.070471 (0.093709) Loss: 0.070471 (0.093709)
2025-06-07,12:35:22 | INFO | Eval Epoch: 200 [64 / 1035]	Clip Loss: 6.824684	
2025-06-07,12:35:29 | INFO | Eval Epoch: 200 image_to_text_mean_rank: 313.4377	image_to_text_median_rank: 243.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0290	image_to_text_R@10: 0.0454	text_to_image_mean_rank: 301.8290	text_to_image_median_rank: 230.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0280	text_to_image_R@10: 0.0580	clip_val_loss: 8.1386	epoch: 200.0000	num_samples: 1035.0000
2025-06-07,12:35:29 | INFO | Start epoch 200
2025-06-07,12:35:31 | INFO | Train Epoch: 200 [  64/1034 (6%)] Data (t): 1.188 Batch (t): 2.380, 26.8919/s, 26.8919/s/gpu LR: 0.000032 Logit Scale: 84.524 Contrastive_loss: 0.016128 (0.016128) Loss: 0.016128 (0.016128)
2025-06-07,12:35:50 | INFO | Train Epoch: 200 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0626/s, 51.0626/s/gpu LR: 0.000032 Logit Scale: 84.515 Contrastive_loss: 0.15078 (0.083455) Loss: 0.15078 (0.083455)
2025-06-07,12:35:50 | INFO | Start epoch 201
2025-06-07,12:35:52 | INFO | Train Epoch: 201 [  64/1034 (6%)] Data (t): 1.222 Batch (t): 2.454, 26.0842/s, 26.0842/s/gpu LR: 0.000032 Logit Scale: 84.514 Contrastive_loss: 0.044385 (0.044385) Loss: 0.044385 (0.044385)
2025-06-07,12:36:11 | INFO | Train Epoch: 201 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.264, 51.0604/s, 51.0604/s/gpu LR: 0.000032 Logit Scale: 84.502 Contrastive_loss: 0.070018 (0.057201) Loss: 0.070018 (0.057201)
2025-06-07,12:36:11 | INFO | Start epoch 202
2025-06-07,12:36:14 | INFO | Train Epoch: 202 [  64/1034 (6%)] Data (t): 1.354 Batch (t): 2.540, 25.2003/s, 25.2003/s/gpu LR: 0.000032 Logit Scale: 84.502 Contrastive_loss: 0.10124 (0.10124) Loss: 0.10124 (0.10124)
2025-06-07,12:36:33 | INFO | Train Epoch: 202 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1187/s, 51.1187/s/gpu LR: 0.000032 Logit Scale: 84.503 Contrastive_loss: 0.058029 (0.079637) Loss: 0.058029 (0.079637)
2025-06-07,12:36:33 | INFO | Start epoch 203
2025-06-07,12:36:35 | INFO | Train Epoch: 203 [  64/1034 (6%)] Data (t): 1.273 Batch (t): 2.460, 26.0140/s, 26.0140/s/gpu LR: 0.000032 Logit Scale: 84.504 Contrastive_loss: 0.14267 (0.14267) Loss: 0.14267 (0.14267)
2025-06-07,12:36:54 | INFO | Train Epoch: 203 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.1489/s, 51.1489/s/gpu LR: 0.000033 Logit Scale: 84.494 Contrastive_loss: 0.11099 (0.12683) Loss: 0.11099 (0.12683)
2025-06-07,12:36:54 | INFO | Start epoch 204
2025-06-07,12:36:57 | INFO | Train Epoch: 204 [  64/1034 (6%)] Data (t): 1.217 Batch (t): 2.399, 26.6725/s, 26.6725/s/gpu LR: 0.000033 Logit Scale: 84.493 Contrastive_loss: 0.11233 (0.11233) Loss: 0.11233 (0.11233)
2025-06-07,12:37:16 | INFO | Train Epoch: 204 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1363/s, 51.1363/s/gpu LR: 0.000033 Logit Scale: 84.481 Contrastive_loss: 0.052416 (0.082374) Loss: 0.052416 (0.082374)
2025-06-07,12:37:16 | INFO | Start epoch 205
2025-06-07,12:37:18 | INFO | Train Epoch: 205 [  64/1034 (6%)] Data (t): 1.325 Batch (t): 2.523, 25.3634/s, 25.3634/s/gpu LR: 0.000033 Logit Scale: 84.481 Contrastive_loss: 0.15541 (0.15541) Loss: 0.15541 (0.15541)
2025-06-07,12:37:37 | INFO | Train Epoch: 205 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.3879/s, 50.3879/s/gpu LR: 0.000033 Logit Scale: 84.471 Contrastive_loss: 0.25955 (0.20748) Loss: 0.25955 (0.20748)
2025-06-07,12:37:37 | INFO | Start epoch 206
2025-06-07,12:37:40 | INFO | Train Epoch: 206 [  64/1034 (6%)] Data (t): 1.188 Batch (t): 2.400, 26.6628/s, 26.6628/s/gpu LR: 0.000033 Logit Scale: 84.470 Contrastive_loss: 0.093415 (0.093415) Loss: 0.093415 (0.093415)
2025-06-07,12:37:59 | INFO | Train Epoch: 206 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.264, 50.2746/s, 50.2746/s/gpu LR: 0.000033 Logit Scale: 84.456 Contrastive_loss: 0.23534 (0.16438) Loss: 0.23534 (0.16438)
2025-06-07,12:37:59 | INFO | Start epoch 207
2025-06-07,12:38:01 | INFO | Train Epoch: 207 [  64/1034 (6%)] Data (t): 1.239 Batch (t): 2.441, 26.2234/s, 26.2234/s/gpu LR: 0.000033 Logit Scale: 84.454 Contrastive_loss: 0.16119 (0.16119) Loss: 0.16119 (0.16119)
2025-06-07,12:38:20 | INFO | Train Epoch: 207 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.258, 51.0241/s, 51.0241/s/gpu LR: 0.000033 Logit Scale: 84.443 Contrastive_loss: 0.12070 (0.14094) Loss: 0.12070 (0.14094)
2025-06-07,12:38:20 | INFO | Start epoch 208
2025-06-07,12:38:23 | INFO | Train Epoch: 208 [  64/1034 (6%)] Data (t): 1.242 Batch (t): 2.434, 26.2965/s, 26.2965/s/gpu LR: 0.000033 Logit Scale: 84.442 Contrastive_loss: 0.076822 (0.076822) Loss: 0.076822 (0.076822)
2025-06-07,12:38:41 | INFO | Train Epoch: 208 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 50.3125/s, 50.3125/s/gpu LR: 0.000033 Logit Scale: 84.429 Contrastive_loss: 0.055311 (0.066067) Loss: 0.055311 (0.066067)
2025-06-07,12:38:42 | INFO | Start epoch 209
2025-06-07,12:38:44 | INFO | Train Epoch: 209 [  64/1034 (6%)] Data (t): 1.282 Batch (t): 2.475, 25.8566/s, 25.8566/s/gpu LR: 0.000033 Logit Scale: 84.428 Contrastive_loss: 0.092656 (0.092656) Loss: 0.092656 (0.092656)
2025-06-07,12:39:03 | INFO | Train Epoch: 209 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.261, 50.1313/s, 50.1313/s/gpu LR: 0.000034 Logit Scale: 84.420 Contrastive_loss: 0.11370 (0.10318) Loss: 0.11370 (0.10318)
2025-06-07,12:39:05 | INFO | Eval Epoch: 210 [64 / 1035]	Clip Loss: 7.351224	
2025-06-07,12:39:11 | INFO | Eval Epoch: 210 image_to_text_mean_rank: 335.8889	image_to_text_median_rank: 274.0000	image_to_text_R@1: 0.0058	image_to_text_R@5: 0.0319	image_to_text_R@10: 0.0464	text_to_image_mean_rank: 315.2957	text_to_image_median_rank: 238.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0338	text_to_image_R@10: 0.0531	clip_val_loss: 7.9285	epoch: 210.0000	num_samples: 1035.0000
2025-06-07,12:39:11 | INFO | Start epoch 210
2025-06-07,12:39:14 | INFO | Train Epoch: 210 [  64/1034 (6%)] Data (t): 1.258 Batch (t): 2.479, 25.8183/s, 25.8183/s/gpu LR: 0.000034 Logit Scale: 84.420 Contrastive_loss: 0.12402 (0.12402) Loss: 0.12402 (0.12402)
2025-06-07,12:39:33 | INFO | Train Epoch: 210 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.258, 51.0491/s, 51.0491/s/gpu LR: 0.000034 Logit Scale: 84.413 Contrastive_loss: 0.090814 (0.10742) Loss: 0.090814 (0.10742)
2025-06-07,12:39:33 | INFO | Start epoch 211
2025-06-07,12:39:35 | INFO | Train Epoch: 211 [  64/1034 (6%)] Data (t): 1.155 Batch (t): 2.365, 27.0644/s, 27.0644/s/gpu LR: 0.000034 Logit Scale: 84.412 Contrastive_loss: 0.055443 (0.055443) Loss: 0.055443 (0.055443)
2025-06-07,12:39:54 | INFO | Train Epoch: 211 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1059/s, 51.1059/s/gpu LR: 0.000034 Logit Scale: 84.404 Contrastive_loss: 0.061796 (0.058619) Loss: 0.061796 (0.058619)
2025-06-07,12:39:54 | INFO | Start epoch 212
2025-06-07,12:39:57 | INFO | Train Epoch: 212 [  64/1034 (6%)] Data (t): 1.221 Batch (t): 2.404, 26.6266/s, 26.6266/s/gpu LR: 0.000034 Logit Scale: 84.403 Contrastive_loss: 0.075153 (0.075153) Loss: 0.075153 (0.075153)
2025-06-07,12:40:15 | INFO | Train Epoch: 212 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0678/s, 51.0678/s/gpu LR: 0.000034 Logit Scale: 84.401 Contrastive_loss: 0.074293 (0.074723) Loss: 0.074293 (0.074723)
2025-06-07,12:40:15 | INFO | Start epoch 213
2025-06-07,12:40:18 | INFO | Train Epoch: 213 [  64/1034 (6%)] Data (t): 1.192 Batch (t): 2.394, 26.7330/s, 26.7330/s/gpu LR: 0.000034 Logit Scale: 84.401 Contrastive_loss: 0.053610 (0.053610) Loss: 0.053610 (0.053610)
2025-06-07,12:40:37 | INFO | Train Epoch: 213 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.9215/s, 50.9215/s/gpu LR: 0.000034 Logit Scale: 84.393 Contrastive_loss: 0.11261 (0.083109) Loss: 0.11261 (0.083109)
2025-06-07,12:40:37 | INFO | Start epoch 214
2025-06-07,12:40:39 | INFO | Train Epoch: 214 [  64/1034 (6%)] Data (t): 1.139 Batch (t): 2.335, 27.4038/s, 27.4038/s/gpu LR: 0.000034 Logit Scale: 84.392 Contrastive_loss: 0.083934 (0.083934) Loss: 0.083934 (0.083934)
2025-06-07,12:40:58 | INFO | Train Epoch: 214 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.3681/s, 51.3681/s/gpu LR: 0.000034 Logit Scale: 84.389 Contrastive_loss: 0.013086 (0.048510) Loss: 0.013086 (0.048510)
2025-06-07,12:40:58 | INFO | Start epoch 215
2025-06-07,12:41:01 | INFO | Train Epoch: 215 [  64/1034 (6%)] Data (t): 1.281 Batch (t): 2.464, 25.9705/s, 25.9705/s/gpu LR: 0.000034 Logit Scale: 84.390 Contrastive_loss: 0.048429 (0.048429) Loss: 0.048429 (0.048429)
2025-06-07,12:41:19 | INFO | Train Epoch: 215 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.3683/s, 50.3683/s/gpu LR: 0.000035 Logit Scale: 84.392 Contrastive_loss: 0.14922 (0.098827) Loss: 0.14922 (0.098827)
2025-06-07,12:41:19 | INFO | Start epoch 216
2025-06-07,12:41:22 | INFO | Train Epoch: 216 [  64/1034 (6%)] Data (t): 1.238 Batch (t): 2.442, 26.2047/s, 26.2047/s/gpu LR: 0.000035 Logit Scale: 84.391 Contrastive_loss: 0.067309 (0.067309) Loss: 0.067309 (0.067309)
2025-06-07,12:41:41 | INFO | Train Epoch: 216 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9686/s, 50.9686/s/gpu LR: 0.000035 Logit Scale: 84.388 Contrastive_loss: 0.11036 (0.088833) Loss: 0.11036 (0.088833)
2025-06-07,12:41:41 | INFO | Start epoch 217
2025-06-07,12:41:43 | INFO | Train Epoch: 217 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.442, 26.2057/s, 26.2057/s/gpu LR: 0.000035 Logit Scale: 84.387 Contrastive_loss: 0.077276 (0.077276) Loss: 0.077276 (0.077276)
2025-06-07,12:42:02 | INFO | Train Epoch: 217 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.9486/s, 50.9486/s/gpu LR: 0.000035 Logit Scale: 84.387 Contrastive_loss: 0.12021 (0.098742) Loss: 0.12021 (0.098742)
2025-06-07,12:42:02 | INFO | Start epoch 218
2025-06-07,12:42:05 | INFO | Train Epoch: 218 [  64/1034 (6%)] Data (t): 1.247 Batch (t): 2.421, 26.4331/s, 26.4331/s/gpu LR: 0.000035 Logit Scale: 84.387 Contrastive_loss: 0.26175 (0.26175) Loss: 0.26175 (0.26175)
2025-06-07,12:42:23 | INFO | Train Epoch: 218 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2369/s, 51.2369/s/gpu LR: 0.000035 Logit Scale: 84.365 Contrastive_loss: 0.039752 (0.15075) Loss: 0.039752 (0.15075)
2025-06-07,12:42:24 | INFO | Start epoch 219
2025-06-07,12:42:26 | INFO | Train Epoch: 219 [  64/1034 (6%)] Data (t): 1.330 Batch (t): 2.533, 25.2696/s, 25.2696/s/gpu LR: 0.000035 Logit Scale: 84.362 Contrastive_loss: 0.11248 (0.11248) Loss: 0.11248 (0.11248)
2025-06-07,12:42:45 | INFO | Train Epoch: 219 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.9191/s, 50.9191/s/gpu LR: 0.000035 Logit Scale: 84.346 Contrastive_loss: 0.23974 (0.17611) Loss: 0.23974 (0.17611)
2025-06-07,12:42:47 | INFO | Eval Epoch: 220 [64 / 1035]	Clip Loss: 8.013763	
2025-06-07,12:42:53 | INFO | Eval Epoch: 220 image_to_text_mean_rank: 325.7014	image_to_text_median_rank: 244.0000	image_to_text_R@1: 0.0058	image_to_text_R@5: 0.0329	image_to_text_R@10: 0.0512	text_to_image_mean_rank: 314.6928	text_to_image_median_rank: 233.0000	text_to_image_R@1: 0.0106	text_to_image_R@5: 0.0329	text_to_image_R@10: 0.0628	clip_val_loss: 8.2012	epoch: 220.0000	num_samples: 1035.0000
2025-06-07,12:42:53 | INFO | Start epoch 220
2025-06-07,12:42:56 | INFO | Train Epoch: 220 [  64/1034 (6%)] Data (t): 1.173 Batch (t): 2.374, 26.9558/s, 26.9558/s/gpu LR: 0.000035 Logit Scale: 84.344 Contrastive_loss: 0.089912 (0.089912) Loss: 0.089912 (0.089912)
2025-06-07,12:43:15 | INFO | Train Epoch: 220 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0967/s, 51.0967/s/gpu LR: 0.000035 Logit Scale: 84.334 Contrastive_loss: 0.066135 (0.078024) Loss: 0.066135 (0.078024)
2025-06-07,12:43:15 | INFO | Start epoch 221
2025-06-07,12:43:17 | INFO | Train Epoch: 221 [  64/1034 (6%)] Data (t): 1.264 Batch (t): 2.476, 25.8461/s, 25.8461/s/gpu LR: 0.000035 Logit Scale: 84.334 Contrastive_loss: 0.14432 (0.14432) Loss: 0.14432 (0.14432)
2025-06-07,12:43:36 | INFO | Train Epoch: 221 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.7521/s, 50.7521/s/gpu LR: 0.000036 Logit Scale: 84.325 Contrastive_loss: 0.13491 (0.13961) Loss: 0.13491 (0.13961)
2025-06-07,12:43:36 | INFO | Start epoch 222
2025-06-07,12:43:39 | INFO | Train Epoch: 222 [  64/1034 (6%)] Data (t): 1.246 Batch (t): 2.436, 26.2688/s, 26.2688/s/gpu LR: 0.000036 Logit Scale: 84.324 Contrastive_loss: 0.053531 (0.053531) Loss: 0.053531 (0.053531)
2025-06-07,12:43:57 | INFO | Train Epoch: 222 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0431/s, 51.0431/s/gpu LR: 0.000036 Logit Scale: 84.309 Contrastive_loss: 0.18140 (0.11746) Loss: 0.18140 (0.11746)
2025-06-07,12:43:57 | INFO | Start epoch 223
2025-06-07,12:44:00 | INFO | Train Epoch: 223 [  64/1034 (6%)] Data (t): 1.214 Batch (t): 2.401, 26.6541/s, 26.6541/s/gpu LR: 0.000036 Logit Scale: 84.308 Contrastive_loss: 0.037800 (0.037800) Loss: 0.037800 (0.037800)
2025-06-07,12:44:19 | INFO | Train Epoch: 223 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.3266/s, 50.3266/s/gpu LR: 0.000036 Logit Scale: 84.290 Contrastive_loss: 0.084380 (0.061090) Loss: 0.084380 (0.061090)
2025-06-07,12:44:19 | INFO | Start epoch 224
2025-06-07,12:44:21 | INFO | Train Epoch: 224 [  64/1034 (6%)] Data (t): 1.298 Batch (t): 2.503, 25.5719/s, 25.5719/s/gpu LR: 0.000036 Logit Scale: 84.290 Contrastive_loss: 0.10462 (0.10462) Loss: 0.10462 (0.10462)
2025-06-07,12:44:40 | INFO | Train Epoch: 224 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.2423/s, 51.2423/s/gpu LR: 0.000036 Logit Scale: 84.286 Contrastive_loss: 0.0053280 (0.054972) Loss: 0.0053280 (0.054972)
2025-06-07,12:44:40 | INFO | Start epoch 225
2025-06-07,12:44:43 | INFO | Train Epoch: 225 [  64/1034 (6%)] Data (t): 1.163 Batch (t): 2.364, 27.0770/s, 27.0770/s/gpu LR: 0.000036 Logit Scale: 84.285 Contrastive_loss: 0.063952 (0.063952) Loss: 0.063952 (0.063952)
2025-06-07,12:45:01 | INFO | Train Epoch: 225 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.7507/s, 50.7507/s/gpu LR: 0.000036 Logit Scale: 84.275 Contrastive_loss: 0.033129 (0.048540) Loss: 0.033129 (0.048540)
2025-06-07,12:45:02 | INFO | Start epoch 226
2025-06-07,12:45:04 | INFO | Train Epoch: 226 [  64/1034 (6%)] Data (t): 1.179 Batch (t): 2.364, 27.0771/s, 27.0771/s/gpu LR: 0.000036 Logit Scale: 84.274 Contrastive_loss: 0.092775 (0.092775) Loss: 0.092775 (0.092775)
2025-06-07,12:45:23 | INFO | Train Epoch: 226 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.3501/s, 51.3501/s/gpu LR: 0.000036 Logit Scale: 84.266 Contrastive_loss: 0.034380 (0.063577) Loss: 0.034380 (0.063577)
2025-06-07,12:45:23 | INFO | Start epoch 227
2025-06-07,12:45:25 | INFO | Train Epoch: 227 [  64/1034 (6%)] Data (t): 1.183 Batch (t): 2.384, 26.8436/s, 26.8436/s/gpu LR: 0.000036 Logit Scale: 84.266 Contrastive_loss: 0.014162 (0.014162) Loss: 0.014162 (0.014162)
2025-06-07,12:45:44 | INFO | Train Epoch: 227 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1582/s, 51.1582/s/gpu LR: 0.000036 Logit Scale: 84.249 Contrastive_loss: 0.17441 (0.094286) Loss: 0.17441 (0.094286)
2025-06-07,12:45:44 | INFO | Start epoch 228
2025-06-07,12:45:47 | INFO | Train Epoch: 228 [  64/1034 (6%)] Data (t): 1.206 Batch (t): 2.413, 26.5245/s, 26.5245/s/gpu LR: 0.000036 Logit Scale: 84.248 Contrastive_loss: 0.043287 (0.043287) Loss: 0.043287 (0.043287)
2025-06-07,12:46:05 | INFO | Train Epoch: 228 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.254, 51.1391/s, 51.1391/s/gpu LR: 0.000037 Logit Scale: 84.233 Contrastive_loss: 0.018403 (0.030845) Loss: 0.018403 (0.030845)
2025-06-07,12:46:06 | INFO | Start epoch 229
2025-06-07,12:46:08 | INFO | Train Epoch: 229 [  64/1034 (6%)] Data (t): 1.351 Batch (t): 2.535, 25.2510/s, 25.2510/s/gpu LR: 0.000037 Logit Scale: 84.232 Contrastive_loss: 0.058896 (0.058896) Loss: 0.058896 (0.058896)
2025-06-07,12:46:27 | INFO | Train Epoch: 229 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0719/s, 51.0719/s/gpu LR: 0.000037 Logit Scale: 84.213 Contrastive_loss: 0.081883 (0.070390) Loss: 0.081883 (0.070390)
2025-06-07,12:46:29 | INFO | Eval Epoch: 230 [64 / 1035]	Clip Loss: 7.993206	
2025-06-07,12:46:35 | INFO | Eval Epoch: 230 image_to_text_mean_rank: 341.7179	image_to_text_median_rank: 280.0000	image_to_text_R@1: 0.0087	image_to_text_R@5: 0.0290	image_to_text_R@10: 0.0493	text_to_image_mean_rank: 320.1855	text_to_image_median_rank: 265.0000	text_to_image_R@1: 0.0106	text_to_image_R@5: 0.0300	text_to_image_R@10: 0.0541	clip_val_loss: 8.4488	epoch: 230.0000	num_samples: 1035.0000
2025-06-07,12:46:35 | INFO | Start epoch 230
2025-06-07,12:46:38 | INFO | Train Epoch: 230 [  64/1034 (6%)] Data (t): 1.250 Batch (t): 2.444, 26.1908/s, 26.1908/s/gpu LR: 0.000037 Logit Scale: 84.211 Contrastive_loss: 0.098553 (0.098553) Loss: 0.098553 (0.098553)
2025-06-07,12:46:57 | INFO | Train Epoch: 230 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.255, 50.6309/s, 50.6309/s/gpu LR: 0.000037 Logit Scale: 84.187 Contrastive_loss: 0.050442 (0.074498) Loss: 0.050442 (0.074498)
2025-06-07,12:46:57 | INFO | Start epoch 231
2025-06-07,12:46:59 | INFO | Train Epoch: 231 [  64/1034 (6%)] Data (t): 1.206 Batch (t): 2.391, 26.7616/s, 26.7616/s/gpu LR: 0.000037 Logit Scale: 84.186 Contrastive_loss: 0.040123 (0.040123) Loss: 0.040123 (0.040123)
2025-06-07,12:47:18 | INFO | Train Epoch: 231 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.256, 50.7802/s, 50.7802/s/gpu LR: 0.000037 Logit Scale: 84.181 Contrastive_loss: 0.074496 (0.057309) Loss: 0.074496 (0.057309)
2025-06-07,12:47:18 | INFO | Start epoch 232
2025-06-07,12:47:21 | INFO | Train Epoch: 232 [  64/1034 (6%)] Data (t): 1.298 Batch (t): 2.492, 25.6871/s, 25.6871/s/gpu LR: 0.000037 Logit Scale: 84.181 Contrastive_loss: 0.053025 (0.053025) Loss: 0.053025 (0.053025)
2025-06-07,12:47:39 | INFO | Train Epoch: 232 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0903/s, 51.0903/s/gpu LR: 0.000037 Logit Scale: 84.185 Contrastive_loss: 0.16477 (0.10890) Loss: 0.16477 (0.10890)
2025-06-07,12:47:39 | INFO | Start epoch 233
2025-06-07,12:47:42 | INFO | Train Epoch: 233 [  64/1034 (6%)] Data (t): 1.189 Batch (t): 2.381, 26.8802/s, 26.8802/s/gpu LR: 0.000037 Logit Scale: 84.185 Contrastive_loss: 0.10192 (0.10192) Loss: 0.10192 (0.10192)
2025-06-07,12:48:01 | INFO | Train Epoch: 233 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.3155/s, 50.3155/s/gpu LR: 0.000037 Logit Scale: 84.178 Contrastive_loss: 0.084000 (0.092963) Loss: 0.084000 (0.092963)
2025-06-07,12:48:01 | INFO | Start epoch 234
2025-06-07,12:48:03 | INFO | Train Epoch: 234 [  64/1034 (6%)] Data (t): 1.211 Batch (t): 2.436, 26.2713/s, 26.2713/s/gpu LR: 0.000037 Logit Scale: 84.177 Contrastive_loss: 0.090605 (0.090605) Loss: 0.090605 (0.090605)
2025-06-07,12:48:22 | INFO | Train Epoch: 234 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.254, 50.9937/s, 50.9937/s/gpu LR: 0.000038 Logit Scale: 84.170 Contrastive_loss: 0.065990 (0.078297) Loss: 0.065990 (0.078297)
2025-06-07,12:48:22 | INFO | Start epoch 235
2025-06-07,12:48:25 | INFO | Train Epoch: 235 [  64/1034 (6%)] Data (t): 1.287 Batch (t): 2.485, 25.7584/s, 25.7584/s/gpu LR: 0.000038 Logit Scale: 84.170 Contrastive_loss: 0.081789 (0.081789) Loss: 0.081789 (0.081789)
2025-06-07,12:48:44 | INFO | Train Epoch: 235 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.8089/s, 50.8089/s/gpu LR: 0.000038 Logit Scale: 84.153 Contrastive_loss: 0.027596 (0.054693) Loss: 0.027596 (0.054693)
2025-06-07,12:48:44 | INFO | Start epoch 236
2025-06-07,12:48:46 | INFO | Train Epoch: 236 [  64/1034 (6%)] Data (t): 1.182 Batch (t): 2.398, 26.6883/s, 26.6883/s/gpu LR: 0.000038 Logit Scale: 84.151 Contrastive_loss: 0.12771 (0.12771) Loss: 0.12771 (0.12771)
2025-06-07,12:49:05 | INFO | Train Epoch: 236 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.255, 50.3085/s, 50.3085/s/gpu LR: 0.000038 Logit Scale: 84.122 Contrastive_loss: 0.13430 (0.13100) Loss: 0.13430 (0.13100)
2025-06-07,12:49:05 | INFO | Start epoch 237
2025-06-07,12:49:08 | INFO | Train Epoch: 237 [  64/1034 (6%)] Data (t): 1.226 Batch (t): 2.426, 26.3769/s, 26.3769/s/gpu LR: 0.000038 Logit Scale: 84.120 Contrastive_loss: 0.067890 (0.067890) Loss: 0.067890 (0.067890)
2025-06-07,12:49:26 | INFO | Train Epoch: 237 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.9981/s, 50.9981/s/gpu LR: 0.000038 Logit Scale: 84.106 Contrastive_loss: 0.075410 (0.071650) Loss: 0.075410 (0.071650)
2025-06-07,12:49:26 | INFO | Start epoch 238
2025-06-07,12:49:29 | INFO | Train Epoch: 238 [  64/1034 (6%)] Data (t): 1.275 Batch (t): 2.481, 25.7960/s, 25.7960/s/gpu LR: 0.000038 Logit Scale: 84.106 Contrastive_loss: 0.12830 (0.12830) Loss: 0.12830 (0.12830)
2025-06-07,12:49:48 | INFO | Train Epoch: 238 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8906/s, 50.8906/s/gpu LR: 0.000038 Logit Scale: 84.096 Contrastive_loss: 0.10248 (0.11539) Loss: 0.10248 (0.11539)
2025-06-07,12:49:48 | INFO | Start epoch 239
2025-06-07,12:49:50 | INFO | Train Epoch: 239 [  64/1034 (6%)] Data (t): 1.297 Batch (t): 2.492, 25.6867/s, 25.6867/s/gpu LR: 0.000038 Logit Scale: 84.096 Contrastive_loss: 0.17118 (0.17118) Loss: 0.17118 (0.17118)
2025-06-07,12:50:09 | INFO | Train Epoch: 239 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.9742/s, 50.9742/s/gpu LR: 0.000038 Logit Scale: 84.089 Contrastive_loss: 0.053895 (0.11254) Loss: 0.053895 (0.11254)
2025-06-07,12:50:11 | INFO | Eval Epoch: 240 [64 / 1035]	Clip Loss: 7.881123	
2025-06-07,12:50:18 | INFO | Eval Epoch: 240 image_to_text_mean_rank: 331.6222	image_to_text_median_rank: 268.0000	image_to_text_R@1: 0.0068	image_to_text_R@5: 0.0203	image_to_text_R@10: 0.0454	text_to_image_mean_rank: 325.5063	text_to_image_median_rank: 253.0000	text_to_image_R@1: 0.0068	text_to_image_R@5: 0.0242	text_to_image_R@10: 0.0464	clip_val_loss: 8.7995	epoch: 240.0000	num_samples: 1035.0000
2025-06-07,12:50:21 | INFO | Start epoch 240
2025-06-07,12:50:23 | INFO | Train Epoch: 240 [  64/1034 (6%)] Data (t): 1.505 Batch (t): 2.738, 23.3707/s, 23.3707/s/gpu LR: 0.000038 Logit Scale: 84.089 Contrastive_loss: 0.084460 (0.084460) Loss: 0.084460 (0.084460)
2025-06-07,12:50:42 | INFO | Train Epoch: 240 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.259, 50.1609/s, 50.1609/s/gpu LR: 0.000039 Logit Scale: 84.082 Contrastive_loss: 0.050308 (0.067384) Loss: 0.050308 (0.067384)
2025-06-07,12:50:42 | INFO | Start epoch 241
2025-06-07,12:50:45 | INFO | Train Epoch: 241 [  64/1034 (6%)] Data (t): 1.165 Batch (t): 2.403, 26.6343/s, 26.6343/s/gpu LR: 0.000039 Logit Scale: 84.080 Contrastive_loss: 0.071937 (0.071937) Loss: 0.071937 (0.071937)
2025-06-07,12:51:04 | INFO | Train Epoch: 241 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.267, 51.0356/s, 51.0356/s/gpu LR: 0.000039 Logit Scale: 84.058 Contrastive_loss: 0.095442 (0.083689) Loss: 0.095442 (0.083689)
2025-06-07,12:51:04 | INFO | Start epoch 242
2025-06-07,12:51:06 | INFO | Train Epoch: 242 [  64/1034 (6%)] Data (t): 1.293 Batch (t): 2.482, 25.7862/s, 25.7862/s/gpu LR: 0.000039 Logit Scale: 84.057 Contrastive_loss: 0.098314 (0.098314) Loss: 0.098314 (0.098314)
2025-06-07,12:51:25 | INFO | Train Epoch: 242 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.0657/s, 51.0657/s/gpu LR: 0.000039 Logit Scale: 84.052 Contrastive_loss: 0.0090313 (0.053672) Loss: 0.0090313 (0.053672)
2025-06-07,12:51:25 | INFO | Start epoch 243
2025-06-07,12:51:28 | INFO | Train Epoch: 243 [  64/1034 (6%)] Data (t): 1.454 Batch (t): 2.648, 24.1722/s, 24.1722/s/gpu LR: 0.000039 Logit Scale: 84.053 Contrastive_loss: 0.030704 (0.030704) Loss: 0.030704 (0.030704)
2025-06-07,12:51:47 | INFO | Train Epoch: 243 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.251, 51.0711/s, 51.0711/s/gpu LR: 0.000039 Logit Scale: 84.056 Contrastive_loss: 0.00065327 (0.015679) Loss: 0.00065327 (0.015679)
2025-06-07,12:51:47 | INFO | Start epoch 244
2025-06-07,12:51:49 | INFO | Train Epoch: 244 [  64/1034 (6%)] Data (t): 1.189 Batch (t): 2.389, 26.7865/s, 26.7865/s/gpu LR: 0.000039 Logit Scale: 84.056 Contrastive_loss: 0.052267 (0.052267) Loss: 0.052267 (0.052267)
2025-06-07,12:52:08 | INFO | Train Epoch: 244 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.3308/s, 51.3308/s/gpu LR: 0.000039 Logit Scale: 84.050 Contrastive_loss: 0.048920 (0.050594) Loss: 0.048920 (0.050594)
2025-06-07,12:52:08 | INFO | Start epoch 245
2025-06-07,12:52:11 | INFO | Train Epoch: 245 [  64/1034 (6%)] Data (t): 1.256 Batch (t): 2.437, 26.2631/s, 26.2631/s/gpu LR: 0.000039 Logit Scale: 84.048 Contrastive_loss: 0.14886 (0.14886) Loss: 0.14886 (0.14886)
2025-06-07,12:52:30 | INFO | Train Epoch: 245 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0727/s, 51.0727/s/gpu LR: 0.000039 Logit Scale: 84.031 Contrastive_loss: 0.055994 (0.10243) Loss: 0.055994 (0.10243)
2025-06-07,12:52:30 | INFO | Start epoch 246
2025-06-07,12:52:32 | INFO | Train Epoch: 246 [  64/1034 (6%)] Data (t): 1.265 Batch (t): 2.453, 26.0937/s, 26.0937/s/gpu LR: 0.000039 Logit Scale: 84.031 Contrastive_loss: 0.072591 (0.072591) Loss: 0.072591 (0.072591)
2025-06-07,12:52:51 | INFO | Train Epoch: 246 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.0553/s, 51.0553/s/gpu LR: 0.000040 Logit Scale: 84.020 Contrastive_loss: 0.041756 (0.057173) Loss: 0.041756 (0.057173)
2025-06-07,12:52:51 | INFO | Start epoch 247
2025-06-07,12:52:54 | INFO | Train Epoch: 247 [  64/1034 (6%)] Data (t): 1.242 Batch (t): 2.467, 25.9435/s, 25.9435/s/gpu LR: 0.000040 Logit Scale: 84.019 Contrastive_loss: 0.10719 (0.10719) Loss: 0.10719 (0.10719)
2025-06-07,12:53:12 | INFO | Train Epoch: 247 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.7144/s, 50.7144/s/gpu LR: 0.000040 Logit Scale: 84.010 Contrastive_loss: 0.054998 (0.081092) Loss: 0.054998 (0.081092)
2025-06-07,12:53:12 | INFO | Start epoch 248
2025-06-07,12:53:15 | INFO | Train Epoch: 248 [  64/1034 (6%)] Data (t): 1.256 Batch (t): 2.460, 26.0206/s, 26.0206/s/gpu LR: 0.000040 Logit Scale: 84.008 Contrastive_loss: 0.083842 (0.083842) Loss: 0.083842 (0.083842)
2025-06-07,12:53:34 | INFO | Train Epoch: 248 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.7902/s, 50.7902/s/gpu LR: 0.000040 Logit Scale: 83.982 Contrastive_loss: 0.069264 (0.076553) Loss: 0.069264 (0.076553)
2025-06-07,12:53:34 | INFO | Start epoch 249
2025-06-07,12:53:36 | INFO | Train Epoch: 249 [  64/1034 (6%)] Data (t): 1.215 Batch (t): 2.402, 26.6420/s, 26.6420/s/gpu LR: 0.000040 Logit Scale: 83.982 Contrastive_loss: 0.078576 (0.078576) Loss: 0.078576 (0.078576)
2025-06-07,12:53:55 | INFO | Train Epoch: 249 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.2428/s, 51.2428/s/gpu LR: 0.000040 Logit Scale: 83.974 Contrastive_loss: 0.11907 (0.098821) Loss: 0.11907 (0.098821)
2025-06-07,12:53:57 | INFO | Eval Epoch: 250 [64 / 1035]	Clip Loss: 7.547548	
2025-06-07,12:54:04 | INFO | Eval Epoch: 250 image_to_text_mean_rank: 335.0831	image_to_text_median_rank: 264.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0222	image_to_text_R@10: 0.0396	text_to_image_mean_rank: 322.5217	text_to_image_median_rank: 263.0000	text_to_image_R@1: 0.0068	text_to_image_R@5: 0.0348	text_to_image_R@10: 0.0502	clip_val_loss: 8.6340	epoch: 250.0000	num_samples: 1035.0000
2025-06-07,12:54:04 | INFO | Start epoch 250
2025-06-07,12:54:06 | INFO | Train Epoch: 250 [  64/1034 (6%)] Data (t): 1.382 Batch (t): 2.586, 24.7523/s, 24.7523/s/gpu LR: 0.000040 Logit Scale: 83.973 Contrastive_loss: 0.027731 (0.027731) Loss: 0.027731 (0.027731)
2025-06-07,12:54:25 | INFO | Train Epoch: 250 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.0911/s, 51.0911/s/gpu LR: 0.000040 Logit Scale: 83.960 Contrastive_loss: 0.078486 (0.053109) Loss: 0.078486 (0.053109)
2025-06-07,12:54:25 | INFO | Start epoch 251
2025-06-07,12:54:28 | INFO | Train Epoch: 251 [  64/1034 (6%)] Data (t): 1.153 Batch (t): 2.370, 27.0062/s, 27.0062/s/gpu LR: 0.000040 Logit Scale: 83.960 Contrastive_loss: 0.068179 (0.068179) Loss: 0.068179 (0.068179)
2025-06-07,12:54:46 | INFO | Train Epoch: 251 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.9984/s, 50.9984/s/gpu LR: 0.000040 Logit Scale: 83.967 Contrastive_loss: 0.11687 (0.092527) Loss: 0.11687 (0.092527)
2025-06-07,12:54:46 | INFO | Start epoch 252
2025-06-07,12:54:49 | INFO | Train Epoch: 252 [  64/1034 (6%)] Data (t): 1.272 Batch (t): 2.454, 26.0849/s, 26.0849/s/gpu LR: 0.000040 Logit Scale: 83.967 Contrastive_loss: 0.041736 (0.041736) Loss: 0.041736 (0.041736)
2025-06-07,12:55:08 | INFO | Train Epoch: 252 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.1199/s, 51.1199/s/gpu LR: 0.000040 Logit Scale: 83.957 Contrastive_loss: 0.11505 (0.078393) Loss: 0.11505 (0.078393)
2025-06-07,12:55:08 | INFO | Start epoch 253
2025-06-07,12:55:10 | INFO | Train Epoch: 253 [  64/1034 (6%)] Data (t): 1.265 Batch (t): 2.457, 26.0501/s, 26.0501/s/gpu LR: 0.000040 Logit Scale: 83.956 Contrastive_loss: 0.12092 (0.12092) Loss: 0.12092 (0.12092)
2025-06-07,12:55:29 | INFO | Train Epoch: 253 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.249, 51.2438/s, 51.2438/s/gpu LR: 0.000041 Logit Scale: 83.935 Contrastive_loss: 0.19593 (0.15843) Loss: 0.19593 (0.15843)
2025-06-07,12:55:29 | INFO | Start epoch 254
2025-06-07,12:55:32 | INFO | Train Epoch: 254 [  64/1034 (6%)] Data (t): 1.230 Batch (t): 2.428, 26.3644/s, 26.3644/s/gpu LR: 0.000041 Logit Scale: 83.933 Contrastive_loss: 0.044849 (0.044849) Loss: 0.044849 (0.044849)
2025-06-07,12:55:50 | INFO | Train Epoch: 254 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.2440/s, 51.2440/s/gpu LR: 0.000041 Logit Scale: 83.922 Contrastive_loss: 0.0036605 (0.024255) Loss: 0.0036605 (0.024255)
2025-06-07,12:55:51 | INFO | Start epoch 255
2025-06-07,12:55:53 | INFO | Train Epoch: 255 [  64/1034 (6%)] Data (t): 1.188 Batch (t): 2.400, 26.6621/s, 26.6621/s/gpu LR: 0.000041 Logit Scale: 83.921 Contrastive_loss: 0.045861 (0.045861) Loss: 0.045861 (0.045861)
2025-06-07,12:56:12 | INFO | Train Epoch: 255 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.255, 51.2974/s, 51.2974/s/gpu LR: 0.000041 Logit Scale: 83.911 Contrastive_loss: 0.11259 (0.079224) Loss: 0.11259 (0.079224)
2025-06-07,12:56:12 | INFO | Start epoch 256
2025-06-07,12:56:14 | INFO | Train Epoch: 256 [  64/1034 (6%)] Data (t): 1.250 Batch (t): 2.462, 25.9909/s, 25.9909/s/gpu LR: 0.000041 Logit Scale: 83.911 Contrastive_loss: 0.0034624 (0.0034624) Loss: 0.0034624 (0.0034624)
2025-06-07,12:56:33 | INFO | Train Epoch: 256 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8593/s, 50.8593/s/gpu LR: 0.000041 Logit Scale: 83.910 Contrastive_loss: 0.010253 (0.0068575) Loss: 0.010253 (0.0068575)
2025-06-07,12:56:33 | INFO | Start epoch 257
2025-06-07,12:56:36 | INFO | Train Epoch: 257 [  64/1034 (6%)] Data (t): 1.248 Batch (t): 2.442, 26.2071/s, 26.2071/s/gpu LR: 0.000041 Logit Scale: 83.910 Contrastive_loss: 0.11580 (0.11580) Loss: 0.11580 (0.11580)
2025-06-07,12:56:55 | INFO | Train Epoch: 257 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0090/s, 51.0090/s/gpu LR: 0.000041 Logit Scale: 83.898 Contrastive_loss: 0.12562 (0.12071) Loss: 0.12562 (0.12071)
2025-06-07,12:56:55 | INFO | Start epoch 258
2025-06-07,12:56:57 | INFO | Train Epoch: 258 [  64/1034 (6%)] Data (t): 1.250 Batch (t): 2.441, 26.2219/s, 26.2219/s/gpu LR: 0.000041 Logit Scale: 83.896 Contrastive_loss: 0.11236 (0.11236) Loss: 0.11236 (0.11236)
2025-06-07,12:57:16 | INFO | Train Epoch: 258 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 50.9926/s, 50.9926/s/gpu LR: 0.000041 Logit Scale: 83.884 Contrastive_loss: 0.092932 (0.10265) Loss: 0.092932 (0.10265)
2025-06-07,12:57:16 | INFO | Start epoch 259
2025-06-07,12:57:19 | INFO | Train Epoch: 259 [  64/1034 (6%)] Data (t): 1.216 Batch (t): 2.413, 26.5239/s, 26.5239/s/gpu LR: 0.000041 Logit Scale: 83.883 Contrastive_loss: 0.0018849 (0.0018849) Loss: 0.0018849 (0.0018849)
2025-06-07,12:57:37 | INFO | Train Epoch: 259 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.254, 51.3292/s, 51.3292/s/gpu LR: 0.000042 Logit Scale: 83.875 Contrastive_loss: 0.065351 (0.033618) Loss: 0.065351 (0.033618)
2025-06-07,12:57:39 | INFO | Eval Epoch: 260 [64 / 1035]	Clip Loss: 8.749708	
2025-06-07,12:57:46 | INFO | Eval Epoch: 260 image_to_text_mean_rank: 339.2918	image_to_text_median_rank: 279.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0271	image_to_text_R@10: 0.0406	text_to_image_mean_rank: 320.9932	text_to_image_median_rank: 253.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0386	text_to_image_R@10: 0.0512	clip_val_loss: 9.4964	epoch: 260.0000	num_samples: 1035.0000
2025-06-07,12:57:46 | INFO | Start epoch 260
2025-06-07,12:57:48 | INFO | Train Epoch: 260 [  64/1034 (6%)] Data (t): 1.177 Batch (t): 2.385, 26.8339/s, 26.8339/s/gpu LR: 0.000042 Logit Scale: 83.875 Contrastive_loss: 0.10304 (0.10304) Loss: 0.10304 (0.10304)
2025-06-07,12:58:07 | INFO | Train Epoch: 260 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.256, 50.9513/s, 50.9513/s/gpu LR: 0.000042 Logit Scale: 83.848 Contrastive_loss: 0.050526 (0.076783) Loss: 0.050526 (0.076783)
2025-06-07,12:58:07 | INFO | Start epoch 261
2025-06-07,12:58:10 | INFO | Train Epoch: 261 [  64/1034 (6%)] Data (t): 1.259 Batch (t): 2.473, 25.8822/s, 25.8822/s/gpu LR: 0.000042 Logit Scale: 83.848 Contrastive_loss: 0.052617 (0.052617) Loss: 0.052617 (0.052617)
2025-06-07,12:58:28 | INFO | Train Epoch: 261 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.254, 50.9586/s, 50.9586/s/gpu LR: 0.000042 Logit Scale: 83.844 Contrastive_loss: 0.11502 (0.083820) Loss: 0.11502 (0.083820)
2025-06-07,12:58:28 | INFO | Start epoch 262
2025-06-07,12:58:31 | INFO | Train Epoch: 262 [  64/1034 (6%)] Data (t): 1.207 Batch (t): 2.403, 26.6292/s, 26.6292/s/gpu LR: 0.000042 Logit Scale: 83.845 Contrastive_loss: 0.025359 (0.025359) Loss: 0.025359 (0.025359)
2025-06-07,12:58:50 | INFO | Train Epoch: 262 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0832/s, 51.0832/s/gpu LR: 0.000042 Logit Scale: 83.850 Contrastive_loss: 0.028291 (0.026825) Loss: 0.028291 (0.026825)
2025-06-07,12:58:50 | INFO | Start epoch 263
2025-06-07,12:58:52 | INFO | Train Epoch: 263 [  64/1034 (6%)] Data (t): 1.253 Batch (t): 2.429, 26.3438/s, 26.3438/s/gpu LR: 0.000042 Logit Scale: 83.851 Contrastive_loss: 0.042182 (0.042182) Loss: 0.042182 (0.042182)
2025-06-07,12:59:11 | INFO | Train Epoch: 263 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.249, 51.1206/s, 51.1206/s/gpu LR: 0.000042 Logit Scale: 83.839 Contrastive_loss: 0.11413 (0.078157) Loss: 0.11413 (0.078157)
2025-06-07,12:59:11 | INFO | Start epoch 264
2025-06-07,12:59:14 | INFO | Train Epoch: 264 [  64/1034 (6%)] Data (t): 1.351 Batch (t): 2.535, 25.2492/s, 25.2492/s/gpu LR: 0.000042 Logit Scale: 83.838 Contrastive_loss: 0.068823 (0.068823) Loss: 0.068823 (0.068823)
2025-06-07,12:59:32 | INFO | Train Epoch: 264 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.7287/s, 50.7287/s/gpu LR: 0.000042 Logit Scale: 83.821 Contrastive_loss: 0.062473 (0.065648) Loss: 0.062473 (0.065648)
2025-06-07,12:59:33 | INFO | Start epoch 265
2025-06-07,12:59:35 | INFO | Train Epoch: 265 [  64/1034 (6%)] Data (t): 1.147 Batch (t): 2.347, 27.2663/s, 27.2663/s/gpu LR: 0.000042 Logit Scale: 83.821 Contrastive_loss: 0.077344 (0.077344) Loss: 0.077344 (0.077344)
2025-06-07,12:59:54 | INFO | Train Epoch: 265 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.0926/s, 51.0926/s/gpu LR: 0.000043 Logit Scale: 83.810 Contrastive_loss: 0.048489 (0.062916) Loss: 0.048489 (0.062916)
2025-06-07,12:59:54 | INFO | Start epoch 266
2025-06-07,12:59:56 | INFO | Train Epoch: 266 [  64/1034 (6%)] Data (t): 1.239 Batch (t): 2.434, 26.2922/s, 26.2922/s/gpu LR: 0.000043 Logit Scale: 83.810 Contrastive_loss: 0.029651 (0.029651) Loss: 0.029651 (0.029651)
2025-06-07,13:00:15 | INFO | Train Epoch: 266 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.3347/s, 51.3347/s/gpu LR: 0.000043 Logit Scale: 83.802 Contrastive_loss: 0.027105 (0.028378) Loss: 0.027105 (0.028378)
2025-06-07,13:00:15 | INFO | Start epoch 267
2025-06-07,13:00:18 | INFO | Train Epoch: 267 [  64/1034 (6%)] Data (t): 1.279 Batch (t): 2.463, 25.9890/s, 25.9890/s/gpu LR: 0.000043 Logit Scale: 83.802 Contrastive_loss: 0.090917 (0.090917) Loss: 0.090917 (0.090917)
2025-06-07,13:00:37 | INFO | Train Epoch: 267 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.6906/s, 50.6906/s/gpu LR: 0.000043 Logit Scale: 83.790 Contrastive_loss: 0.15172 (0.12132) Loss: 0.15172 (0.12132)
2025-06-07,13:00:37 | INFO | Start epoch 268
2025-06-07,13:00:39 | INFO | Train Epoch: 268 [  64/1034 (6%)] Data (t): 1.228 Batch (t): 2.426, 26.3816/s, 26.3816/s/gpu LR: 0.000043 Logit Scale: 83.788 Contrastive_loss: 0.045392 (0.045392) Loss: 0.045392 (0.045392)
2025-06-07,13:00:58 | INFO | Train Epoch: 268 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.253, 51.0032/s, 51.0032/s/gpu LR: 0.000043 Logit Scale: 83.768 Contrastive_loss: 0.057448 (0.051420) Loss: 0.057448 (0.051420)
2025-06-07,13:00:58 | INFO | Start epoch 269
2025-06-07,13:01:01 | INFO | Train Epoch: 269 [  64/1034 (6%)] Data (t): 1.254 Batch (t): 2.468, 25.9331/s, 25.9331/s/gpu LR: 0.000043 Logit Scale: 83.767 Contrastive_loss: 0.10965 (0.10965) Loss: 0.10965 (0.10965)
2025-06-07,13:01:19 | INFO | Train Epoch: 269 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 50.3585/s, 50.3585/s/gpu LR: 0.000043 Logit Scale: 83.753 Contrastive_loss: 0.058613 (0.084133) Loss: 0.058613 (0.084133)
2025-06-07,13:01:21 | INFO | Eval Epoch: 270 [64 / 1035]	Clip Loss: 8.341772	
2025-06-07,13:01:28 | INFO | Eval Epoch: 270 image_to_text_mean_rank: 341.4348	image_to_text_median_rank: 273.0000	image_to_text_R@1: 0.0029	image_to_text_R@5: 0.0106	image_to_text_R@10: 0.0300	text_to_image_mean_rank: 323.3333	text_to_image_median_rank: 249.0000	text_to_image_R@1: 0.0048	text_to_image_R@5: 0.0222	text_to_image_R@10: 0.0541	clip_val_loss: 8.4533	epoch: 270.0000	num_samples: 1035.0000
2025-06-07,13:01:28 | INFO | Start epoch 270
2025-06-07,13:01:30 | INFO | Train Epoch: 270 [  64/1034 (6%)] Data (t): 1.271 Batch (t): 2.481, 25.7941/s, 25.7941/s/gpu LR: 0.000043 Logit Scale: 83.753 Contrastive_loss: 0.18628 (0.18628) Loss: 0.18628 (0.18628)
2025-06-07,13:01:49 | INFO | Train Epoch: 270 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1928/s, 51.1928/s/gpu LR: 0.000043 Logit Scale: 83.754 Contrastive_loss: 0.035668 (0.11097) Loss: 0.035668 (0.11097)
2025-06-07,13:01:49 | INFO | Start epoch 271
2025-06-07,13:01:52 | INFO | Train Epoch: 271 [  64/1034 (6%)] Data (t): 1.312 Batch (t): 2.505, 25.5442/s, 25.5442/s/gpu LR: 0.000043 Logit Scale: 83.754 Contrastive_loss: 0.0075851 (0.0075851) Loss: 0.0075851 (0.0075851)
2025-06-07,13:02:11 | INFO | Train Epoch: 271 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9494/s, 50.9494/s/gpu LR: 0.000044 Logit Scale: 83.752 Contrastive_loss: 0.11441 (0.060999) Loss: 0.11441 (0.060999)
2025-06-07,13:02:11 | INFO | Start epoch 272
2025-06-07,13:02:13 | INFO | Train Epoch: 272 [  64/1034 (6%)] Data (t): 1.279 Batch (t): 2.492, 25.6842/s, 25.6842/s/gpu LR: 0.000044 Logit Scale: 83.752 Contrastive_loss: 0.094608 (0.094608) Loss: 0.094608 (0.094608)
2025-06-07,13:02:32 | INFO | Train Epoch: 272 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8529/s, 50.8529/s/gpu LR: 0.000044 Logit Scale: 83.742 Contrastive_loss: 0.030012 (0.062310) Loss: 0.030012 (0.062310)
2025-06-07,13:02:32 | INFO | Start epoch 273
2025-06-07,13:02:35 | INFO | Train Epoch: 273 [  64/1034 (6%)] Data (t): 1.305 Batch (t): 2.489, 25.7155/s, 25.7155/s/gpu LR: 0.000044 Logit Scale: 83.742 Contrastive_loss: 0.063199 (0.063199) Loss: 0.063199 (0.063199)
2025-06-07,13:02:53 | INFO | Train Epoch: 273 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1439/s, 51.1439/s/gpu LR: 0.000044 Logit Scale: 83.729 Contrastive_loss: 0.13648 (0.099839) Loss: 0.13648 (0.099839)
2025-06-07,13:02:53 | INFO | Start epoch 274
2025-06-07,13:02:56 | INFO | Train Epoch: 274 [  64/1034 (6%)] Data (t): 1.226 Batch (t): 2.440, 26.2344/s, 26.2344/s/gpu LR: 0.000044 Logit Scale: 83.728 Contrastive_loss: 0.11402 (0.11402) Loss: 0.11402 (0.11402)
2025-06-07,13:03:15 | INFO | Train Epoch: 274 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.251, 51.0904/s, 51.0904/s/gpu LR: 0.000044 Logit Scale: 83.712 Contrastive_loss: 0.096265 (0.10514) Loss: 0.096265 (0.10514)
2025-06-07,13:03:15 | INFO | Start epoch 275
2025-06-07,13:03:17 | INFO | Train Epoch: 275 [  64/1034 (6%)] Data (t): 1.292 Batch (t): 2.487, 25.7312/s, 25.7312/s/gpu LR: 0.000044 Logit Scale: 83.711 Contrastive_loss: 0.086771 (0.086771) Loss: 0.086771 (0.086771)
2025-06-07,13:03:36 | INFO | Train Epoch: 275 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.8867/s, 50.8867/s/gpu LR: 0.000044 Logit Scale: 83.695 Contrastive_loss: 0.039985 (0.063378) Loss: 0.039985 (0.063378)
2025-06-07,13:03:36 | INFO | Start epoch 276
2025-06-07,13:03:39 | INFO | Train Epoch: 276 [  64/1034 (6%)] Data (t): 1.233 Batch (t): 2.435, 26.2877/s, 26.2877/s/gpu LR: 0.000044 Logit Scale: 83.695 Contrastive_loss: 0.074746 (0.074746) Loss: 0.074746 (0.074746)
2025-06-07,13:03:58 | INFO | Train Epoch: 276 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1737/s, 51.1737/s/gpu LR: 0.000044 Logit Scale: 83.679 Contrastive_loss: 0.082533 (0.078640) Loss: 0.082533 (0.078640)
2025-06-07,13:03:58 | INFO | Start epoch 277
2025-06-07,13:04:00 | INFO | Train Epoch: 277 [  64/1034 (6%)] Data (t): 1.196 Batch (t): 2.391, 26.7618/s, 26.7618/s/gpu LR: 0.000044 Logit Scale: 83.678 Contrastive_loss: 0.11146 (0.11146) Loss: 0.11146 (0.11146)
2025-06-07,13:04:19 | INFO | Train Epoch: 277 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.7123/s, 50.7123/s/gpu LR: 0.000044 Logit Scale: 83.665 Contrastive_loss: 0.048060 (0.079758) Loss: 0.048060 (0.079758)
2025-06-07,13:04:19 | INFO | Start epoch 278
2025-06-07,13:04:21 | INFO | Train Epoch: 278 [  64/1034 (6%)] Data (t): 1.261 Batch (t): 2.460, 26.0132/s, 26.0132/s/gpu LR: 0.000044 Logit Scale: 83.665 Contrastive_loss: 0.0077465 (0.0077465) Loss: 0.0077465 (0.0077465)
2025-06-07,13:04:40 | INFO | Train Epoch: 278 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.1233/s, 51.1233/s/gpu LR: 0.000045 Logit Scale: 83.668 Contrastive_loss: 0.086712 (0.047229) Loss: 0.086712 (0.047229)
2025-06-07,13:04:40 | INFO | Start epoch 279
2025-06-07,13:04:43 | INFO | Train Epoch: 279 [  64/1034 (6%)] Data (t): 1.260 Batch (t): 2.473, 25.8759/s, 25.8759/s/gpu LR: 0.000045 Logit Scale: 83.667 Contrastive_loss: 0.011680 (0.011680) Loss: 0.011680 (0.011680)
2025-06-07,13:05:02 | INFO | Train Epoch: 279 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.253, 50.9908/s, 50.9908/s/gpu LR: 0.000045 Logit Scale: 83.646 Contrastive_loss: 0.038150 (0.024915) Loss: 0.038150 (0.024915)
2025-06-07,13:05:03 | INFO | Eval Epoch: 280 [64 / 1035]	Clip Loss: 8.260162	
2025-06-07,13:05:10 | INFO | Eval Epoch: 280 image_to_text_mean_rank: 329.8242	image_to_text_median_rank: 262.0000	image_to_text_R@1: 0.0039	image_to_text_R@5: 0.0242	image_to_text_R@10: 0.0435	text_to_image_mean_rank: 317.7024	text_to_image_median_rank: 235.0000	text_to_image_R@1: 0.0068	text_to_image_R@5: 0.0261	text_to_image_R@10: 0.0464	clip_val_loss: 8.8616	epoch: 280.0000	num_samples: 1035.0000
2025-06-07,13:05:10 | INFO | Start epoch 280
2025-06-07,13:05:12 | INFO | Train Epoch: 280 [  64/1034 (6%)] Data (t): 1.184 Batch (t): 2.400, 26.6676/s, 26.6676/s/gpu LR: 0.000045 Logit Scale: 83.644 Contrastive_loss: 0.092328 (0.092328) Loss: 0.092328 (0.092328)
2025-06-07,13:05:31 | INFO | Train Epoch: 280 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.0194/s, 51.0194/s/gpu LR: 0.000045 Logit Scale: 83.622 Contrastive_loss: 0.18872 (0.14052) Loss: 0.18872 (0.14052)
2025-06-07,13:05:31 | INFO | Start epoch 281
2025-06-07,13:05:34 | INFO | Train Epoch: 281 [  64/1034 (6%)] Data (t): 1.190 Batch (t): 2.396, 26.7157/s, 26.7157/s/gpu LR: 0.000045 Logit Scale: 83.620 Contrastive_loss: 0.0095556 (0.0095556) Loss: 0.0095556 (0.0095556)
2025-06-07,13:05:53 | INFO | Train Epoch: 281 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0377/s, 51.0377/s/gpu LR: 0.000045 Logit Scale: 83.609 Contrastive_loss: 0.047086 (0.028321) Loss: 0.047086 (0.028321)
2025-06-07,13:05:53 | INFO | Start epoch 282
2025-06-07,13:05:55 | INFO | Train Epoch: 282 [  64/1034 (6%)] Data (t): 1.214 Batch (t): 2.415, 26.4994/s, 26.4994/s/gpu LR: 0.000045 Logit Scale: 83.609 Contrastive_loss: 0.0047302 (0.0047302) Loss: 0.0047302 (0.0047302)
2025-06-07,13:06:14 | INFO | Train Epoch: 282 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.2872/s, 51.2872/s/gpu LR: 0.000045 Logit Scale: 83.594 Contrastive_loss: 0.13220 (0.068465) Loss: 0.13220 (0.068465)
2025-06-07,13:06:14 | INFO | Start epoch 283
2025-06-07,13:06:17 | INFO | Train Epoch: 283 [  64/1034 (6%)] Data (t): 1.288 Batch (t): 2.465, 25.9683/s, 25.9683/s/gpu LR: 0.000045 Logit Scale: 83.593 Contrastive_loss: 0.027150 (0.027150) Loss: 0.027150 (0.027150)
2025-06-07,13:06:35 | INFO | Train Epoch: 283 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2761/s, 51.2761/s/gpu LR: 0.000045 Logit Scale: 83.589 Contrastive_loss: 0.039354 (0.033252) Loss: 0.039354 (0.033252)
2025-06-07,13:06:35 | INFO | Start epoch 284
2025-06-07,13:06:38 | INFO | Train Epoch: 284 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.454, 26.0833/s, 26.0833/s/gpu LR: 0.000045 Logit Scale: 83.588 Contrastive_loss: 0.074542 (0.074542) Loss: 0.074542 (0.074542)
2025-06-07,13:06:57 | INFO | Train Epoch: 284 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.251, 51.0719/s, 51.0719/s/gpu LR: 0.000046 Logit Scale: 83.570 Contrastive_loss: 0.051324 (0.062933) Loss: 0.051324 (0.062933)
2025-06-07,13:06:57 | INFO | Start epoch 285
2025-06-07,13:07:00 | INFO | Train Epoch: 285 [  64/1034 (6%)] Data (t): 2.163 Batch (t): 3.369, 18.9995/s, 18.9995/s/gpu LR: 0.000046 Logit Scale: 83.569 Contrastive_loss: 0.073277 (0.073277) Loss: 0.073277 (0.073277)
2025-06-07,13:07:20 | INFO | Train Epoch: 285 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.284, 50.9681/s, 50.9681/s/gpu LR: 0.000046 Logit Scale: 83.555 Contrastive_loss: 0.089560 (0.081419) Loss: 0.089560 (0.081419)
2025-06-07,13:07:20 | INFO | Start epoch 286
2025-06-07,13:07:23 | INFO | Train Epoch: 286 [  64/1034 (6%)] Data (t): 1.736 Batch (t): 2.956, 21.6487/s, 21.6487/s/gpu LR: 0.000046 Logit Scale: 83.553 Contrastive_loss: 0.079160 (0.079160) Loss: 0.079160 (0.079160)
2025-06-07,13:07:42 | INFO | Train Epoch: 286 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.256, 51.0403/s, 51.0403/s/gpu LR: 0.000046 Logit Scale: 83.529 Contrastive_loss: 0.060805 (0.069982) Loss: 0.060805 (0.069982)
2025-06-07,13:07:42 | INFO | Start epoch 287
2025-06-07,13:07:44 | INFO | Train Epoch: 287 [  64/1034 (6%)] Data (t): 1.651 Batch (t): 2.847, 22.4832/s, 22.4832/s/gpu LR: 0.000046 Logit Scale: 83.528 Contrastive_loss: 0.068123 (0.068123) Loss: 0.068123 (0.068123)
2025-06-07,13:08:03 | INFO | Train Epoch: 287 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0573/s, 51.0573/s/gpu LR: 0.000046 Logit Scale: 83.527 Contrastive_loss: 0.15945 (0.11379) Loss: 0.15945 (0.11379)
2025-06-07,13:08:03 | INFO | Start epoch 288
2025-06-07,13:08:06 | INFO | Train Epoch: 288 [  64/1034 (6%)] Data (t): 1.254 Batch (t): 2.458, 26.0414/s, 26.0414/s/gpu LR: 0.000046 Logit Scale: 83.526 Contrastive_loss: 0.15985 (0.15985) Loss: 0.15985 (0.15985)
2025-06-07,13:08:25 | INFO | Train Epoch: 288 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.8409/s, 50.8409/s/gpu LR: 0.000046 Logit Scale: 83.518 Contrastive_loss: 0.014924 (0.087385) Loss: 0.014924 (0.087385)
2025-06-07,13:08:25 | INFO | Start epoch 289
2025-06-07,13:08:27 | INFO | Train Epoch: 289 [  64/1034 (6%)] Data (t): 1.279 Batch (t): 2.457, 26.0529/s, 26.0529/s/gpu LR: 0.000046 Logit Scale: 83.518 Contrastive_loss: 0.010521 (0.010521) Loss: 0.010521 (0.010521)
2025-06-07,13:08:46 | INFO | Train Epoch: 289 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.9600/s, 50.9600/s/gpu LR: 0.000046 Logit Scale: 83.514 Contrastive_loss: 0.055719 (0.033120) Loss: 0.055719 (0.033120)
2025-06-07,13:08:48 | INFO | Eval Epoch: 290 [64 / 1035]	Clip Loss: 8.480953	
2025-06-07,13:08:55 | INFO | Eval Epoch: 290 image_to_text_mean_rank: 332.1971	image_to_text_median_rank: 250.0000	image_to_text_R@1: 0.0039	image_to_text_R@5: 0.0251	image_to_text_R@10: 0.0444	text_to_image_mean_rank: 328.0406	text_to_image_median_rank: 252.0000	text_to_image_R@1: 0.0048	text_to_image_R@5: 0.0261	text_to_image_R@10: 0.0425	clip_val_loss: 9.3537	epoch: 290.0000	num_samples: 1035.0000
2025-06-07,13:08:55 | INFO | Start epoch 290
2025-06-07,13:08:57 | INFO | Train Epoch: 290 [  64/1034 (6%)] Data (t): 1.239 Batch (t): 2.441, 26.2225/s, 26.2225/s/gpu LR: 0.000046 Logit Scale: 83.513 Contrastive_loss: 0.098441 (0.098441) Loss: 0.098441 (0.098441)
2025-06-07,13:09:16 | INFO | Train Epoch: 290 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.253, 51.1399/s, 51.1399/s/gpu LR: 0.000047 Logit Scale: 83.496 Contrastive_loss: 0.0042129 (0.051327) Loss: 0.0042129 (0.051327)
2025-06-07,13:09:16 | INFO | Start epoch 291
2025-06-07,13:09:18 | INFO | Train Epoch: 291 [  64/1034 (6%)] Data (t): 1.168 Batch (t): 2.372, 26.9833/s, 26.9833/s/gpu LR: 0.000047 Logit Scale: 83.494 Contrastive_loss: 0.082187 (0.082187) Loss: 0.082187 (0.082187)
2025-06-07,13:09:37 | INFO | Train Epoch: 291 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.5763/s, 50.5763/s/gpu LR: 0.000047 Logit Scale: 83.484 Contrastive_loss: 0.043592 (0.062890) Loss: 0.043592 (0.062890)
2025-06-07,13:09:37 | INFO | Start epoch 292
2025-06-07,13:09:40 | INFO | Train Epoch: 292 [  64/1034 (6%)] Data (t): 1.165 Batch (t): 2.359, 27.1247/s, 27.1247/s/gpu LR: 0.000047 Logit Scale: 83.483 Contrastive_loss: 0.15666 (0.15666) Loss: 0.15666 (0.15666)
2025-06-07,13:09:59 | INFO | Train Epoch: 292 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.0890/s, 51.0890/s/gpu LR: 0.000047 Logit Scale: 83.464 Contrastive_loss: 0.055962 (0.10631) Loss: 0.055962 (0.10631)
2025-06-07,13:09:59 | INFO | Start epoch 293
2025-06-07,13:10:01 | INFO | Train Epoch: 293 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.434, 26.2953/s, 26.2953/s/gpu LR: 0.000047 Logit Scale: 83.463 Contrastive_loss: 0.058883 (0.058883) Loss: 0.058883 (0.058883)
2025-06-07,13:10:20 | INFO | Train Epoch: 293 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.253, 51.0738/s, 51.0738/s/gpu LR: 0.000047 Logit Scale: 83.456 Contrastive_loss: 0.0016398 (0.030261) Loss: 0.0016398 (0.030261)
2025-06-07,13:10:20 | INFO | Start epoch 294
2025-06-07,13:10:22 | INFO | Train Epoch: 294 [  64/1034 (6%)] Data (t): 1.224 Batch (t): 2.413, 26.5265/s, 26.5265/s/gpu LR: 0.000047 Logit Scale: 83.456 Contrastive_loss: 0.036633 (0.036633) Loss: 0.036633 (0.036633)
2025-06-07,13:10:41 | INFO | Train Epoch: 294 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.0765/s, 51.0765/s/gpu LR: 0.000047 Logit Scale: 83.445 Contrastive_loss: 0.058386 (0.047510) Loss: 0.058386 (0.047510)
2025-06-07,13:10:41 | INFO | Start epoch 295
2025-06-07,13:10:44 | INFO | Train Epoch: 295 [  64/1034 (6%)] Data (t): 1.242 Batch (t): 2.434, 26.2937/s, 26.2937/s/gpu LR: 0.000047 Logit Scale: 83.444 Contrastive_loss: 0.0088456 (0.0088456) Loss: 0.0088456 (0.0088456)
2025-06-07,13:11:03 | INFO | Train Epoch: 295 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.254, 51.1635/s, 51.1635/s/gpu LR: 0.000047 Logit Scale: 83.418 Contrastive_loss: 0.18744 (0.098145) Loss: 0.18744 (0.098145)
2025-06-07,13:11:03 | INFO | Start epoch 296
2025-06-07,13:11:05 | INFO | Train Epoch: 296 [  64/1034 (6%)] Data (t): 1.277 Batch (t): 2.456, 26.0564/s, 26.0564/s/gpu LR: 0.000047 Logit Scale: 83.416 Contrastive_loss: 0.11878 (0.11878) Loss: 0.11878 (0.11878)
2025-06-07,13:11:24 | INFO | Train Epoch: 296 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2931/s, 51.2931/s/gpu LR: 0.000048 Logit Scale: 83.405 Contrastive_loss: 0.074885 (0.096834) Loss: 0.074885 (0.096834)
2025-06-07,13:11:24 | INFO | Start epoch 297
2025-06-07,13:11:27 | INFO | Train Epoch: 297 [  64/1034 (6%)] Data (t): 1.336 Batch (t): 2.525, 25.3513/s, 25.3513/s/gpu LR: 0.000048 Logit Scale: 83.405 Contrastive_loss: 0.011360 (0.011360) Loss: 0.011360 (0.011360)
2025-06-07,13:11:45 | INFO | Train Epoch: 297 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.4437/s, 51.4437/s/gpu LR: 0.000048 Logit Scale: 83.403 Contrastive_loss: 0.15537 (0.083365) Loss: 0.15537 (0.083365)
2025-06-07,13:11:46 | INFO | Start epoch 298
2025-06-07,13:11:48 | INFO | Train Epoch: 298 [  64/1034 (6%)] Data (t): 1.222 Batch (t): 2.428, 26.3583/s, 26.3583/s/gpu LR: 0.000048 Logit Scale: 83.401 Contrastive_loss: 0.050707 (0.050707) Loss: 0.050707 (0.050707)
2025-06-07,13:12:07 | INFO | Train Epoch: 298 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.8315/s, 50.8315/s/gpu LR: 0.000048 Logit Scale: 83.390 Contrastive_loss: 0.026923 (0.038815) Loss: 0.026923 (0.038815)
2025-06-07,13:12:07 | INFO | Start epoch 299
2025-06-07,13:12:09 | INFO | Train Epoch: 299 [  64/1034 (6%)] Data (t): 1.174 Batch (t): 2.383, 26.8552/s, 26.8552/s/gpu LR: 0.000048 Logit Scale: 83.390 Contrastive_loss: 0.10433 (0.10433) Loss: 0.10433 (0.10433)
2025-06-07,13:12:28 | INFO | Train Epoch: 299 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 50.8836/s, 50.8836/s/gpu LR: 0.000048 Logit Scale: 83.389 Contrastive_loss: 0.031652 (0.067991) Loss: 0.031652 (0.067991)
2025-06-07,13:12:30 | INFO | Eval Epoch: 300 [64 / 1035]	Clip Loss: 7.814470	
2025-06-07,13:12:37 | INFO | Eval Epoch: 300 image_to_text_mean_rank: 337.4019	image_to_text_median_rank: 269.0000	image_to_text_R@1: 0.0116	image_to_text_R@5: 0.0367	image_to_text_R@10: 0.0483	text_to_image_mean_rank: 325.3391	text_to_image_median_rank: 240.0000	text_to_image_R@1: 0.0068	text_to_image_R@5: 0.0290	text_to_image_R@10: 0.0522	clip_val_loss: 8.5943	epoch: 300.0000	num_samples: 1035.0000
2025-06-07,13:12:40 | INFO | Start epoch 300
2025-06-07,13:12:42 | INFO | Train Epoch: 300 [  64/1034 (6%)] Data (t): 1.271 Batch (t): 2.509, 25.5081/s, 25.5081/s/gpu LR: 0.000048 Logit Scale: 83.388 Contrastive_loss: 0.061865 (0.061865) Loss: 0.061865 (0.061865)
2025-06-07,13:13:01 | INFO | Train Epoch: 300 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.248, 51.2192/s, 51.2192/s/gpu LR: 0.000048 Logit Scale: 83.391 Contrastive_loss: 0.084702 (0.073284) Loss: 0.084702 (0.073284)
2025-06-07,13:13:01 | INFO | Start epoch 301
2025-06-07,13:13:04 | INFO | Train Epoch: 301 [  64/1034 (6%)] Data (t): 1.671 Batch (t): 2.875, 22.2617/s, 22.2617/s/gpu LR: 0.000048 Logit Scale: 83.389 Contrastive_loss: 0.026775 (0.026775) Loss: 0.026775 (0.026775)
2025-06-07,13:13:23 | INFO | Train Epoch: 301 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.257, 50.2996/s, 50.2996/s/gpu LR: 0.000048 Logit Scale: 83.368 Contrastive_loss: 0.056259 (0.041517) Loss: 0.056259 (0.041517)
2025-06-07,13:13:23 | INFO | Start epoch 302
2025-06-07,13:13:25 | INFO | Train Epoch: 302 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.444, 26.1818/s, 26.1818/s/gpu LR: 0.000048 Logit Scale: 83.366 Contrastive_loss: 0.074211 (0.074211) Loss: 0.074211 (0.074211)
2025-06-07,13:13:44 | INFO | Train Epoch: 302 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.5506/s, 51.5506/s/gpu LR: 0.000048 Logit Scale: 83.343 Contrastive_loss: 0.084559 (0.079385) Loss: 0.084559 (0.079385)
2025-06-07,13:13:44 | INFO | Start epoch 303
2025-06-07,13:13:47 | INFO | Train Epoch: 303 [  64/1034 (6%)] Data (t): 1.222 Batch (t): 2.417, 26.4746/s, 26.4746/s/gpu LR: 0.000048 Logit Scale: 83.340 Contrastive_loss: 0.086102 (0.086102) Loss: 0.086102 (0.086102)
2025-06-07,13:14:06 | INFO | Train Epoch: 303 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0397/s, 51.0397/s/gpu LR: 0.000049 Logit Scale: 83.322 Contrastive_loss: 0.099822 (0.092962) Loss: 0.099822 (0.092962)
2025-06-07,13:14:06 | INFO | Start epoch 304
2025-06-07,13:14:08 | INFO | Train Epoch: 304 [  64/1034 (6%)] Data (t): 1.362 Batch (t): 2.536, 25.2354/s, 25.2354/s/gpu LR: 0.000049 Logit Scale: 83.322 Contrastive_loss: 0.023747 (0.023747) Loss: 0.023747 (0.023747)
2025-06-07,13:14:27 | INFO | Train Epoch: 304 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.249, 51.0114/s, 51.0114/s/gpu LR: 0.000049 Logit Scale: 83.318 Contrastive_loss: 0.011801 (0.017774) Loss: 0.011801 (0.017774)
2025-06-07,13:14:27 | INFO | Start epoch 305
2025-06-07,13:14:30 | INFO | Train Epoch: 305 [  64/1034 (6%)] Data (t): 1.330 Batch (t): 2.528, 25.3124/s, 25.3124/s/gpu LR: 0.000049 Logit Scale: 83.317 Contrastive_loss: 0.042513 (0.042513) Loss: 0.042513 (0.042513)
2025-06-07,13:14:48 | INFO | Train Epoch: 305 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2456/s, 51.2456/s/gpu LR: 0.000049 Logit Scale: 83.306 Contrastive_loss: 0.061200 (0.051857) Loss: 0.061200 (0.051857)
2025-06-07,13:14:48 | INFO | Start epoch 306
2025-06-07,13:14:51 | INFO | Train Epoch: 306 [  64/1034 (6%)] Data (t): 1.210 Batch (t): 2.431, 26.3301/s, 26.3301/s/gpu LR: 0.000049 Logit Scale: 83.305 Contrastive_loss: 0.11746 (0.11746) Loss: 0.11746 (0.11746)
2025-06-07,13:15:10 | INFO | Train Epoch: 306 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.252, 51.2389/s, 51.2389/s/gpu LR: 0.000049 Logit Scale: 83.282 Contrastive_loss: 0.066269 (0.091867) Loss: 0.066269 (0.091867)
2025-06-07,13:15:10 | INFO | Start epoch 307
2025-06-07,13:15:12 | INFO | Train Epoch: 307 [  64/1034 (6%)] Data (t): 1.259 Batch (t): 2.461, 26.0083/s, 26.0083/s/gpu LR: 0.000049 Logit Scale: 83.281 Contrastive_loss: 0.045901 (0.045901) Loss: 0.045901 (0.045901)
2025-06-07,13:15:31 | INFO | Train Epoch: 307 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.3236/s, 51.3236/s/gpu LR: 0.000049 Logit Scale: 83.281 Contrastive_loss: 0.028645 (0.037273) Loss: 0.028645 (0.037273)
2025-06-07,13:15:31 | INFO | Start epoch 308
2025-06-07,13:15:34 | INFO | Train Epoch: 308 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.440, 26.2276/s, 26.2276/s/gpu LR: 0.000049 Logit Scale: 83.280 Contrastive_loss: 0.074694 (0.074694) Loss: 0.074694 (0.074694)
2025-06-07,13:15:53 | INFO | Train Epoch: 308 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 50.9233/s, 50.9233/s/gpu LR: 0.000049 Logit Scale: 83.270 Contrastive_loss: 0.10980 (0.092247) Loss: 0.10980 (0.092247)
2025-06-07,13:15:53 | INFO | Start epoch 309
2025-06-07,13:15:55 | INFO | Train Epoch: 309 [  64/1034 (6%)] Data (t): 1.248 Batch (t): 2.423, 26.4176/s, 26.4176/s/gpu LR: 0.000049 Logit Scale: 83.270 Contrastive_loss: 0.018676 (0.018676) Loss: 0.018676 (0.018676)
2025-06-07,13:16:14 | INFO | Train Epoch: 309 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.8748/s, 50.8748/s/gpu LR: 0.000050 Logit Scale: 83.248 Contrastive_loss: 0.10762 (0.063147) Loss: 0.10762 (0.063147)
2025-06-07,13:16:16 | INFO | Eval Epoch: 310 [64 / 1035]	Clip Loss: 8.184229	
2025-06-07,13:16:22 | INFO | Eval Epoch: 310 image_to_text_mean_rank: 333.5391	image_to_text_median_rank: 263.0000	image_to_text_R@1: 0.0077	image_to_text_R@5: 0.0232	image_to_text_R@10: 0.0425	text_to_image_mean_rank: 324.2039	text_to_image_median_rank: 246.0000	text_to_image_R@1: 0.0116	text_to_image_R@5: 0.0300	text_to_image_R@10: 0.0454	clip_val_loss: 8.6217	epoch: 310.0000	num_samples: 1035.0000
2025-06-07,13:16:22 | INFO | Start epoch 310
2025-06-07,13:16:25 | INFO | Train Epoch: 310 [  64/1034 (6%)] Data (t): 1.262 Batch (t): 2.457, 26.0443/s, 26.0443/s/gpu LR: 0.000050 Logit Scale: 83.248 Contrastive_loss: 0.13182 (0.13182) Loss: 0.13182 (0.13182)
2025-06-07,13:16:44 | INFO | Train Epoch: 310 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.2339/s, 51.2339/s/gpu LR: 0.000050 Logit Scale: 83.240 Contrastive_loss: 0.035897 (0.083861) Loss: 0.035897 (0.083861)
2025-06-07,13:16:44 | INFO | Start epoch 311
2025-06-07,13:16:46 | INFO | Train Epoch: 311 [  64/1034 (6%)] Data (t): 1.425 Batch (t): 2.622, 24.4051/s, 24.4051/s/gpu LR: 0.000050 Logit Scale: 83.240 Contrastive_loss: 0.062317 (0.062317) Loss: 0.062317 (0.062317)
2025-06-07,13:17:05 | INFO | Train Epoch: 311 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9828/s, 50.9828/s/gpu LR: 0.000050 Logit Scale: 83.228 Contrastive_loss: 0.070279 (0.066298) Loss: 0.070279 (0.066298)
2025-06-07,13:17:05 | INFO | Start epoch 312
2025-06-07,13:17:08 | INFO | Train Epoch: 312 [  64/1034 (6%)] Data (t): 1.244 Batch (t): 2.450, 26.1248/s, 26.1248/s/gpu LR: 0.000050 Logit Scale: 83.226 Contrastive_loss: 0.071004 (0.071004) Loss: 0.071004 (0.071004)
2025-06-07,13:17:27 | INFO | Train Epoch: 312 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.250, 50.9445/s, 50.9445/s/gpu LR: 0.000050 Logit Scale: 83.214 Contrastive_loss: 0.031656 (0.051330) Loss: 0.031656 (0.051330)
2025-06-07,13:17:27 | INFO | Start epoch 313
2025-06-07,13:17:29 | INFO | Train Epoch: 313 [  64/1034 (6%)] Data (t): 1.234 Batch (t): 2.443, 26.1955/s, 26.1955/s/gpu LR: 0.000050 Logit Scale: 83.213 Contrastive_loss: 0.13028 (0.13028) Loss: 0.13028 (0.13028)
2025-06-07,13:17:48 | INFO | Train Epoch: 313 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.253, 50.9979/s, 50.9979/s/gpu LR: 0.000050 Logit Scale: 83.194 Contrastive_loss: 0.0047083 (0.067493) Loss: 0.0047083 (0.067493)
2025-06-07,13:17:48 | INFO | Start epoch 314
2025-06-07,13:17:50 | INFO | Train Epoch: 314 [  64/1034 (6%)] Data (t): 1.205 Batch (t): 2.407, 26.5924/s, 26.5924/s/gpu LR: 0.000050 Logit Scale: 83.192 Contrastive_loss: 0.033670 (0.033670) Loss: 0.033670 (0.033670)
2025-06-07,13:18:09 | INFO | Train Epoch: 314 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.251, 51.3915/s, 51.3915/s/gpu LR: 0.000050 Logit Scale: 83.179 Contrastive_loss: 0.059589 (0.046630) Loss: 0.059589 (0.046630)
2025-06-07,13:18:09 | INFO | Start epoch 315
2025-06-07,13:18:12 | INFO | Train Epoch: 315 [  64/1034 (6%)] Data (t): 1.390 Batch (t): 2.583, 24.7754/s, 24.7754/s/gpu LR: 0.000050 Logit Scale: 83.178 Contrastive_loss: 0.10296 (0.10296) Loss: 0.10296 (0.10296)
2025-06-07,13:18:31 | INFO | Train Epoch: 315 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.9661/s, 50.9661/s/gpu LR: 0.000051 Logit Scale: 83.168 Contrastive_loss: 0.047634 (0.075298) Loss: 0.047634 (0.075298)
2025-06-07,13:18:31 | INFO | Start epoch 316
2025-06-07,13:18:33 | INFO | Train Epoch: 316 [  64/1034 (6%)] Data (t): 1.213 Batch (t): 2.429, 26.3478/s, 26.3478/s/gpu LR: 0.000051 Logit Scale: 83.167 Contrastive_loss: 0.0089547 (0.0089547) Loss: 0.0089547 (0.0089547)
2025-06-07,13:18:52 | INFO | Train Epoch: 316 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 50.7151/s, 50.7151/s/gpu LR: 0.000051 Logit Scale: 83.163 Contrastive_loss: 0.088819 (0.048887) Loss: 0.088819 (0.048887)
2025-06-07,13:18:52 | INFO | Start epoch 317
2025-06-07,13:18:55 | INFO | Train Epoch: 317 [  64/1034 (6%)] Data (t): 1.316 Batch (t): 2.503, 25.5675/s, 25.5675/s/gpu LR: 0.000051 Logit Scale: 83.163 Contrastive_loss: 0.0060689 (0.0060689) Loss: 0.0060689 (0.0060689)
2025-06-07,13:19:14 | INFO | Train Epoch: 317 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.251, 51.0273/s, 51.0273/s/gpu LR: 0.000051 Logit Scale: 83.150 Contrastive_loss: 0.028067 (0.017068) Loss: 0.028067 (0.017068)
2025-06-07,13:19:14 | INFO | Start epoch 318
2025-06-07,13:19:16 | INFO | Train Epoch: 318 [  64/1034 (6%)] Data (t): 1.185 Batch (t): 2.368, 27.0323/s, 27.0323/s/gpu LR: 0.000051 Logit Scale: 83.149 Contrastive_loss: 0.032632 (0.032632) Loss: 0.032632 (0.032632)
2025-06-07,13:19:35 | INFO | Train Epoch: 318 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.252, 51.0915/s, 51.0915/s/gpu LR: 0.000051 Logit Scale: 83.137 Contrastive_loss: 0.028616 (0.030624) Loss: 0.028616 (0.030624)
2025-06-07,13:19:35 | INFO | Start epoch 319
2025-06-07,13:19:37 | INFO | Train Epoch: 319 [  64/1034 (6%)] Data (t): 1.284 Batch (t): 2.465, 25.9668/s, 25.9668/s/gpu LR: 0.000051 Logit Scale: 83.136 Contrastive_loss: 0.075622 (0.075622) Loss: 0.075622 (0.075622)
2025-06-07,13:19:56 | INFO | Train Epoch: 319 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.248, 51.0289/s, 51.0289/s/gpu LR: 0.000051 Logit Scale: 83.131 Contrastive_loss: 0.097054 (0.086338) Loss: 0.097054 (0.086338)
2025-06-07,13:19:58 | INFO | Eval Epoch: 320 [64 / 1035]	Clip Loss: 9.504112	
2025-06-07,13:20:04 | INFO | Eval Epoch: 320 image_to_text_mean_rank: 349.8077	image_to_text_median_rank: 294.0000	image_to_text_R@1: 0.0068	image_to_text_R@5: 0.0271	image_to_text_R@10: 0.0406	text_to_image_mean_rank: 334.3324	text_to_image_median_rank: 274.0000	text_to_image_R@1: 0.0077	text_to_image_R@5: 0.0232	text_to_image_R@10: 0.0415	clip_val_loss: 9.8060	epoch: 320.0000	num_samples: 1035.0000
2025-06-07,13:20:04 | INFO | Start epoch 320
2025-06-07,13:20:07 | INFO | Train Epoch: 320 [  64/1034 (6%)] Data (t): 1.212 Batch (t): 2.422, 26.4255/s, 26.4255/s/gpu LR: 0.000051 Logit Scale: 83.131 Contrastive_loss: 0.088745 (0.088745) Loss: 0.088745 (0.088745)
2025-06-07,13:20:26 | INFO | Train Epoch: 320 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.248, 51.0616/s, 51.0616/s/gpu LR: 0.000051 Logit Scale: 83.116 Contrastive_loss: 0.011011 (0.049878) Loss: 0.011011 (0.049878)
2025-06-07,13:20:26 | INFO | Start epoch 321
2025-06-07,13:20:28 | INFO | Train Epoch: 321 [  64/1034 (6%)] Data (t): 1.147 Batch (t): 2.343, 27.3209/s, 27.3209/s/gpu LR: 0.000051 Logit Scale: 83.114 Contrastive_loss: 0.091083 (0.091083) Loss: 0.091083 (0.091083)
2025-06-07,13:20:47 | INFO | Train Epoch: 321 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2615/s, 51.2615/s/gpu LR: 0.000052 Logit Scale: 83.098 Contrastive_loss: 0.0047168 (0.047900) Loss: 0.0047168 (0.047900)
2025-06-07,13:20:47 | INFO | Start epoch 322
2025-06-07,13:20:50 | INFO | Train Epoch: 322 [  64/1034 (6%)] Data (t): 1.291 Batch (t): 2.476, 25.8474/s, 25.8474/s/gpu LR: 0.000052 Logit Scale: 83.096 Contrastive_loss: 0.071646 (0.071646) Loss: 0.071646 (0.071646)
2025-06-07,13:21:08 | INFO | Train Epoch: 322 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9707/s, 50.9707/s/gpu LR: 0.000052 Logit Scale: 83.070 Contrastive_loss: 0.033710 (0.052678) Loss: 0.033710 (0.052678)
2025-06-07,13:21:08 | INFO | Start epoch 323
2025-06-07,13:21:11 | INFO | Train Epoch: 323 [  64/1034 (6%)] Data (t): 1.192 Batch (t): 2.391, 26.7714/s, 26.7714/s/gpu LR: 0.000052 Logit Scale: 83.069 Contrastive_loss: 0.039464 (0.039464) Loss: 0.039464 (0.039464)
2025-06-07,13:21:30 | INFO | Train Epoch: 323 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0841/s, 51.0841/s/gpu LR: 0.000052 Logit Scale: 83.067 Contrastive_loss: 0.10895 (0.074208) Loss: 0.10895 (0.074208)
2025-06-07,13:21:30 | INFO | Start epoch 324
2025-06-07,13:21:32 | INFO | Train Epoch: 324 [  64/1034 (6%)] Data (t): 1.208 Batch (t): 2.402, 26.6454/s, 26.6454/s/gpu LR: 0.000052 Logit Scale: 83.066 Contrastive_loss: 0.11772 (0.11772) Loss: 0.11772 (0.11772)
2025-06-07,13:21:51 | INFO | Train Epoch: 324 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2431/s, 51.2431/s/gpu LR: 0.000052 Logit Scale: 83.040 Contrastive_loss: 0.043840 (0.080779) Loss: 0.043840 (0.080779)
2025-06-07,13:21:51 | INFO | Start epoch 325
2025-06-07,13:21:54 | INFO | Train Epoch: 325 [  64/1034 (6%)] Data (t): 1.236 Batch (t): 2.434, 26.2914/s, 26.2914/s/gpu LR: 0.000052 Logit Scale: 83.039 Contrastive_loss: 0.054131 (0.054131) Loss: 0.054131 (0.054131)
2025-06-07,13:22:12 | INFO | Train Epoch: 325 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.6862/s, 50.6862/s/gpu LR: 0.000052 Logit Scale: 83.017 Contrastive_loss: 0.17949 (0.11681) Loss: 0.17949 (0.11681)
2025-06-07,13:22:12 | INFO | Start epoch 326
2025-06-07,13:22:15 | INFO | Train Epoch: 326 [  64/1034 (6%)] Data (t): 1.215 Batch (t): 2.412, 26.5386/s, 26.5386/s/gpu LR: 0.000052 Logit Scale: 83.015 Contrastive_loss: 0.034656 (0.034656) Loss: 0.034656 (0.034656)
2025-06-07,13:22:34 | INFO | Train Epoch: 326 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0474/s, 51.0474/s/gpu LR: 0.000052 Logit Scale: 83.009 Contrastive_loss: 0.034139 (0.034398) Loss: 0.034139 (0.034398)
2025-06-07,13:22:34 | INFO | Start epoch 327
2025-06-07,13:22:36 | INFO | Train Epoch: 327 [  64/1034 (6%)] Data (t): 1.170 Batch (t): 2.374, 26.9616/s, 26.9616/s/gpu LR: 0.000052 Logit Scale: 83.008 Contrastive_loss: 0.040115 (0.040115) Loss: 0.040115 (0.040115)
2025-06-07,13:22:55 | INFO | Train Epoch: 327 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.248, 51.0138/s, 51.0138/s/gpu LR: 0.000052 Logit Scale: 82.997 Contrastive_loss: 0.078104 (0.059110) Loss: 0.078104 (0.059110)
2025-06-07,13:22:55 | INFO | Start epoch 328
2025-06-07,13:22:57 | INFO | Train Epoch: 328 [  64/1034 (6%)] Data (t): 1.191 Batch (t): 2.401, 26.6519/s, 26.6519/s/gpu LR: 0.000052 Logit Scale: 82.997 Contrastive_loss: 0.077216 (0.077216) Loss: 0.077216 (0.077216)
2025-06-07,13:23:16 | INFO | Train Epoch: 328 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.245, 51.8530/s, 51.8530/s/gpu LR: 0.000053 Logit Scale: 82.991 Contrastive_loss: 0.035841 (0.056528) Loss: 0.035841 (0.056528)
2025-06-07,13:23:16 | INFO | Start epoch 329
2025-06-07,13:23:19 | INFO | Train Epoch: 329 [  64/1034 (6%)] Data (t): 1.227 Batch (t): 2.422, 26.4292/s, 26.4292/s/gpu LR: 0.000053 Logit Scale: 82.990 Contrastive_loss: 0.052260 (0.052260) Loss: 0.052260 (0.052260)
2025-06-07,13:23:37 | INFO | Train Epoch: 329 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.250, 50.9072/s, 50.9072/s/gpu LR: 0.000053 Logit Scale: 82.975 Contrastive_loss: 0.062491 (0.057375) Loss: 0.062491 (0.057375)
2025-06-07,13:23:39 | INFO | Eval Epoch: 330 [64 / 1035]	Clip Loss: 8.832707	
2025-06-07,13:23:46 | INFO | Eval Epoch: 330 image_to_text_mean_rank: 355.1382	image_to_text_median_rank: 294.0000	image_to_text_R@1: 0.0106	image_to_text_R@5: 0.0261	image_to_text_R@10: 0.0396	text_to_image_mean_rank: 330.0280	text_to_image_median_rank: 270.0000	text_to_image_R@1: 0.0097	text_to_image_R@5: 0.0242	text_to_image_R@10: 0.0415	clip_val_loss: 9.2040	epoch: 330.0000	num_samples: 1035.0000
2025-06-07,13:23:46 | INFO | Start epoch 330
2025-06-07,13:23:48 | INFO | Train Epoch: 330 [  64/1034 (6%)] Data (t): 1.159 Batch (t): 2.351, 27.2235/s, 27.2235/s/gpu LR: 0.000053 Logit Scale: 82.974 Contrastive_loss: 0.044336 (0.044336) Loss: 0.044336 (0.044336)
2025-06-07,13:24:07 | INFO | Train Epoch: 330 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.250, 51.0988/s, 51.0988/s/gpu LR: 0.000053 Logit Scale: 82.963 Contrastive_loss: 0.084048 (0.064192) Loss: 0.084048 (0.064192)
2025-06-07,13:24:07 | INFO | Start epoch 331
2025-06-07,13:24:10 | INFO | Train Epoch: 331 [  64/1034 (6%)] Data (t): 1.261 Batch (t): 2.432, 26.3157/s, 26.3157/s/gpu LR: 0.000053 Logit Scale: 82.961 Contrastive_loss: 0.053452 (0.053452) Loss: 0.053452 (0.053452)
2025-06-07,13:24:28 | INFO | Train Epoch: 331 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.1394/s, 51.1394/s/gpu LR: 0.000053 Logit Scale: 82.948 Contrastive_loss: 0.053203 (0.053328) Loss: 0.053203 (0.053328)
2025-06-07,13:24:28 | INFO | Start epoch 332
2025-06-07,13:24:31 | INFO | Train Epoch: 332 [  64/1034 (6%)] Data (t): 1.180 Batch (t): 2.377, 26.9196/s, 26.9196/s/gpu LR: 0.000053 Logit Scale: 82.947 Contrastive_loss: 0.094255 (0.094255) Loss: 0.094255 (0.094255)
2025-06-07,13:24:50 | INFO | Train Epoch: 332 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.3662/s, 51.3662/s/gpu LR: 0.000053 Logit Scale: 82.940 Contrastive_loss: 0.096328 (0.095292) Loss: 0.096328 (0.095292)
2025-06-07,13:24:50 | INFO | Start epoch 333
2025-06-07,13:24:52 | INFO | Train Epoch: 333 [  64/1034 (6%)] Data (t): 1.220 Batch (t): 2.394, 26.7284/s, 26.7284/s/gpu LR: 0.000053 Logit Scale: 82.939 Contrastive_loss: 0.044140 (0.044140) Loss: 0.044140 (0.044140)
2025-06-07,13:25:11 | INFO | Train Epoch: 333 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.250, 51.0274/s, 51.0274/s/gpu LR: 0.000053 Logit Scale: 82.924 Contrastive_loss: 0.033426 (0.038783) Loss: 0.033426 (0.038783)
2025-06-07,13:25:11 | INFO | Start epoch 334
2025-06-07,13:25:14 | INFO | Train Epoch: 334 [  64/1034 (6%)] Data (t): 1.318 Batch (t): 2.514, 25.4585/s, 25.4585/s/gpu LR: 0.000053 Logit Scale: 82.923 Contrastive_loss: 0.041934 (0.041934) Loss: 0.041934 (0.041934)
2025-06-07,13:25:32 | INFO | Train Epoch: 334 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.6874/s, 50.6874/s/gpu LR: 0.000054 Logit Scale: 82.909 Contrastive_loss: 0.12463 (0.083283) Loss: 0.12463 (0.083283)
2025-06-07,13:25:32 | INFO | Start epoch 335
2025-06-07,13:25:35 | INFO | Train Epoch: 335 [  64/1034 (6%)] Data (t): 1.243 Batch (t): 2.432, 26.3162/s, 26.3162/s/gpu LR: 0.000054 Logit Scale: 82.907 Contrastive_loss: 0.0059128 (0.0059128) Loss: 0.0059128 (0.0059128)
2025-06-07,13:25:54 | INFO | Train Epoch: 335 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.0489/s, 51.0489/s/gpu LR: 0.000054 Logit Scale: 82.894 Contrastive_loss: 0.038479 (0.022196) Loss: 0.038479 (0.022196)
2025-06-07,13:25:54 | INFO | Start epoch 336
2025-06-07,13:25:56 | INFO | Train Epoch: 336 [  64/1034 (6%)] Data (t): 1.140 Batch (t): 2.339, 27.3657/s, 27.3657/s/gpu LR: 0.000054 Logit Scale: 82.895 Contrastive_loss: 0.0096337 (0.0096337) Loss: 0.0096337 (0.0096337)
2025-06-07,13:26:15 | INFO | Train Epoch: 336 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.2169/s, 51.2169/s/gpu LR: 0.000054 Logit Scale: 82.883 Contrastive_loss: 0.025329 (0.017481) Loss: 0.025329 (0.017481)
2025-06-07,13:26:15 | INFO | Start epoch 337
2025-06-07,13:26:18 | INFO | Train Epoch: 337 [  64/1034 (6%)] Data (t): 1.297 Batch (t): 2.482, 25.7888/s, 25.7888/s/gpu LR: 0.000054 Logit Scale: 82.883 Contrastive_loss: 0.047844 (0.047844) Loss: 0.047844 (0.047844)
2025-06-07,13:26:36 | INFO | Train Epoch: 337 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.251, 51.1015/s, 51.1015/s/gpu LR: 0.000054 Logit Scale: 82.862 Contrastive_loss: 0.042443 (0.045144) Loss: 0.042443 (0.045144)
2025-06-07,13:26:36 | INFO | Start epoch 338
2025-06-07,13:26:39 | INFO | Train Epoch: 338 [  64/1034 (6%)] Data (t): 1.193 Batch (t): 2.385, 26.8311/s, 26.8311/s/gpu LR: 0.000054 Logit Scale: 82.861 Contrastive_loss: 0.20069 (0.20069) Loss: 0.20069 (0.20069)
2025-06-07,13:26:58 | INFO | Train Epoch: 338 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.1500/s, 51.1500/s/gpu LR: 0.000054 Logit Scale: 82.841 Contrastive_loss: 0.026344 (0.11352) Loss: 0.026344 (0.11352)
2025-06-07,13:26:58 | INFO | Start epoch 339
2025-06-07,13:27:00 | INFO | Train Epoch: 339 [  64/1034 (6%)] Data (t): 1.483 Batch (t): 2.662, 24.0459/s, 24.0459/s/gpu LR: 0.000054 Logit Scale: 82.841 Contrastive_loss: 0.046846 (0.046846) Loss: 0.046846 (0.046846)
2025-06-07,13:27:19 | INFO | Train Epoch: 339 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.247, 51.2475/s, 51.2475/s/gpu LR: 0.000054 Logit Scale: 82.850 Contrastive_loss: 0.026316 (0.036581) Loss: 0.026316 (0.036581)
2025-06-07,13:27:21 | INFO | Eval Epoch: 340 [64 / 1035]	Clip Loss: 8.925618	
2025-06-07,13:27:28 | INFO | Eval Epoch: 340 image_to_text_mean_rank: 344.6502	image_to_text_median_rank: 285.0000	image_to_text_R@1: 0.0068	image_to_text_R@5: 0.0280	image_to_text_R@10: 0.0473	text_to_image_mean_rank: 336.2667	text_to_image_median_rank: 277.0000	text_to_image_R@1: 0.0048	text_to_image_R@5: 0.0271	text_to_image_R@10: 0.0512	clip_val_loss: 9.4954	epoch: 340.0000	num_samples: 1035.0000
2025-06-07,13:27:28 | INFO | Start epoch 340
2025-06-07,13:27:30 | INFO | Train Epoch: 340 [  64/1034 (6%)] Data (t): 1.472 Batch (t): 2.643, 24.2152/s, 24.2152/s/gpu LR: 0.000054 Logit Scale: 82.851 Contrastive_loss: 0.021764 (0.021764) Loss: 0.021764 (0.021764)
2025-06-07,13:27:49 | INFO | Train Epoch: 340 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.243, 50.8341/s, 50.8341/s/gpu LR: 0.000055 Logit Scale: 82.839 Contrastive_loss: 0.061720 (0.041742) Loss: 0.061720 (0.041742)
2025-06-07,13:27:49 | INFO | Start epoch 341
2025-06-07,13:27:51 | INFO | Train Epoch: 341 [  64/1034 (6%)] Data (t): 1.238 Batch (t): 2.426, 26.3812/s, 26.3812/s/gpu LR: 0.000055 Logit Scale: 82.838 Contrastive_loss: 0.040672 (0.040672) Loss: 0.040672 (0.040672)
2025-06-07,13:28:10 | INFO | Train Epoch: 341 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.1013/s, 51.1013/s/gpu LR: 0.000055 Logit Scale: 82.813 Contrastive_loss: 0.084653 (0.062662) Loss: 0.084653 (0.062662)
2025-06-07,13:28:10 | INFO | Start epoch 342
2025-06-07,13:28:13 | INFO | Train Epoch: 342 [  64/1034 (6%)] Data (t): 1.151 Batch (t): 2.341, 27.3384/s, 27.3384/s/gpu LR: 0.000055 Logit Scale: 82.812 Contrastive_loss: 0.046014 (0.046014) Loss: 0.046014 (0.046014)
2025-06-07,13:28:31 | INFO | Train Epoch: 342 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.1537/s, 51.1537/s/gpu LR: 0.000055 Logit Scale: 82.802 Contrastive_loss: 0.12074 (0.083375) Loss: 0.12074 (0.083375)
2025-06-07,13:28:32 | INFO | Start epoch 343
2025-06-07,13:28:34 | INFO | Train Epoch: 343 [  64/1034 (6%)] Data (t): 1.264 Batch (t): 2.455, 26.0710/s, 26.0710/s/gpu LR: 0.000055 Logit Scale: 82.802 Contrastive_loss: 0.032261 (0.032261) Loss: 0.032261 (0.032261)
2025-06-07,13:28:53 | INFO | Train Epoch: 343 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0031/s, 51.0031/s/gpu LR: 0.000055 Logit Scale: 82.787 Contrastive_loss: 0.090305 (0.061283) Loss: 0.090305 (0.061283)
2025-06-07,13:28:53 | INFO | Start epoch 344
2025-06-07,13:28:55 | INFO | Train Epoch: 344 [  64/1034 (6%)] Data (t): 1.280 Batch (t): 2.466, 25.9482/s, 25.9482/s/gpu LR: 0.000055 Logit Scale: 82.786 Contrastive_loss: 0.016796 (0.016796) Loss: 0.016796 (0.016796)
2025-06-07,13:29:14 | INFO | Train Epoch: 344 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.252, 51.2715/s, 51.2715/s/gpu LR: 0.000055 Logit Scale: 82.772 Contrastive_loss: 0.053830 (0.035313) Loss: 0.053830 (0.035313)
2025-06-07,13:29:14 | INFO | Start epoch 345
2025-06-07,13:29:17 | INFO | Train Epoch: 345 [  64/1034 (6%)] Data (t): 1.299 Batch (t): 2.481, 25.8006/s, 25.8006/s/gpu LR: 0.000055 Logit Scale: 82.771 Contrastive_loss: 0.020806 (0.020806) Loss: 0.020806 (0.020806)
2025-06-07,13:29:36 | INFO | Train Epoch: 345 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.3518/s, 51.3518/s/gpu LR: 0.000055 Logit Scale: 82.758 Contrastive_loss: 0.039613 (0.030210) Loss: 0.039613 (0.030210)
2025-06-07,13:29:36 | INFO | Start epoch 346
2025-06-07,13:29:38 | INFO | Train Epoch: 346 [  64/1034 (6%)] Data (t): 1.190 Batch (t): 2.392, 26.7527/s, 26.7527/s/gpu LR: 0.000055 Logit Scale: 82.757 Contrastive_loss: 0.060248 (0.060248) Loss: 0.060248 (0.060248)
2025-06-07,13:29:57 | INFO | Train Epoch: 346 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.6115/s, 50.6115/s/gpu LR: 0.000056 Logit Scale: 82.742 Contrastive_loss: 0.23009 (0.14517) Loss: 0.23009 (0.14517)
2025-06-07,13:29:57 | INFO | Start epoch 347
2025-06-07,13:30:00 | INFO | Train Epoch: 347 [  64/1034 (6%)] Data (t): 1.205 Batch (t): 2.403, 26.6285/s, 26.6285/s/gpu LR: 0.000056 Logit Scale: 82.739 Contrastive_loss: 0.053501 (0.053501) Loss: 0.053501 (0.053501)
2025-06-07,13:30:18 | INFO | Train Epoch: 347 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0001/s, 51.0001/s/gpu LR: 0.000056 Logit Scale: 82.713 Contrastive_loss: 0.010869 (0.032185) Loss: 0.010869 (0.032185)
2025-06-07,13:30:18 | INFO | Start epoch 348
2025-06-07,13:30:21 | INFO | Train Epoch: 348 [  64/1034 (6%)] Data (t): 1.294 Batch (t): 2.487, 25.7296/s, 25.7296/s/gpu LR: 0.000056 Logit Scale: 82.712 Contrastive_loss: 0.091472 (0.091472) Loss: 0.091472 (0.091472)
2025-06-07,13:30:40 | INFO | Train Epoch: 348 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.8093/s, 50.8093/s/gpu LR: 0.000056 Logit Scale: 82.708 Contrastive_loss: 0.066781 (0.079127) Loss: 0.066781 (0.079127)
2025-06-07,13:30:40 | INFO | Start epoch 349
2025-06-07,13:30:42 | INFO | Train Epoch: 349 [  64/1034 (6%)] Data (t): 1.180 Batch (t): 2.400, 26.6692/s, 26.6692/s/gpu LR: 0.000056 Logit Scale: 82.707 Contrastive_loss: 0.060412 (0.060412) Loss: 0.060412 (0.060412)
2025-06-07,13:31:01 | INFO | Train Epoch: 349 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 50.8450/s, 50.8450/s/gpu LR: 0.000056 Logit Scale: 82.690 Contrastive_loss: 0.067453 (0.063932) Loss: 0.067453 (0.063932)
2025-06-07,13:31:03 | INFO | Eval Epoch: 350 [64 / 1035]	Clip Loss: 8.312298	
2025-06-07,13:31:09 | INFO | Eval Epoch: 350 image_to_text_mean_rank: 366.8454	image_to_text_median_rank: 317.0000	image_to_text_R@1: 0.0039	image_to_text_R@5: 0.0155	image_to_text_R@10: 0.0348	text_to_image_mean_rank: 345.1324	text_to_image_median_rank: 271.0000	text_to_image_R@1: 0.0029	text_to_image_R@5: 0.0251	text_to_image_R@10: 0.0406	clip_val_loss: 9.8696	epoch: 350.0000	num_samples: 1035.0000
2025-06-07,13:31:09 | INFO | Start epoch 350
2025-06-07,13:31:12 | INFO | Train Epoch: 350 [  64/1034 (6%)] Data (t): 1.298 Batch (t): 2.471, 25.8994/s, 25.8994/s/gpu LR: 0.000056 Logit Scale: 82.688 Contrastive_loss: 0.037092 (0.037092) Loss: 0.037092 (0.037092)
2025-06-07,13:31:31 | INFO | Train Epoch: 350 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 50.9982/s, 50.9982/s/gpu LR: 0.000056 Logit Scale: 82.675 Contrastive_loss: 0.073301 (0.055196) Loss: 0.073301 (0.055196)
2025-06-07,13:31:31 | INFO | Start epoch 351
2025-06-07,13:31:33 | INFO | Train Epoch: 351 [  64/1034 (6%)] Data (t): 1.201 Batch (t): 2.405, 26.6140/s, 26.6140/s/gpu LR: 0.000056 Logit Scale: 82.674 Contrastive_loss: 0.070216 (0.070216) Loss: 0.070216 (0.070216)
2025-06-07,13:31:52 | INFO | Train Epoch: 351 [1024/1034 (100%)] Data (t): 0.004 Batch (t): 1.251, 50.7758/s, 50.7758/s/gpu LR: 0.000056 Logit Scale: 82.662 Contrastive_loss: 0.12018 (0.095197) Loss: 0.12018 (0.095197)
2025-06-07,13:31:52 | INFO | Start epoch 352
2025-06-07,13:31:55 | INFO | Train Epoch: 352 [  64/1034 (6%)] Data (t): 1.270 Batch (t): 2.445, 26.1727/s, 26.1727/s/gpu LR: 0.000056 Logit Scale: 82.661 Contrastive_loss: 0.069127 (0.069127) Loss: 0.069127 (0.069127)
2025-06-07,13:32:14 | INFO | Train Epoch: 352 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.255, 51.1751/s, 51.1751/s/gpu LR: 0.000056 Logit Scale: 82.656 Contrastive_loss: 0.026393 (0.047760) Loss: 0.026393 (0.047760)
2025-06-07,13:32:14 | INFO | Start epoch 353
2025-06-07,13:32:16 | INFO | Train Epoch: 353 [  64/1034 (6%)] Data (t): 1.186 Batch (t): 2.364, 27.0720/s, 27.0720/s/gpu LR: 0.000056 Logit Scale: 82.655 Contrastive_loss: 0.025839 (0.025839) Loss: 0.025839 (0.025839)
2025-06-07,13:32:35 | INFO | Train Epoch: 353 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.254, 51.2097/s, 51.2097/s/gpu LR: 0.000057 Logit Scale: 82.628 Contrastive_loss: 0.084124 (0.054982) Loss: 0.084124 (0.054982)
2025-06-07,13:32:35 | INFO | Start epoch 354
2025-06-07,13:32:37 | INFO | Train Epoch: 354 [  64/1034 (6%)] Data (t): 1.201 Batch (t): 2.385, 26.8332/s, 26.8332/s/gpu LR: 0.000057 Logit Scale: 82.628 Contrastive_loss: 0.039273 (0.039273) Loss: 0.039273 (0.039273)
2025-06-07,13:32:56 | INFO | Train Epoch: 354 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.0859/s, 51.0859/s/gpu LR: 0.000057 Logit Scale: 82.606 Contrastive_loss: 0.028093 (0.033683) Loss: 0.028093 (0.033683)
2025-06-07,13:32:56 | INFO | Start epoch 355
2025-06-07,13:32:59 | INFO | Train Epoch: 355 [  64/1034 (6%)] Data (t): 1.263 Batch (t): 2.441, 26.2167/s, 26.2167/s/gpu LR: 0.000057 Logit Scale: 82.604 Contrastive_loss: 0.0059069 (0.0059069) Loss: 0.0059069 (0.0059069)
2025-06-07,13:33:18 | INFO | Train Epoch: 355 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.253, 51.4233/s, 51.4233/s/gpu LR: 0.000057 Logit Scale: 82.607 Contrastive_loss: 0.075967 (0.040937) Loss: 0.075967 (0.040937)
2025-06-07,13:33:18 | INFO | Start epoch 356
2025-06-07,13:33:20 | INFO | Train Epoch: 356 [  64/1034 (6%)] Data (t): 1.275 Batch (t): 2.475, 25.8551/s, 25.8551/s/gpu LR: 0.000057 Logit Scale: 82.608 Contrastive_loss: 0.20621 (0.20621) Loss: 0.20621 (0.20621)
2025-06-07,13:33:39 | INFO | Train Epoch: 356 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.249, 51.9661/s, 51.9661/s/gpu LR: 0.000057 Logit Scale: 82.605 Contrastive_loss: 0.00082462 (0.10351) Loss: 0.00082462 (0.10351)
2025-06-07,13:33:39 | INFO | Start epoch 357
2025-06-07,13:33:41 | INFO | Train Epoch: 357 [  64/1034 (6%)] Data (t): 1.279 Batch (t): 2.451, 26.1156/s, 26.1156/s/gpu LR: 0.000057 Logit Scale: 82.604 Contrastive_loss: 0.055895 (0.055895) Loss: 0.055895 (0.055895)
2025-06-07,13:34:00 | INFO | Train Epoch: 357 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.248, 50.9395/s, 50.9395/s/gpu LR: 0.000057 Logit Scale: 82.580 Contrastive_loss: 0.065753 (0.060824) Loss: 0.065753 (0.060824)
2025-06-07,13:34:00 | INFO | Start epoch 358
2025-06-07,13:34:03 | INFO | Train Epoch: 358 [  64/1034 (6%)] Data (t): 1.241 Batch (t): 2.437, 26.2574/s, 26.2574/s/gpu LR: 0.000057 Logit Scale: 82.578 Contrastive_loss: 0.063313 (0.063313) Loss: 0.063313 (0.063313)
2025-06-07,13:34:21 | INFO | Train Epoch: 358 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.249, 50.7826/s, 50.7826/s/gpu LR: 0.000057 Logit Scale: 82.566 Contrastive_loss: 0.052561 (0.057937) Loss: 0.052561 (0.057937)
2025-06-07,13:34:22 | INFO | Start epoch 359
2025-06-07,13:34:24 | INFO | Train Epoch: 359 [  64/1034 (6%)] Data (t): 1.333 Batch (t): 2.516, 25.4399/s, 25.4399/s/gpu LR: 0.000057 Logit Scale: 82.566 Contrastive_loss: 0.092577 (0.092577) Loss: 0.092577 (0.092577)
2025-06-07,13:34:43 | INFO | Train Epoch: 359 [1024/1034 (100%)] Data (t): 0.005 Batch (t): 1.249, 51.0052/s, 51.0052/s/gpu LR: 0.000058 Logit Scale: 82.570 Contrastive_loss: 0.038020 (0.065299) Loss: 0.038020 (0.065299)
2025-06-07,13:34:45 | INFO | Eval Epoch: 360 [64 / 1035]	Clip Loss: 8.273764	
2025-06-07,13:34:51 | INFO | Eval Epoch: 360 image_to_text_mean_rank: 337.9420	image_to_text_median_rank: 277.0000	image_to_text_R@1: 0.0116	image_to_text_R@5: 0.0261	image_to_text_R@10: 0.0541	text_to_image_mean_rank: 333.3304	text_to_image_median_rank: 260.0000	text_to_image_R@1: 0.0116	text_to_image_R@5: 0.0280	text_to_image_R@10: 0.0425	clip_val_loss: 9.1041	epoch: 360.0000	num_samples: 1035.0000

I0607 13:34:54.722000 120 torch/_inductor/remote_cache.py:414] Cache Metrics: None
I0607 13:34:54.722000 120 torch/_inductor/remote_cache.py:414] 
I0607 13:34:54.723000 120 torch/_dynamo/eval_frame.py:398] TorchDynamo attempted to trace the following frames: [
I0607 13:34:54.723000 120 torch/_dynamo/eval_frame.py:398] 
I0607 13:34:54.723000 120 torch/_dynamo/eval_frame.py:398] ]
I0607 13:34:54.750000 120 torch/_dynamo/utils.py:446] TorchDynamo compilation metrics:
I0607 13:34:54.750000 120 torch/_dynamo/utils.py:446] Function    Runtimes (s)
I0607 13:34:54.750000 120 torch/_dynamo/utils.py:446] ----------  --------------
I0607 13:34:54.766000 120 torch/_subclasses/fake_tensor.py:2795] FakeTensor cache stats:
I0607 13:34:54.766000 120 torch/_subclasses/fake_tensor.py:2796]   cache_hits: 0
I0607 13:34:54.766000 120 torch/_subclasses/fake_tensor.py:2797]   cache_misses: 0